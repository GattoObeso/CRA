{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Replication_package_FineTuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPvSxZP1nAXmVYf7Nk+DS/f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masies/CRA/blob/main/Replication_package_FineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWgILLAAy_N-"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX9_YlEdy8gz",
        "outputId": "360b1a5b-c995-4dd7-f323-2f2cddc233d6"
      },
      "source": [
        "!pip3 install tensorflow\n",
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "#!pip install -qU t5\n",
        "!pip3 install git+https://github.com/google-research/text-to-text-transfer-transformer.git #extra_id_x support\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://example_comment\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.34.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (56.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.0)\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/82/04e9aaf603fdbaecb4323b9e723f13c92c245f6ab2902195c53987848c78/pip-21.1.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.1.2\n",
            "Collecting git+https://github.com/google-research/text-to-text-transfer-transformer.git\n",
            "  Cloning https://github.com/google-research/text-to-text-transfer-transformer.git to /tmp/pip-req-build-_u65bb7d\n",
            "  Running command git clone -q https://github.com/google-research/text-to-text-transfer-transformer.git /tmp/pip-req-build-_u65bb7d\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (0.12.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (2.9.1)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (0.4.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.19-py3-none-any.whl (366 kB)\n",
            "\u001b[K     |████████████████████████████████| 366 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.1.5)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 9.5 MB/s \n",
            "\u001b[?25hCollecting seqio\n",
            "  Downloading seqio-0.0.5-py3-none-any.whl (249 kB)\n",
            "\u001b[K     |████████████████████████████████| 249 kB 18.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.15.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 18.8 MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.3.0.dev202105270107-py3-none-any.whl (3.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9 MB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.8.1+cu101)\n",
            "Collecting transformers>=2.7.0\n",
            "  Downloading transformers-4.6.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2 MB 71.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (4.0.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 71.5 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub==0.0.8\n",
            "  Downloading huggingface_hub-0.0.8-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (20.9)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (2019.12.20)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5==0.9.1) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.9.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.9.1) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.7.0->t5==0.9.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->t5==0.9.1) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.1) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.1) (2.10)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.9.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.9.1) (1.0.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (1.0.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (21.2.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (3.12.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (5.1.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (0.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (56.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (1.53.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.9.1) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.6,>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.9.1) (2.5.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.6.3)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (0.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (2.5.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (3.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.34.1)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (2.5.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (0.4.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow<2.6,>=2.5.0->tensorflow-text->t5==0.9.1) (3.1.0)\n",
            "Building wheels for collected packages: t5\n",
            "  Building wheel for t5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for t5: filename=t5-0.9.1-py3-none-any.whl size=152187 sha256=db3093f2f1a07ad867be506eefc64b4442cd1373aaa5701d180e0d075b9f10e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hs7fa8sc/wheels/bf/e8/36/0d7b7d2aa6a91236ea133d24d501fb1faf73d6bf2579f05c96\n",
            "Successfully built t5\n",
            "Installing collected packages: tokenizers, tfds-nightly, tensorflow-text, sentencepiece, sacremoses, portalocker, mesh-tensorflow, huggingface-hub, transformers, seqio, sacrebleu, rouge-score, t5\n",
            "Successfully installed huggingface-hub-0.0.8 mesh-tensorflow-0.1.19 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.5.1 sacremoses-0.0.45 sentencepiece-0.1.95 seqio-0.0.5 t5-0.9.1 tensorflow-text-2.5.0 tfds-nightly-4.3.0.dev202105270107 tokenizers-0.10.3 transformers-4.6.1\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Running on TPU: grpc://10.40.152.130:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAo86QxiwX9F"
      },
      "source": [
        "We link all the datasets we built to their related tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IC03zV3sy8oT"
      },
      "source": [
        "## tasks large dataset\n",
        "nq_tsv_path_code_code_large = {\n",
        "    \"train\":      'gs://code_review_automation/replication_package/dataset/fine-tuning/large/code_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/replication_package/dataset/fine-tuning/large/code_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_code_code_large = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_code_comment_large = {\n",
        "    \"train\":      'gs://code_review_automation/replication_package/dataset/fine-tuning/large/code_comment/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/replication_package/dataset/fine-tuning/large/code_comment/val.tsv'\n",
        "}\n",
        "num_nq_examples_code_comment_large = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_codeANDcomment_code_large = {\n",
        "    \"train\":      'gs://code_review_automation/replication_package/dataset/fine-tuning/large/codeANDcomment_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/replication_package/dataset/fine-tuning/large/codeANDcomment_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_codeANDcomment_code_large = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_marked_code_large = {\n",
        "    \"train\":      'gs://code_review_automation/replication_package/dataset/fine-tuning/large/marked_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/replication_package/dataset/fine-tuning/large/marked_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_marked_code_large = dict(train=134442, validation=16805)\n",
        "\n",
        "\n",
        "## tasks small dataset v1\n",
        "\n",
        "nq_tsv_path_code_code_small_v1 = {\n",
        "    \"train\":      'gs://code_review_automation/replication_package/dataset/fine-tuning/small/v1/code_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/replication_package/dataset/fine-tuning/small/v1/code_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_code_code_small_v1 = dict(train=13671, validation=1714)\n",
        "\n",
        "nq_tsv_path_codeANDcomment_code_small_v1 = {\n",
        "    \"train\":      'gs://code_review_automation/replication_package/dataset/fine-tuning/small/v1/codeANDcomment_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/replication_package/dataset/fine-tuning/small/v1/codeANDcomment_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_codeANDcomment_code_small_v1 = dict(train=13671, validation=1714)\n",
        "\n",
        "## tasks small dataset v2\n",
        "nq_tsv_path_code_code_small_v2 = {\n",
        "    \"train\":      'gs://code_review_automation/replication_package/dataset/fine-tuning/small/v2/code_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/replication_package/dataset/fine-tuning/small/v2/code_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_code_code_small_v2 = dict(train=13671, validation=1714)\n",
        "\n",
        "nq_tsv_path_codeANDcomment_code_small_v2 = {\n",
        "    \"train\":      'gs://code_review_automation/replication_package/dataset/fine-tuning/small/v2/codeANDcomment_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/replication_package/dataset/fine-tuning/small/v2/codeANDcomment_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_codeANDcomment_code_small_v2 = dict(train=13671, validation=1714)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_twenV5ZwhPf"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "\n",
        "vocab_model_path = 'gs://code_review_automation/CodeReviewModel/TestModel.model'\n",
        "vocab_path = 'gs://code_review_automation/CodeReviewModel/TestModel.vocab'\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDvropGqwja9"
      },
      "source": [
        "# Setting up all the tasks\n",
        "\n",
        "We will set 8 tasks\n",
        "- code prediction (large dataset)\n",
        "- code prediction (small dataset v1)\n",
        "- code prediction (small dataset v2)\n",
        "- comment implementation (large dataset)\n",
        "- comment implementation (small dataset v1)\n",
        "- comment implementation (small dataset v2)\n",
        "- code prediction, given marked code (large dataset)\n",
        "- comment prediction (large dataset)\n",
        "\n",
        "then we will later chose which one or which mixture to tune\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8zPvNrpypq7"
      },
      "source": [
        "## FIRST TASK : CODE to CODE large_dataset\n",
        "- task name = `code_code`\n",
        "- task prefix = `code2code: `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHRgYezy8uE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8612d8d2-80cc-4ddf-8c97-e123c1b6756a"
      },
      "source": [
        "def nq_dataset_code_code_large(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_code_code_large[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code_large(\"validation\").take(2)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code_large(\"train\").take(2)):\n",
        "  print(ex)\n",
        "\n",
        "def code_code_preprocessing(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join(['code2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "t5.data.TaskRegistry.remove('code_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"code_code\",\n",
        "    dataset_fn=nq_dataset_code_code_large,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[code_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_code_code_large\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"code_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "# print(\"A few preprocessed training examples...\")\n",
        "# for ex in tfds.as_numpy(ds.take(3)):\n",
        "#   print(ex)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'public void execute() throws BuildException { String generatedPassword=\"\"; if (addproperty == null || addproperty.equals(\"\")) { throw new BuildException(\"\\\\tThe output property is required for this task.\"); } if (password == null || password.equals(\"\")) { throw new BuildException(\"\\\\tThe password property is required for this task.\"); } try { MessageDigest md = MessageDigest.getInstance(\"SHA-256\"); md.update(password.getBytes()); byte[] bytes = md.digest(); generatedPassword = new String(Base64.encodeBase64(bytes)); } catch (NoSuchAlgorithmException e) { throw new BuildException(\"\\\\tThere is a problem encrypting the password with MD5 algorithm\"); } if (addproperty != null && !addproperty.equals(\"\")) { getProject().setProperty(addproperty, generatedPassword); } }', 'output': b'public void execute() throws BuildException { String generatedPassword=\"\"; if (addproperty == null || addproperty.equals(\"\")) { throw new BuildException(\"\\\\tThe output property is required for this task.\"); } if (password == null || password.equals(\"\")) { throw new BuildException(\"\\\\tThe password property is required for this task.\"); } generatedPassword = DigestUtils.sha256Hex(password); if (addproperty != null && !addproperty.equals(\"\")) { getProject().setProperty(addproperty, generatedPassword); } }'}\n",
            "{'input': b'protected VdcActionParametersBase getParametersForTask(VdcActionType actionType, VdcActionParametersBase parameters) { VdcActionType parentCommandType = getParentCommand(actionType); VdcActionParametersBase parentParameters = null; if (parentHasCallback()) { if (getTaskType() == AsyncTaskType.notSupported) { parentParameters = getParameters().getParentParameters(); } } else { parentParameters = getParameters().getParentParameters(); } if (parentCommandType == VdcActionType.Unknown || parentParameters == null) { return parameters; } parentParameters.setExecutionReason(parameters.getExecutionReason()); parentParameters.setCommandType(parentCommandType); return parentParameters; }', 'output': b'protected VdcActionParametersBase getParametersForTask(VdcActionType actionType, VdcActionParametersBase parameters) { VdcActionType parentCommandType = getParentCommandType(actionType); VdcActionParametersBase parentParameters = getParentParameters(); if (parentCommandType == VdcActionType.Unknown || parentParameters == null) { return parameters; } parentParameters.setExecutionReason(parameters.getExecutionReason()); parentParameters.setCommandType(parentCommandType); return parentParameters; }'}\n",
            "A few raw training examples...\n",
            "{'input': b'public static Region parseRegion(String regionString) { Region region = null; if (regionString != null && !regionString.equals(\"\")) { if (regionString.indexOf(\\':\\') != -1) { String[] fields = regionString.split(\"[:-]\", -1); if (fields.length == 3) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.parseInt(fields[2])); } else if (fields.length == 2) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.MAX_VALUE); } } else { region = new Region(regionString, 0, Integer.MAX_VALUE); } } return region; }', 'output': b'public static Region parseRegion(String regionString) { Region region = null; if (regionString != null && !regionString.equals(\"\")) { if (regionString.indexOf(\\':\\') != -1) { String[] fields = regionString.split(\"[:-]\", -1); if (fields.length == 3) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.parseInt(fields[2])); } else if (fields.length == 2) { region = new Region(fields[0], Integer.parseInt(fields[1])); } } else { region = new Region(regionString); } } return region; }'}\n",
            "{'input': b'public VdcActionParametersBase getParameters(VM incoming, org.ovirt.engine.core.common.businessentities.VM entity) { VmStatic updated = getMapper(modelType, VmStatic.class).map(incoming, entity.getStaticData()); updated.setUsbPolicy(VmMapper.getUsbPolicyOnUpdate(incoming.getUsb(), entity.getUsbPolicy(), lookupCluster(updated.getVdsGroupId()))); VmManagementParametersBase params = new VmManagementParametersBase(updated); if (incoming.isSetPayloads()) { if (incoming.isSetPayloads() && incoming.getPayloads().isSetPayload()) { params.setVmPayload(parent.getPayload(incoming)); } else { params.setClearPayload(true); } } if (incoming.isSetMemoryPolicy() && incoming.getMemoryPolicy().isSetBallooning()) { params.setBalloonEnabled(incoming.getMemoryPolicy().isBallooning()); } if (incoming.isSetConsoleDeviceEnabled()) { params.setConsoleEnabled(incoming.isConsoleDeviceEnabled()); } return params; }', 'output': b'public VdcActionParametersBase getParameters(VM incoming, org.ovirt.engine.core.common.businessentities.VM entity) { VmStatic updated = getMapper(modelType, VmStatic.class).map(incoming, entity.getStaticData()); updated.setUsbPolicy(VmMapper.getUsbPolicyOnUpdate(incoming.getUsb(), entity.getUsbPolicy(), lookupCluster(updated.getVdsGroupId()))); VmManagementParametersBase params = new VmManagementParametersBase(updated); if (incoming.isSetPayloads()) { if (incoming.isSetPayloads() && incoming.getPayloads().isSetPayload()) { params.setVmPayload(parent.getPayload(incoming)); } else { params.setClearPayload(true); } } if (incoming.isSetMemoryPolicy() && incoming.getMemoryPolicy().isSetBallooning()) { params.setBalloonEnabled(incoming.getMemoryPolicy().isBallooning()); } if (incoming.isSetConsole() && incoming.getConsole().isSetEnabled()) { params.setConsoleEnabled(incoming.getConsole().isEnabled()); } return params; }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32bONo87yxhA"
      },
      "source": [
        "## SECOND TASK : CODE to COMMENT large_dataset\n",
        "- task name = `code_comment`\n",
        "- task prefix = `code2comment: `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p68qZUBTxWiF",
        "outputId": "15b56d9c-b9bb-44fb-a1d6-898e2f881786"
      },
      "source": [
        "def nq_dataset_code_comment_large(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_code_comment_large[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_comment_large(\"validation\").take(2)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_comment_large(\"train\").take(2)):\n",
        "  print(ex)\n",
        "\n",
        "def code_comment_preprocessing(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code2comment: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('code_comment')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"code_comment\",\n",
        "    dataset_fn=nq_dataset_code_comment_large,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[code_comment_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_code_comment_large\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"code_comment\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "# print(\"A few preprocessed training examples...\")\n",
        "# for ex in tfds.as_numpy(ds.take(3)):\n",
        "#   print(ex)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'public void execute() throws BuildException { String generatedPassword=\"\"; if (addproperty == null || addproperty.equals(\"\")) { throw new BuildException(\"\\\\tThe output property is required for this task.\"); } if (password == null || password.equals(\"\")) { throw new BuildException(\"\\\\tThe password property is required for this task.\"); } try { MessageDigest md = MessageDigest.getInstance(\"SHA-256\"); md.update(password.getBytes()); byte[] bytes = md.digest(); generatedPassword = new String(Base64.encodeBase64(bytes)); } catch (NoSuchAlgorithmException e) { throw new BuildException(\"\\\\tThere is a problem encrypting the password with MD5 algorithm\"); } if (addproperty != null && !addproperty.equals(\"\")) { getProject().setProperty(addproperty, generatedPassword); } }', 'output': b\"If we're going to include commons-codec as a dependency, then I think you should just replace the whole block of code above with this:  generatedPassword = DigestUtils.sha256Hex(password);\"}\n",
            "{'input': b'protected VdcActionParametersBase getParametersForTask(VdcActionType actionType, VdcActionParametersBase parameters) { VdcActionType parentCommandType = getParentCommand(actionType); VdcActionParametersBase parentParameters = null; if (parentHasCallback()) { if (getTaskType() == AsyncTaskType.notSupported) { parentParameters = getParameters().getParentParameters(); } } else { parentParameters = getParameters().getParentParameters(); } if (parentCommandType == VdcActionType.Unknown || parentParameters == null) { return parameters; } parentParameters.setExecutionReason(parameters.getExecutionReason()); parentParameters.setCommandType(parentCommandType); return parentParameters; }', 'output': b\"couldn't this be replaced with getParentCommand() ?\"}\n",
            "A few raw training examples...\n",
            "{'input': b'public static Region parseRegion(String regionString) { Region region = null; if (regionString != null && !regionString.equals(\"\")) { if (regionString.indexOf(\\':\\') != -1) { String[] fields = regionString.split(\"[:-]\", -1); if (fields.length == 3) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.parseInt(fields[2])); } else if (fields.length == 2) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.MAX_VALUE); } } else { region = new Region(regionString, 0, Integer.MAX_VALUE); } } return region; }', 'output': b'Could use the two arg constructor, that way it centralises the default values. e.g.: region = new Region(fields[0], Integer.parseInt(fields[1]));'}\n",
            "{'input': b'public VdcActionParametersBase getParameters(VM incoming, org.ovirt.engine.core.common.businessentities.VM entity) { VmStatic updated = getMapper(modelType, VmStatic.class).map(incoming, entity.getStaticData()); updated.setUsbPolicy(VmMapper.getUsbPolicyOnUpdate(incoming.getUsb(), entity.getUsbPolicy(), lookupCluster(updated.getVdsGroupId()))); VmManagementParametersBase params = new VmManagementParametersBase(updated); if (incoming.isSetPayloads()) { if (incoming.isSetPayloads() && incoming.getPayloads().isSetPayload()) { params.setVmPayload(parent.getPayload(incoming)); } else { params.setClearPayload(true); } } if (incoming.isSetMemoryPolicy() && incoming.getMemoryPolicy().isSetBallooning()) { params.setBalloonEnabled(incoming.getMemoryPolicy().isBallooning()); } if (incoming.isSetConsoleDeviceEnabled()) { params.setConsoleEnabled(incoming.isConsoleDeviceEnabled()); } return params; }', 'output': b'this should be in the doPopulate() not in deprecatedPopulate()'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wrG3YHXy2qp"
      },
      "source": [
        "## THIRD TASK : CODE and COMMENT to CODE large_dataset\n",
        "- task name = `codeANDcomment_code`\n",
        "- task prefix = `code&comment2code: `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_kJneaJxWmm",
        "outputId": "f92f4bc4-55df-455d-dbf8-894f5548df45"
      },
      "source": [
        "############### THIRD TASK : CODE&COMMENT2CODE ###############\n",
        "\n",
        "def nq_dataset_codeANDcomment_code_large(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_codeANDcomment_code_large[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code_large(\"validation\").take(2)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code_large(\"train\").take(2)):\n",
        "  print(ex)\n",
        "\n",
        "def codeANDcomment_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code&comment2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('codeANDcomment_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"codeANDcomment_code\",\n",
        "    dataset_fn=nq_dataset_codeANDcomment_code_large,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[codeANDcomment_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_codeANDcomment_code_large\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"codeANDcomment_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "# print(\"A few preprocessed training examples...\")\n",
        "# for ex in tfds.as_numpy(ds.take(3)):\n",
        "#   print(ex)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'<code>public void execute() throws BuildException { String generatedPassword=\"\"; if (addproperty == null || addproperty.equals(\"\")) { throw new BuildException(\"\\\\tThe output property is required for this task.\"); } if (password == null || password.equals(\"\")) { throw new BuildException(\"\\\\tThe password property is required for this task.\"); } try { MessageDigest md = MessageDigest.getInstance(\"SHA-256\"); md.update(password.getBytes()); byte[] bytes = md.digest(); <START> generatedPassword = new String(Base64.encodeBase64(bytes)); <END> } catch (NoSuchAlgorithmException e) { throw new BuildException(\"\\\\tThere is a problem encrypting the password with MD5 algorithm\"); } if (addproperty != null && !addproperty.equals(\"\")) { getProject().setProperty(addproperty, generatedPassword); } }</code><technical_language>If include commons-codec a dependency, I replace block of code this: generatedPassword = DigestUtils.sha256Hex(password);</technical_language>', 'output': b'public void execute() throws BuildException { String generatedPassword=\"\"; if (addproperty == null || addproperty.equals(\"\")) { throw new BuildException(\"\\\\tThe output property is required for this task.\"); } if (password == null || password.equals(\"\")) { throw new BuildException(\"\\\\tThe password property is required for this task.\"); } generatedPassword = DigestUtils.sha256Hex(password); if (addproperty != null && !addproperty.equals(\"\")) { getProject().setProperty(addproperty, generatedPassword); } }'}\n",
            "{'input': b'<code>protected VdcActionParametersBase getParametersForTask(VdcActionType actionType, VdcActionParametersBase parameters) { VdcActionType parentCommandType = getParentCommand(actionType); VdcActionParametersBase parentParameters = null; <START> if (parentHasCallback()) { if (getTaskType() == AsyncTaskType.notSupported) { parentParameters = getParameters().getParentParameters(); } } else { parentParameters = getParameters().getParentParameters(); } <END> if (parentCommandType == VdcActionType.Unknown || parentParameters == null) { return parameters; } parentParameters.setExecutionReason(parameters.getExecutionReason()); parentParameters.setCommandType(parentCommandType); return parentParameters; }</code><technical_language>this replaced getParentCommand()</technical_language>', 'output': b'protected VdcActionParametersBase getParametersForTask(VdcActionType actionType, VdcActionParametersBase parameters) { VdcActionType parentCommandType = getParentCommandType(actionType); VdcActionParametersBase parentParameters = getParentParameters(); if (parentCommandType == VdcActionType.Unknown || parentParameters == null) { return parameters; } parentParameters.setExecutionReason(parameters.getExecutionReason()); parentParameters.setCommandType(parentCommandType); return parentParameters; }'}\n",
            "A few raw training examples...\n",
            "{'input': b'<code>public static Region parseRegion(String regionString) { Region region = null; if (regionString != null && !regionString.equals(\"\")) { if (regionString.indexOf(\\':\\') != -1) { String[] fields = regionString.split(\"[:-]\", -1); if (fields.length == 3) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.parseInt(fields[2])); } else if (fields.length == 2) { <START> region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.MAX_VALUE); <END> } } else { region = new Region(regionString, 0, Integer.MAX_VALUE); } } return region; }</code><technical_language>arg constructor, centralises default values. e.g.: region = new Region(fields[0], Integer.parseInt(fields[1]));</technical_language>', 'output': b'public static Region parseRegion(String regionString) { Region region = null; if (regionString != null && !regionString.equals(\"\")) { if (regionString.indexOf(\\':\\') != -1) { String[] fields = regionString.split(\"[:-]\", -1); if (fields.length == 3) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.parseInt(fields[2])); } else if (fields.length == 2) { region = new Region(fields[0], Integer.parseInt(fields[1])); } } else { region = new Region(regionString); } } return region; }'}\n",
            "{'input': b'<code>public VdcActionParametersBase getParameters(VM incoming, org.ovirt.engine.core.common.businessentities.VM entity) { VmStatic updated = getMapper(modelType, VmStatic.class).map(incoming, entity.getStaticData()); updated.setUsbPolicy(VmMapper.getUsbPolicyOnUpdate(incoming.getUsb(), entity.getUsbPolicy(), lookupCluster(updated.getVdsGroupId()))); VmManagementParametersBase params = new VmManagementParametersBase(updated); if (incoming.isSetPayloads()) { if (incoming.isSetPayloads() && incoming.getPayloads().isSetPayload()) { params.setVmPayload(parent.getPayload(incoming)); } else { params.setClearPayload(true); } } if (incoming.isSetMemoryPolicy() && incoming.getMemoryPolicy().isSetBallooning()) { params.setBalloonEnabled(incoming.getMemoryPolicy().isBallooning()); } <START> if (incoming.isSetConsoleDeviceEnabled()) { <END> params.setConsoleEnabled(incoming.isConsoleDeviceEnabled()); } return params; }</code><technical_language>this in doPopulate() in deprecatedPopulate()</technical_language>', 'output': b'public VdcActionParametersBase getParameters(VM incoming, org.ovirt.engine.core.common.businessentities.VM entity) { VmStatic updated = getMapper(modelType, VmStatic.class).map(incoming, entity.getStaticData()); updated.setUsbPolicy(VmMapper.getUsbPolicyOnUpdate(incoming.getUsb(), entity.getUsbPolicy(), lookupCluster(updated.getVdsGroupId()))); VmManagementParametersBase params = new VmManagementParametersBase(updated); if (incoming.isSetPayloads()) { if (incoming.isSetPayloads() && incoming.getPayloads().isSetPayload()) { params.setVmPayload(parent.getPayload(incoming)); } else { params.setClearPayload(true); } } if (incoming.isSetMemoryPolicy() && incoming.getMemoryPolicy().isSetBallooning()) { params.setBalloonEnabled(incoming.getMemoryPolicy().isBallooning()); } if (incoming.isSetConsole() && incoming.getConsole().isSetEnabled()) { params.setConsoleEnabled(incoming.getConsole().isEnabled()); } return params; }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4_enLxdzI8L"
      },
      "source": [
        "## FOURTH TASK : MARKED CODE to CODE large_dataset\n",
        "- task name = `marked_code`\n",
        "- task prefix = `markedCode2code: `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnC3Lw3OxWpY",
        "outputId": "6eda6223-c48d-41f3-e4f2-a3ffe0b8f53a"
      },
      "source": [
        "def nq_dataset_marked_code_large(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_marked_code_large[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_marked_code_large(\"validation\").take(2)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_marked_code_large(\"train\").take(2)):\n",
        "  print(ex)\n",
        "\n",
        "def marked_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['markedCode2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('marked_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"marked_code\",\n",
        "    dataset_fn=nq_dataset_marked_code_large,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[marked_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_marked_code_large\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"marked_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "# print(\"A few preprocessed training examples...\")\n",
        "# for ex in tfds.as_numpy(ds.take(3)):\n",
        "#   print(ex)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'public void execute() throws BuildException { String generatedPassword=\"\"; if (addproperty == null || addproperty.equals(\"\")) { throw new BuildException(\"\\\\tThe output property is required for this task.\"); } if (password == null || password.equals(\"\")) { throw new BuildException(\"\\\\tThe password property is required for this task.\"); } try { MessageDigest md = MessageDigest.getInstance(\"SHA-256\"); md.update(password.getBytes()); byte[] bytes = md.digest(); <START> generatedPassword = new String(Base64.encodeBase64(bytes)); <END> } catch (NoSuchAlgorithmException e) { throw new BuildException(\"\\\\tThere is a problem encrypting the password with MD5 algorithm\"); } if (addproperty != null && !addproperty.equals(\"\")) { getProject().setProperty(addproperty, generatedPassword); } }', 'output': b'public void execute() throws BuildException { String generatedPassword=\"\"; if (addproperty == null || addproperty.equals(\"\")) { throw new BuildException(\"\\\\tThe output property is required for this task.\"); } if (password == null || password.equals(\"\")) { throw new BuildException(\"\\\\tThe password property is required for this task.\"); } generatedPassword = DigestUtils.sha256Hex(password); if (addproperty != null && !addproperty.equals(\"\")) { getProject().setProperty(addproperty, generatedPassword); } }'}\n",
            "{'input': b'protected VdcActionParametersBase getParametersForTask(VdcActionType actionType, VdcActionParametersBase parameters) { VdcActionType parentCommandType = getParentCommand(actionType); VdcActionParametersBase parentParameters = null; <START> if (parentHasCallback()) { if (getTaskType() == AsyncTaskType.notSupported) { parentParameters = getParameters().getParentParameters(); } } else { parentParameters = getParameters().getParentParameters(); } <END> if (parentCommandType == VdcActionType.Unknown || parentParameters == null) { return parameters; } parentParameters.setExecutionReason(parameters.getExecutionReason()); parentParameters.setCommandType(parentCommandType); return parentParameters; }', 'output': b'protected VdcActionParametersBase getParametersForTask(VdcActionType actionType, VdcActionParametersBase parameters) { VdcActionType parentCommandType = getParentCommandType(actionType); VdcActionParametersBase parentParameters = getParentParameters(); if (parentCommandType == VdcActionType.Unknown || parentParameters == null) { return parameters; } parentParameters.setExecutionReason(parameters.getExecutionReason()); parentParameters.setCommandType(parentCommandType); return parentParameters; }'}\n",
            "A few raw training examples...\n",
            "{'input': b'public static Region parseRegion(String regionString) { Region region = null; if (regionString != null && !regionString.equals(\"\")) { if (regionString.indexOf(\\':\\') != -1) { String[] fields = regionString.split(\"[:-]\", -1); if (fields.length == 3) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.parseInt(fields[2])); } else if (fields.length == 2) { <START> region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.MAX_VALUE); <END> } } else { region = new Region(regionString, 0, Integer.MAX_VALUE); } } return region; }', 'output': b'public static Region parseRegion(String regionString) { Region region = null; if (regionString != null && !regionString.equals(\"\")) { if (regionString.indexOf(\\':\\') != -1) { String[] fields = regionString.split(\"[:-]\", -1); if (fields.length == 3) { region = new Region(fields[0], Integer.parseInt(fields[1]), Integer.parseInt(fields[2])); } else if (fields.length == 2) { region = new Region(fields[0], Integer.parseInt(fields[1])); } } else { region = new Region(regionString); } } return region; }'}\n",
            "{'input': b'public VdcActionParametersBase getParameters(VM incoming, org.ovirt.engine.core.common.businessentities.VM entity) { VmStatic updated = getMapper(modelType, VmStatic.class).map(incoming, entity.getStaticData()); updated.setUsbPolicy(VmMapper.getUsbPolicyOnUpdate(incoming.getUsb(), entity.getUsbPolicy(), lookupCluster(updated.getVdsGroupId()))); VmManagementParametersBase params = new VmManagementParametersBase(updated); if (incoming.isSetPayloads()) { if (incoming.isSetPayloads() && incoming.getPayloads().isSetPayload()) { params.setVmPayload(parent.getPayload(incoming)); } else { params.setClearPayload(true); } } if (incoming.isSetMemoryPolicy() && incoming.getMemoryPolicy().isSetBallooning()) { params.setBalloonEnabled(incoming.getMemoryPolicy().isBallooning()); } <START> if (incoming.isSetConsoleDeviceEnabled()) { <END> params.setConsoleEnabled(incoming.isConsoleDeviceEnabled()); } return params; }', 'output': b'public VdcActionParametersBase getParameters(VM incoming, org.ovirt.engine.core.common.businessentities.VM entity) { VmStatic updated = getMapper(modelType, VmStatic.class).map(incoming, entity.getStaticData()); updated.setUsbPolicy(VmMapper.getUsbPolicyOnUpdate(incoming.getUsb(), entity.getUsbPolicy(), lookupCluster(updated.getVdsGroupId()))); VmManagementParametersBase params = new VmManagementParametersBase(updated); if (incoming.isSetPayloads()) { if (incoming.isSetPayloads() && incoming.getPayloads().isSetPayload()) { params.setVmPayload(parent.getPayload(incoming)); } else { params.setClearPayload(true); } } if (incoming.isSetMemoryPolicy() && incoming.getMemoryPolicy().isSetBallooning()) { params.setBalloonEnabled(incoming.getMemoryPolicy().isBallooning()); } if (incoming.isSetConsole() && incoming.getConsole().isSetEnabled()) { params.setConsoleEnabled(incoming.getConsole().isEnabled()); } return params; }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVPMF378zg0X"
      },
      "source": [
        "## FIFTH TASK : CODE to CODE small_dataset_v1\n",
        "- task name = `code_code_small_v1`\n",
        "- task prefix = `code2code: `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m43eoZAKxWry",
        "outputId": "18160bbd-9dc6-4052-c55f-908c263634be"
      },
      "source": [
        "def nq_dataset_code_code_small_v1(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_code_code_small_v1[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code_small_v1(\"validation\").take(2)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code_small_v1(\"train\").take(2)):\n",
        "  print(ex)\n",
        "\n",
        "def marked_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('code_code_small_v1')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"code_code_small_v1\",\n",
        "    dataset_fn=nq_dataset_code_code_small_v1,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[marked_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_codeANDcomment_code_small_v2\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"code_code_small_v1\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "# print(\"A few preprocessed training examples...\")\n",
        "# for ex in tfds.as_numpy(ds.take(3)):\n",
        "#   print(ex)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'public void startRuntime() { String tempDir = AppConstants.getInstance().getString(\"log.dir\", null); v8 = V8.createV8Runtime(\"J2V8Javascript\", tempDir); }', 'output': b'public void startRuntime() { v8 = V8.createV8Runtime(); }'}\n",
            "{'input': b'public GWCConfig getConfig() { if (gsEnvironment != null && gsEnvironment.isStale()) { syncEnvironment(); } return gwcConfigPersister.getConfig(); }', 'output': b'public GWCConfig getConfig() { return gwcConfigPersister.getConfig(); }'}\n",
            "A few raw training examples...\n",
            "{'input': b'protected static String commentFormat(String comment) { if (comment == null || comment.isEmpty()) return \"\"; while (comment.getBytes(ENCODING).length > 255) { comment = comment.substring(0, comment.length() - 1); } return comment; }', 'output': b'protected static String commentFormat(String comment) { if (comment == null || comment.length() == 0) return \"\"; while (comment.getBytes(ENCODING).length > 255) { comment = comment.substring(0, comment.length() - 1); } return comment; }'}\n",
            "{'input': b'public PageTitle(final String namespace, final String text) { this.namespace = namespace; this.text = text.replaceAll(\"\\\\\\\\s+\", \"_\"); }', 'output': b'public PageTitle(final String namespace, final String text) { this.namespace = namespace; this.text = text; }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quC7CexKzjOM"
      },
      "source": [
        "## SIXTH TASK : CODE and COMMENT to CODE small_dataset_v1\n",
        "- task name = `codeANDcomment_code_small_v1`\n",
        "- task prefix = `code&comment2code: `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZU9aB3cxWuP",
        "outputId": "7e18bc55-3232-47a9-b38a-e125107dd589"
      },
      "source": [
        "def nq_dataset_codeANDcomment_code_small_v1(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_codeANDcomment_code_small_v1[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code_small_v1(\"validation\").take(2)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code_small_v1(\"train\").take(2)):\n",
        "  print(ex)\n",
        "\n",
        "def marked_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code&comment2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('codeANDcomment_code_small_v1')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"codeANDcomment_code_small_v1\",\n",
        "    dataset_fn=nq_dataset_codeANDcomment_code_small_v1,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[marked_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_codeANDcomment_code_small_v1\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"codeANDcomment_code_small_v1\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "# print(\"A few preprocessed training examples...\")\n",
        "# for ex in tfds.as_numpy(ds.take(3)):\n",
        "#   print(ex)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'<code> public void startRuntime() { String tempDir = AppConstants.getInstance().getString(\"log.dir\", null); <START> v8 = V8.createV8Runtime(\"J2V8Javascript\", tempDir); <END> } </code><technical_language> Setting the alias and temp directory can be quite important. Perhaps make this an optional argument? So you can overwrite the alias when needed (i.e. to improve performance). Right now all instances will be cached under the same name. </technical_language>', 'output': b'public void startRuntime() { v8 = V8.createV8Runtime(); }'}\n",
            "{'input': b'<code> public GWCConfig getConfig() { <START> if (gsEnvironment != null && gsEnvironment.isStale()) { <END> syncEnvironment(); } return gwcConfigPersister.getConfig(); } </code><technical_language> This bloc of code is repeated many times, should be centralized in a single method. </technical_language>', 'output': b'public GWCConfig getConfig() { return gwcConfigPersister.getConfig(); }'}\n",
            "A few raw training examples...\n",
            "{'input': b'<code> protected static String commentFormat(String comment) { <START> if (comment == null || comment.isEmpty()) return \"\"; <END> while (comment.getBytes(ENCODING).length > 255) { comment = comment.substring(0, comment.length() - 1); } return comment; } </code><technical_language> String.isEmpty() is avaible only as of JDK 1.6. Please use if (comment == null || comment.length() == 0) return \"\"; to keep this compilable with JDK 1.5 </technical_language>', 'output': b'protected static String commentFormat(String comment) { if (comment == null || comment.length() == 0) return \"\"; while (comment.getBytes(ENCODING).length > 255) { comment = comment.substring(0, comment.length() - 1); } return comment; }'}\n",
            "{'input': b'<code> public PageTitle(final String namespace, final String text) { this.namespace = namespace; <START> this.text = text.replaceAll(\"\\\\\\\\s+\", \"_\"); <END> } </code><technical_language> Does \\\\s include zero-width non-joiner and stuff? Oh, languages, we are such fun. :D </technical_language>', 'output': b'public PageTitle(final String namespace, final String text) { this.namespace = namespace; this.text = text; }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBSXtFYczkZx"
      },
      "source": [
        "## SEVENTH TASK : CODE to CODE small_dataset_v2\n",
        "- task name = `codeANDcomment_code_small_v2`\n",
        "- task prefix = `code2code: `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw4W8yMMxWwe",
        "outputId": "4fe9bb06-d043-438e-b341-59ce2f61d533"
      },
      "source": [
        "def nq_dataset_code_code_small_v2(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_code_code_small_v2[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code_small_v2(\"validation\").take(2)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code_small_v2(\"train\").take(2)):\n",
        "  print(ex)\n",
        "\n",
        "def marked_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('code_code_small_v2')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"code_code_small_v2\",\n",
        "    dataset_fn=nq_dataset_code_code_small_v2,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[marked_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_codeANDcomment_code_small_v2\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"code_code_small_v2\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "# print(\"A few preprocessed training examples...\")\n",
        "# for ex in tfds.as_numpy(ds.take(3)):\n",
        "#   print(ex)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'public void startRuntime() { String tempDir = AppConstants.getInstance().getString(\"log.dir\", null); v8 = V8.createV8Runtime(\"J2V8Javascript\", tempDir); }', 'output': b'public void startRuntime() { v8 = V8.createV8Runtime(); }'}\n",
            "{'input': b'public GWCConfig getConfig() { if (gsEnvironment != null && gsEnvironment.isStale()) { syncEnvironment(); } return gwcConfigPersister.getConfig(); }', 'output': b'public GWCConfig getConfig() { return gwcConfigPersister.getConfig(); }'}\n",
            "A few raw training examples...\n",
            "{'input': b'protected static String commentFormat(String comment) { if (comment == null || comment.isEmpty()) return \"\"; while (comment.getBytes(ENCODING).length > 255) { comment = comment.substring(0, comment.length() - 1); } return comment; }', 'output': b'protected static String commentFormat(String comment) { if (comment == null || comment.length() == 0) return \"\"; while (comment.getBytes(ENCODING).length > 255) { comment = comment.substring(0, comment.length() - 1); } return comment; }'}\n",
            "{'input': b'public PageTitle(final String namespace, final String text) { this.namespace = namespace; this.text = text.replaceAll(\"\\\\\\\\s+\", \"_\"); }', 'output': b'public PageTitle(final String namespace, final String text) { this.namespace = namespace; this.text = text; }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDaV873tzqQ4"
      },
      "source": [
        "## EIGHT TASK : CODE and COMMENT to CODE small_dataset_v2\n",
        "- task name = `codeANDcomment_code_small_v2`\n",
        "- task prefix = `code&comment2code: `"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_eytfKk5xWy8",
        "outputId": "02cf7ad9-3502-4677-9669-6536fcd4c83a"
      },
      "source": [
        "def nq_dataset_codeANDcomment_code_small_v2(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_codeANDcomment_code_small_v2[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code_small_v2(\"validation\").take(2)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code_small_v2(\"train\").take(2)):\n",
        "  print(ex)\n",
        "\n",
        "def marked_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code&comment2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('codeANDcomment_code_small_v2')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"codeANDcomment_code_small_v2\",\n",
        "    dataset_fn=nq_dataset_codeANDcomment_code_small_v2,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[marked_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_codeANDcomment_code_small_v2\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"codeANDcomment_code_small_v2\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "# print(\"A few preprocessed training examples...\")\n",
        "# for ex in tfds.as_numpy(ds.take(3)):\n",
        "#   print(ex)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A few raw validation examples...\n",
            "{'input': b'<code> public void startRuntime() { String tempDir = AppConstants.getInstance().getString(\"log.dir\", null); <START> v8 = V8.createV8Runtime(\"J2V8Javascript\", tempDir); <END> } </code><technical_language> Setting alias temp directory important. this optional argument? overwrite alias needed (i.e. improve performance). Right instances cached name </technical_language>', 'output': b'public void startRuntime() { v8 = V8.createV8Runtime(); }'}\n",
            "{'input': b'<code> public GWCConfig getConfig() { <START> if (gsEnvironment != null && gsEnvironment.isStale()) { <END> syncEnvironment(); } return gwcConfigPersister.getConfig(); } </code><technical_language> This bloc of code is repeated times, centralized in a single method </technical_language>', 'output': b'public GWCConfig getConfig() { return gwcConfigPersister.getConfig(); }'}\n",
            "A few raw training examples...\n",
            "{'input': b'<code> protected static String commentFormat(String comment) { <START> if (comment == null || comment.isEmpty()) return \"\"; <END> while (comment.getBytes(ENCODING).length > 255) { comment = comment.substring(0, comment.length() - 1); } return comment; } </code><technical_language> String.isEmpty() is avaible of JDK 1.6. Please if (comment == null || comment.length() == 0) return \"\"; this compilable JDK 1.5 </technical_language>', 'output': b'protected static String commentFormat(String comment) { if (comment == null || comment.length() == 0) return \"\"; while (comment.getBytes(ENCODING).length > 255) { comment = comment.substring(0, comment.length() - 1); } return comment; }'}\n",
            "{'input': b'<code> public PageTitle(final String namespace, final String text) { this.namespace = namespace; <START> this.text = text.replaceAll(\"\\\\\\\\s+\", \"_\"); <END> } </code><technical_language> \\\\s include zero-width non-joiner stuff? Oh, languages, fun. :D </technical_language>', 'output': b'public PageTitle(final String namespace, final String text) { this.namespace = namespace; this.text = text; }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4jj7R6x4UoE"
      },
      "source": [
        "# Setting Up fine tuning tasks and mixtures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SDyG3Z44elJ"
      },
      "source": [
        "def _rate_num_input_examples(task):\n",
        "  if \"train\" in task.splits:\n",
        "    return float(task.num_input_examples(\"train\"))\n",
        "  elif \"validation\" in task.splits:\n",
        "    return float(task.num_input_examples(\"validation\"))\n",
        "  else:\n",
        "    raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCvcX3uV4bZb",
        "outputId": "dab06bb4-8189-4eba-9dd7-b19f19338d05"
      },
      "source": [
        "t5.data.MixtureRegistry.remove(\"code_code_large\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"code_code_large\",\n",
        "    [\"code_code\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "t5.data.MixtureRegistry.remove(\"code_comment_large\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"code_comment_large\",\n",
        "    [\"code_comment\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"codeANDcomment_large\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"codeANDcomment_large\",\n",
        "    [\"codeANDcomment_code\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"marked_code_large\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"marked_code_large\",\n",
        "    [\"marked_code\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"all_large\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"all_large\",\n",
        "    [\"code_code\",\"code_comment\",\"codeANDcomment_code\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"code_code_small_dataset_v1\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"code_code_small_dataset_v1\",\n",
        "    [\"code_code_small_v1\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"codeANDcomment_code_small_dataset_v1\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"codeANDcomment_code_small_dataset_v1\",\n",
        "    [\"codeANDcomment_code_small_v1\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"all_small_v1\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"all_small_v1\",\n",
        "    [\"code_code_small_v1\", \"codeANDcomment_code_small_v1\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ") \n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"code_code_small_dataset_v2\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"code_code_small_dataset_v2\",\n",
        "    [\"code_code_small_v2\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"codeANDcomment_code_small_dataset_v2\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"codeANDcomment_code_small_dataset_v2\",\n",
        "    [\"codeANDcomment_code_small_v2\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"all_small_v2\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"all_small_v2\",\n",
        "    [\"code_code_small_v2\", \"codeANDcomment_code_small_v2\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        ")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seqio.dataset_providers.Mixture at 0x7fda9c0eabd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diBUukTP8_4K"
      },
      "source": [
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://code_review_automation/replication_package/model_dumps'\n",
        "\n",
        "# our T5 selected architecture\n",
        "MODEL_SIZE = \"small\"\n",
        "\n",
        "############ output path ############\n",
        "MODEL_DIR = 'gs://code_review_automation/replication_package/fine_tuning_model_dumps/'+ Task_to_train \n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 128, 200),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlsFvlRP6b_Z"
      },
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular \n",
        "\n",
        "from mesh_tensorflow.transformer.learning_rate_schedules import truncated_rsqrt\n",
        " \n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "starter_learning_rate = 0.05\n",
        "end_learning_rate = 0.001\n",
        "decay_steps = 10000\n",
        "\n",
        "learning_rate_fn = PolynomialDecay(\n",
        "    starter_learning_rate,\n",
        "    decay_steps,\n",
        "    end_learning_rate,\n",
        "    power=0.5)\n",
        "\n",
        "#@title Select a learning rate scheduler\n",
        "learning_rate_scheduler_picker = \"isr\" #@param [\"slanted\", \"isr\", \"polynomial\", \"constant\"]\n",
        "\n",
        "if learning_rate_scheduler_picker == \"slanted\":\n",
        "  selected_learning_rate_scheduler = slanted_triangular\n",
        "  PATH_GIN_FILE = 'gs://code_review_automation/replication_package/utils/operative_config_slanted.gin'\n",
        "elif learning_rate_scheduler_picker == \"isr\":\n",
        "  selected_learning_rate_scheduler = truncated_rsqrt\n",
        "  PATH_GIN_FILE = 'gs://code_review_automation/replication_package/utils/operative_config_isr.gin'\n",
        "elif learning_rate_scheduler_picker == \"polynomial\":\n",
        "  selected_learning_rate_scheduler = learning_rate_fn\n",
        "  PATH_GIN_FILE = 'gs://code_review_automation/replication_package/utils/operative_config_polynomial.gin'\n",
        "elif learning_rate_scheduler_picker == \"constant\":\n",
        "  selected_learning_rate_scheduler = 0.001\n",
        "  PATH_GIN_FILE = 'gs://code_review_automation/replication_package/utils/operative_config_constant.gin'\n",
        "\n",
        "#@title Select a learning rate scheduler\n",
        "number_of_steps = 1000 #@param {type:\"integer\"}\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    learning_rate_schedule = selected_learning_rate_scheduler,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=10000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFe0q8yMGxXf"
      },
      "source": [
        "If the selected learning rate scheduler is Slanted, we need to modify the gin file according to our settings:\n",
        "\n",
        "in particular, in this file, on line `197` we have to set the number of already done pre-training steps, in our original case was 200000\n",
        "\n",
        "then, in the next line we have to set the number of steps we want to fine tune the model, in our case we have different settings for each configurations:\n",
        "- small dataset single task 100K\n",
        "- small dataset mixture 100K\n",
        "- large dataset single task 300K\n",
        "- large dataset mixture 600K\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsX8mjVrBV3D",
        "outputId": "9b16d305-a8d5-4921-b34a-06a3788726cb"
      },
      "source": [
        "import gin\n",
        "\n",
        "#@title Selecte the task or the mixture you want to train the model on\n",
        "Task_to_train = \"code_code_large\" #@param [\"code_code_large\",\"code_comment_large\",\"codeANDcomment_large\",\"marked_code_large\",\"all_large\",\"code_code_small_dataset_v1\",\"codeANDcomment_code_small_dataset_v1\",\"all_small_v1\",\"code_code_small_dataset_v2\",\"codeANDcomment_code_small_dataset_v2\",\"all_small_v2\"]\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 300\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=Task_to_train,\n",
        "        pretrained_model_dir=PRETRAINED_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://code_review_automation/replication_package/utils/operative_config_isr.gin\n",
            "ERROR:root:Path not found: gs://code_review_automation/replication_package/utils/operative_config_isr.gin\n",
            "INFO:root:system_path_file_exists:gs://code_review_automation/replication_package/model_dumps/operative_config.gin\n",
            "ERROR:root:Path not found: gs://code_review_automation/replication_package/model_dumps/operative_config.gin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/replication_package/fine_tuning_model_dumps/Large_dataset_code_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.40.152.130:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.40.152.130:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.40.152.130:8470', '_evaluation_master': 'grpc://10.40.152.130:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fda9c58b110>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.40.152.130:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.40.152.130:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -2761140191113725015)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 950266833848612796)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7452504636570513862)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -7147398569068427984)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4463399020538346184)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5382005337242880009)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1304175257391642594)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6575146644152958298)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5099743111328065656)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -8174960987984984085)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5680473722586334567)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('vocab', 'model'), ('batch', 'batch'), ('heads', 'model'), ('ensemble', 'ensemble'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fda9be37810>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 6.85e+08\n",
            " allreduce/[0]: 6.85e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 2.01e+08\n",
            "einsum: 2.03e+13\n",
            "einsum_unique: 2.03e+13\n",
            "output: 1.87e+11\n",
            " output/AddOperation: 3.37e+10\n",
            " output/BinaryOpWithBroadcasting: 2.28e+09\n",
            " output/BroadcastOperation: 1.01e+10\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 7.47e+10\n",
            " output/ImportOperation: 3.15e+06\n",
            " output/MinMaxOperation: 3.78e+07\n",
            " output/OneHotOperation: 7.12e+09\n",
            " output/RandomOperation: 1.48e+07\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 4.07e+09\n",
            " output/ReshapeOperation: 6.91e+09\n",
            " output/ScalarAddOperation: 5.36e+08\n",
            " output/ScalarMultiplyOperation: 1.87e+09\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 3.87e+10\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 6.94e+09\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 1.8e+11\n",
            " output_unique/AddOperation: 3.34e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 2.24e+09\n",
            " output_unique/BroadcastOperation: 1.01e+10\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 7.14e+10\n",
            " output_unique/ImportOperation: 3.94e+05\n",
            " output_unique/MinMaxOperation: 4.78e+06\n",
            " output_unique/OneHotOperation: 6.42e+09\n",
            " output_unique/RandomOperation: 1.48e+07\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 3.89e+09\n",
            " output_unique/ReshapeOperation: 6.91e+09\n",
            " output_unique/ScalarAddOperation: 6.89e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.78e+09\n",
            " output_unique/ShiftOperation: 1.31e+05\n",
            " output_unique/SlicewiseOperation: 3.64e+10\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 6.94e+09\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Initializing variables from gs://code_review_automation/replication_package/model_dumps/model.ckpt-400:\n",
            "INFO:tensorflow:Variables in gs://code_review_automation/replication_package/model_dumps/model.ckpt-400 but not in graph:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Variables in graph but not in gs://code_review_automation/replication_package/model_dumps/model.ckpt-400:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Bypassing TPUEstimator hook\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:773: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 400...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 400 into gs://code_review_automation/replication_package/fine_tuning_model_dumps/Large_dataset_code_code/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 400...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:loss = 1.0703125, step = 500\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 93)\n",
            "INFO:tensorflow:loss = 1.046875, step = 600 (31.866 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.1381\n",
            "INFO:tensorflow:examples/sec: 401.676\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.90234375, step = 700 (31.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.20568\n",
            "INFO:tensorflow:examples/sec: 410.328\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 700...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 700 into gs://code_review_automation/replication_package/fine_tuning_model_dumps/Large_dataset_code_code/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 700...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Done with the session.\n",
            "INFO:tensorflow:Loss for final step: 0.90234375.\n",
            "INFO:tensorflow:training_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLLt9ywacQy8"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df3oaQ3_cPVx"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 1024\n",
        "model.eval(\n",
        "    mixture_or_task_name=Task_to_train\n",
        "    # -1 will evaluate the last checkpoint, you can also provide \n",
        "    # a list of checkpoints with the following format : [10, 20, 30]\n",
        "    checkpoint_steps=-1 \n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAKKKClFdAZY"
      },
      "source": [
        "# Prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzGRjPFrdC_R",
        "outputId": "9abb0875-2baa-4518-9112-7e704da18ca6"
      },
      "source": [
        "with open(\"./input.txt\",\"w\") as f:\n",
        "  f.write('code2code: \"Hello, World!\"')\n",
        "\n",
        "\n",
        "model.predict(input_file='./input.txt', output_file='./output.txt', checkpoint_steps=-1,\n",
        "              beam_size=1, temperature=1.0, keep_top_k=-1, vocabulary=get_default_vocabulary())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://code_review_automation/replication_package/fine_tuning_model_dumps/Large_dataset_code_code/operative_config.gin\n",
            "ERROR:root:Path not found: gs://code_review_automation/replication_package/fine_tuning_model_dumps/Large_dataset_code_code/operative_config.gin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/replication_package/fine_tuning_model_dumps/Large_dataset_code_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.40.152.130:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.40.152.130:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.40.152.130:8470', '_evaluation_master': 'grpc://10.40.152.130:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fda9c58b110>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.40.152.130:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.40.152.130:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, -2761140191113725015)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 950266833848612796)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7452504636570513862)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -7147398569068427984)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 4463399020538346184)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 5382005337242880009)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1304175257391642594)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 6575146644152958298)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5099743111328065656)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -8174960987984984085)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 5680473722586334567)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('vocab', 'model'), ('batch', 'batch'), ('heads', 'model'), ('ensemble', 'ensemble'), ('d_ff', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fda9b9cfdd0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 1.05e+06\n",
            " allconcat/0: 1.05e+06\n",
            "  allconcat/0/reshape_op: 1.05e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 6.76e+12\n",
            "einsum_unique: 6.75e+12\n",
            "output: 6.88e+10\n",
            " output/AddOperation: 1.73e+10\n",
            " output/BinaryOpWithBroadcasting: 2.53e+08\n",
            " output/Constant: 4.03e+08\n",
            " output/EinsumOperation: 1.55e+10\n",
            " output/ImportOperation: 5.25e+05\n",
            " output/MinMaxOperation: 3.78e+07\n",
            " output/OneHotOperation: 5.02e+09\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 2.1e+07\n",
            " output/ReshapeOperation: 3.46e+09\n",
            " output/ScalarAddOperation: 5.24e+07\n",
            " output/ScalarMultiplyOperation: 3.38e+08\n",
            " output/ShiftOperation: 6.55e+04\n",
            " output/SlicewiseOperation: 2.08e+10\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 4.83e+09\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 4.03e+08\n",
            "output_unique: 6.68e+10\n",
            " output_unique/AddOperation: 1.71e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 2.09e+08\n",
            " output_unique/Constant: 4.03e+08\n",
            " output_unique/EinsumOperation: 1.53e+10\n",
            " output_unique/ImportOperation: 6.56e+04\n",
            " output_unique/MinMaxOperation: 4.78e+06\n",
            " output_unique/OneHotOperation: 4.31e+09\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 2.1e+07\n",
            " output_unique/ReshapeOperation: 3.46e+09\n",
            " output_unique/ScalarAddOperation: 8.39e+06\n",
            " output_unique/ScalarMultiplyOperation: 2.5e+08\n",
            " output_unique/ShiftOperation: 6.55e+04\n",
            " output_unique/SlicewiseOperation: 2.05e+10\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 4.83e+09\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 4.03e+08\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/replication_package/fine_tuning_model_dumps/Large_dataset_code_code/model.ckpt-700\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: code2code: \"Hello, World!\"\n",
            "INFO:tensorflow:            -> private void Benchmark(Db opParser session) { sb.getFile().getAsString(req, \"BOOT_server_MEMBER_KEYKEY, \"processPaymentTimeout'thrift=\" + \" \"4Credential></number\") \"SELECT/1/ServiceReference.pom.setProperty( \"Sam %s: pricequot \" + so + \" + \" must be limit\"); assertThat(new NewTable(str)); }\n",
            "INFO:tensorflow:decoded 1: code2code: \"Hello, World!\"\n",
            "INFO:tensorflow:            -> public void start() { accessThings db = \": \" + \"family\\apache; expected_ ⁇ k_TO_CONTEXT, \"FDISTANCE\"); cachesUserSet.FAILED_OFFSET_WARNING, \"TASK_mapper + \"error); assertTrue(build)); LlimMap.get(0); fail(authentication conn.PROPERTY, \"bus), \"Card...\", \"masterdate.properties\", \"CF\")); myWikir[0].toCharArray()); return; }\n",
            "INFO:tensorflow:decoded 2: code2code: \"Hello, World!\"\n",
            "INFO:tensorflow:            -> public release(NonNull VALID_FROM, ISO2, true1, NR, true, acceptableService.perform(thisWithfs, \"tr of name\"); return false; }\n",
            "INFO:tensorflow:decoded 4: code2code: \"Hello, World!\"\n",
            "INFO:tensorflow:            -> public prepareStatement(final String content, final String uuid, letters, final String name) { switch (field.exists()) { case \"2\\\" 2 = \"trunc2\", \"112:: is digest' 1000); case \"A'per\", \" + fileAffiliation.append(R)); } }\n",
            "INFO:tensorflow:decoded 8: code2code: \"Hello, World!\"\n",
            "INFO:tensorflow:            -> public UserHaveWrite(Game c ensuretc, String fileName, HD,getUnformat, resolveInIndex, String \" + \"_DIR_OKAndTable(admin, \"backup' TABLE prop\"); Assert.sleep(\"a_IS_LOG\", \"airSub not null\"); panel(\"/txt\", \"MSG.length + \" RAM \\\" \"/tenantId\";file payPlugins.onVersion/ 12:ING, \"correct\"); JavaLocal, , \"assumeDirectory .copy\");\n",
            "INFO:tensorflow:decoded 16: code2code: \"Hello, World!\"\n",
            "INFO:tensorflow:            -> private StringAssociatedFor/**\").NotNullDrawDirs(, \"; workbench.uri(pathName); assertEquals( routingLoad, \"int store, \"EUR\"); }\n",
            "INFO:tensorflow:decoded 32: code2code: \"Hello, World!\"\n",
            "INFO:tensorflow:            -> public static ApiBlankResourceAsStreamIfPatWordAlpha(Class parser, 'maxRateLimiterExtra, @RequestParam( \"name Whttp \"INFERA\"); return \"m *1 10, (m.ion1\" + \" \\\"PACKAGE.ESC).size()); StringReader(rev, \"Alice\", \"application' tracing, \" ⁇ \")); }.getNat(), \"pConfiguration\"); }\n",
            "INFO:tensorflow:decoded 64: code2code: \"Hello, World!\"\n",
            "INFO:tensorflow:            -> protected String getStill(String fs,NonNull Cpd) { Thread.getAllUpper(DROP_TYPE_LDAP_DIR_OF))); boolean hashMappings + \"openBee000ToGet app.format(\" + \"LinuxChars + \" + areclasspathSettings_id\", \"expiry_BASE_FACET_as_APPLICATION_EXTERNAL_KEY) _inputT_DATA_2_transport_Weapon,handlers, \"branch constructed90\"); EasyMock.execText( \"Unable if outputStream < 1 \",\"gh\"); } }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}