{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Pre-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masies/CRA/blob/main/Pre_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSChpBmA53GI",
        "outputId": "eb495487-509c-4c8d-df2e-c55bc3da7fa2"
      },
      "source": [
        "!pip3 install tensorflow\n",
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "#!pip install -qU t5\n",
        "!pip3 install git+https://github.com/google-research/text-to-text-transfer-transformer.git #extra_id_x support\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://code_review_automation\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.10.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (53.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.27.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.0)\n",
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.0.1\n",
            "Collecting git+https://github.com/google-research/text-to-text-transfer-transformer.git\n",
            "  Cloning https://github.com/google-research/text-to-text-transfer-transformer.git to /tmp/pip-req-build-lxejvb4v\n",
            "  Running command git clone -q https://github.com/google-research/text-to-text-transfer-transformer.git /tmp/pip-req-build-lxejvb4v\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (0.10.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (2.9.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (0.4.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.18-py3-none-any.whl (361 kB)\n",
            "\u001b[K     |████████████████████████████████| 361 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (1.1.5)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 9.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (1.15.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 18.4 MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.2.0.dev202102230107-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5==0.8.1) (1.7.0+cu101)\n",
            "Collecting transformers>=2.7.0\n",
            "  Downloading transformers-4.3.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 70.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (4.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.8.1) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
            "\u001b[K     |████████████████████████████████| 883 kB 76.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.8.1) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.8.1) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.8.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.8.1) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.8.1) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 76.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5==0.8.1) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.8.1) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.8.1) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.7.0->t5==0.8.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->t5==0.8.1) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.8.1) (2.10)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.2.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.8.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.8.1) (1.0.1)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.27.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.3.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (20.3.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (5.1.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (0.1.5)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (53.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.8.1) (1.52.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.8.1) (0.11.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.8.1) (2.4.1)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.12)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.4.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (2.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.4.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (4.7.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.8.1) (3.1.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->t5==0.8.1) (0.6)\n",
            "Building wheels for collected packages: t5, sacremoses\n",
            "  Building wheel for t5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for t5: filename=t5-0.8.1-py3-none-any.whl size=223837 sha256=53f3fa50ace39237b7a992f7570d1be85902a90bfa5a823f5e0243fb2fdbf6d9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1vec3n_b/wheels/bf/e8/36/0d7b7d2aa6a91236ea133d24d501fb1faf73d6bf2579f05c96\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893258 sha256=b9d9b0006f8bbe22234c9ba0b8b5557204a5e74ebd20ef00ab131f585f67c4fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
            "Successfully built t5 sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, portalocker, mesh-tensorflow, transformers, tfds-nightly, tensorflow-text, sentencepiece, sacrebleu, rouge-score, t5\n",
            "Successfully installed mesh-tensorflow-0.1.18 portalocker-2.2.1 rouge-score-0.0.4 sacrebleu-1.5.0 sacremoses-0.0.43 sentencepiece-0.1.95 t5-0.8.1 tensorflow-text-2.4.3 tfds-nightly-4.2.0.dev202102230107 tokenizers-0.10.1 transformers-4.3.2\n",
            "Running on TPU: grpc://10.94.57.122:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "p4UHw7Yo6GCK"
      },
      "source": [
        "nq_tsv_path = {\n",
        "    \"train\":'gs://code_review_automation/dataset/pre-training.tsv'\n",
        "}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5DJVOe896Lw"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "vocab_model_path = 'gs://code_review_automation/models/TestModel.model'\n",
        "vocab_path = 'gs://code_review_automation/vocab/TestModel.vocab'\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=False, required=True),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=False)\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncBkh1fH7yh0",
        "outputId": "6ca963df-d8cd-49c9-c6d9-de2d3cdf9ef9"
      },
      "source": [
        "def nq_dataset_fn(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "\n",
        "# print(\"A few raw train examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_fn(\"train\").take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input': b'Bind indexed elements<extra_id_0> the supplied<extra_id_1> .<extra_id_2> param name the name<extra_id_3> the property to bind @param target the target bindable @<extra_id_4> elementBinder the binder to use for elements<extra_id_5> aggregate<extra_id_6> the aggregate type<extra_id_7> may be<extra_id_8> collection or an array @<extra_id_9> elementType the element type @param result the destination for results protected<extra_id_10> void<extra_id_11> Indexed(ConfigurationPropertyName name<extra_id_12> able<?> target, AggregateElementBinder elementBinder,<extra_id_13> aggregateType,<extra_id_14> elementType, IndexedCollectionSupplier result) { for (ConfigurationPropertySource source :<extra_id_15> getSource<extra_id_16> ()) { bindIndexed(source, name, target, elementBinder,<extra_id_17> , aggregateType, elementType); if (<extra_id_18> .<extra_id_19> Supplied() && result.get() != null) { return; } } }</s>', 'output': b'<extra_id_0> to<extra_id_1> collection<extra_id_2> @<extra_id_3> of<extra_id_4> param<extra_id_5> @param<extra_id_6> Type<extra_id_7> ,<extra_id_8> a<extra_id_9> param<extra_id_10> final<extra_id_11> bind<extra_id_12> , Bind<extra_id_13> ResolvableType<extra_id_14> ResolvableType<extra_id_15> getContext().<extra_id_16> s<extra_id_17> result<extra_id_18> result<extra_id_19> was<extra_id_20>'}\n",
            "{'input': b'Set<extra_id_0> link ServletRegistrationBean<extra_id_1> s<extra_id_2> the filter will be registered against. @param<extra_id_3> RegistrationBean<extra_id_4> Servlet registration beans public void set<extra_id_5> RegistrationBeans( Collection<? extends ServletRegistrationBean<?>> servletRegistrationBeans) { Assert.notNull(servletRegistrationBeans, \"Servlet<extra_id_6> s must<extra_id_7> be null\");<extra_id_8> .servletRegistrationBeans =<extra_id_9> LinkedHashSet<>(servletRegistrationBeans); }</s>', 'output': b'<extra_id_0> {@<extra_id_1> }<extra_id_2> that<extra_id_3> servlet<extra_id_4> s the<extra_id_5> Servlet<extra_id_6> RegistrationBean<extra_id_7> not<extra_id_8> this<extra_id_9> new<extra_id_10>'}\n",
            "{'input': b'Add {@link ServletRegistrationBean}s for the filter. @param servletRegistrationBeans the<extra_id_0> registration<extra_id_1> to add @see #setServletRegistrationBeans public void addServletRegistrationBeans<extra_id_2> RegistrationBean<?>... servletRegistrationBeans) {<extra_id_3> .notNull<extra_id_4> servletRegistrationBeans, \"Servlet<extra_id_5> s must<extra_id_6> be null<extra_id_7> Collections.addAll<extra_id_8> this<extra_id_9> servletRegistrationBeans, servletRegistrationBeans); }</s>', 'output': b'<extra_id_0> servlet<extra_id_1> beans<extra_id_2> ( Servlet<extra_id_3> Assert<extra_id_4> (<extra_id_5> RegistrationBean<extra_id_6> not<extra_id_7> \");<extra_id_8> (<extra_id_9> .<extra_id_10>'}\n",
            "{'input': b'Set servlet names that the filter will be registered against. This will replace any previously specified<extra_id_0> names<extra_id_1> @param servletNames the servlet names @see #set<extra_id_2> RegistrationBeans<extra_id_3> see<extra_id_4> setUrlPatterns public void setServletNames(Collection<String> servletNames) { Assert.<extra_id_5> (servletNames<extra_id_6> \"Servlet<extra_id_7> must not<extra_id_8> null<extra_id_9> this.servlet<extra_id_10> = new LinkedHashSet<>(servletNames<extra_id_11> }</s>', 'output': b'<extra_id_0> servlet<extra_id_1> .<extra_id_2> Servlet<extra_id_3> @<extra_id_4> #<extra_id_5> notNull<extra_id_6> ,<extra_id_7> Names<extra_id_8> be<extra_id_9> \");<extra_id_10> Names<extra_id_11> );<extra_id_12>'}\n",
            "{'input': b'Add servlet<extra_id_0> for the filter. @param servletNames the servlet names to add public void addServlet<extra_id_1> String... servletNames)<extra_id_2> Assert.notNull(servletNames, \"ServletNames must<extra_id_3> be null\"); this<extra_id_4> servlet<extra_id_5> .addAll<extra_id_6> Arrays.asList(servletNames)); }</s>', 'output': b'<extra_id_0> names<extra_id_1> Names(<extra_id_2> {<extra_id_3> not<extra_id_4> .<extra_id_5> Names<extra_id_6> (<extra_id_7>'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z998BqAT42eL"
      },
      "source": [
        "def preprocessing(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join([ ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "  return ds.map(to_inputs_and_targets, num_parallel_calls=tf.data.experimental.AUTOTUNE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq_ljAs373oK",
        "outputId": "c31648fc-f25a-4593-f491-797583959cf5"
      },
      "source": [
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('pretraining')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"pretraining\",\n",
        "    t5.data.Task,\n",
        "    dataset_fn=nq_dataset_fn,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<t5.data.dataset_providers.FunctionTask at 0x7f2a9455fe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFAAvLfG7528",
        "outputId": "dedc6d07-19a2-4dc3-9cce-1c961ecbd326"
      },
      "source": [
        "nq_task = t5.data.TaskRegistry.get(\"pretraining\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(5)):\n",
        "  print(ex)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'Apply caching configuration when appropriate to the given invoker. @param invoker the invoker to wrap @param timeToLive the maximum<extra_id_0> in milliseconds that a response can be cached<extra_id_1> return a caching version<extra_id_2> the invoker or<extra_id_3> original instance<extra_id_4> is not required public<extra_id_5> OperationInvoker<extra_id_6> (OperationInvoker invoker, long timeToLive)<extra_id_7> if<extra_id_8> timeToLive<extra_id_9> 0)<extra_id_10> return new CachingOperationInvoker(invoker, timeToLive); }<extra_id_11> invoker; }</s>', 'inputs': array([ 7989,  6198,   507,   156,  1566,    10,     4,   240, 20670,\n",
            "           3,    21,    45, 20670,     4, 20670,    10,  2272,    21,\n",
            "          45,     7, 30247,     4,  1641,    41,  9105,    24,   164,\n",
            "        3258,    18,    26,  2945,    38,    13,   300,    51,    42,\n",
            "        2851,    41,  9105,    24,   164,  3332,    18,    36,    13,\n",
            "        6198,   355,    41,  9105,    24,   164,  5677,    18,     4,\n",
            "       20670,    71,    41,  9105,    24,   164,  8381,    18,   793,\n",
            "         200,    41,  9105,    24,   164,    24,   252,    18,    19,\n",
            "          50,   704,    39,    41,  9105,    24,   164,    24,   686,\n",
            "          18,  4264, 12816,    41,  9105,    24,   164,    24,   883,\n",
            "          18,    14,  1171, 12816, 20670,     6,   297,     7, 30247,\n",
            "           8,    41,  9105,    24,   164,    24,  1024,    18,    25,\n",
            "          41,  9105,    24,   164, 10449,    18,     7, 30247,    41,\n",
            "        9105,    24,   164,    24,  1325,    18,   377,    41,  9105,\n",
            "          24,   164,    24,  1482,    18,    36,    30, 20421,  1171,\n",
            "       12816,     5,  2463,   276,     6,     7, 30247,    15,    12,\n",
            "          41,  9105,    24,   164,    24,  2031,    18, 20670,    17,\n",
            "          12,    94,    16,    18], dtype=int32), 'targets_pretokenized': b'<extra_id_0> time<extra_id_1> @<extra_id_2> of<extra_id_3> the<extra_id_4> if caching<extra_id_5> static<extra_id_6> apply<extra_id_7> {<extra_id_8> (<extra_id_9> ><extra_id_10> {<extra_id_11> return<extra_id_12>', 'targets': array([32099,   216,    41,  9105,    24,   164,  3332,    18,    21,\n",
            "          41,  9105,    24,   164,  5677,    18,    23,    41,  9105,\n",
            "          24,   164,  8381,    18,     4,    41,  9105,    24,   164,\n",
            "          24,   252,    18,    25,  6198,    41,  9105,    24,   164,\n",
            "          24,   686,    18,    79,    41,  9105,    24,   164,    24,\n",
            "         883,    18,  1346,    41,  9105,    24,   164,    24,  1024,\n",
            "          18,    11,    41,  9105,    24,   164, 10449,    18,    14,\n",
            "          41,  9105,    24,   164,    24,  1325,    18,     7,   838,\n",
            "        9105,    24,   164,    24,  1482,    18,    11,    41,  9105,\n",
            "          24,   164,    24,  2031,    18,    36,    41,  9105,    24,\n",
            "         164,    24,  1533,    18], dtype=int32)}\n",
            "{'inputs_pretokenized': b'<em>Replaces</em> all<extra_id_0> with the<extra_id_1> attribute with a<extra_id_2> with the given value. If multiple parameters with the same attributes are necessary use {@link #<extra_id_3> Parameters(String, Iterable)}. Prefer {@link #withCharset} for<extra_id_4> the {@code charset} parameter when using a {@link Charset} object. @<extra_id_5> IllegalArgumentException if<extra_id_6> {@code attribute}<extra_id_7> {@<extra_id_8> } is invalid public MediaType withParameter(String attribute, String<extra_id_9> ) {<extra_id_10> Parameters(attribute, ImmutableSet.of<extra_id_11> value<extra_id_12> }</s>', 'inputs': array([   40,  1985,    18,  6211,    16,    94,  1985,    18,   119,\n",
            "          41,  9105,    24,   164,  3258,    18,    53,     4,    41,\n",
            "        9105,    24,   164,  3332,    18,   654,    53,    13,    41,\n",
            "        9105,    24,   164,  5677,    18,    53,     4,   240,    74,\n",
            "           3,    96,   778,   415,    53,     4,   198,  1194,    63,\n",
            "        1500,    64,   100,   146,   421,    41,  9105,    24,   164,\n",
            "        8381,    18,  6161,     5,    49,     6,  2555,  6810, 21211,\n",
            "         100,   146,   421,   753,  5466,    87,    32,    41,  9105,\n",
            "          24,   164,    24,   252,    18,     4,   100,    82,  2736,\n",
            "          87,   372,   156,   120,    13,   100,   146,  4740,    87,\n",
            "         112,     3,    21,    41,  9105,    24,   164,    24,   686,\n",
            "          18,   477,    70,    25,    41,  9105,    24,   164,    24,\n",
            "         883,    18,   100,    82,   654,    87,    41,  9105,    24,\n",
            "         164,    24,  1024,    18,   100,    41,  9105,    24,   164,\n",
            "       10449,    18,    12,    19,  1632,    39,  6827,    53,   996,\n",
            "           5,    49,   654,     6,    44,    41,  9105,    24,   164,\n",
            "          24,  1325,    18,   267,    11,    41,  9105,    24,   164,\n",
            "          24,  1482,    18,  6161,     5,  2792,     6, 12163,     3,\n",
            "         718,    41,  9105,    24,   164,    24,  2031,    18,    74,\n",
            "          41,  9105,    24,   164,    24,  1533,    18,    12,    94,\n",
            "          16,    18], dtype=int32), 'targets_pretokenized': b'<extra_id_0> parameters<extra_id_1> given<extra_id_2> single parameter<extra_id_3> with<extra_id_4> setting<extra_id_5> throws<extra_id_6> either<extra_id_7> or<extra_id_8> code value<extra_id_9> value<extra_id_10> return with<extra_id_11> (<extra_id_12> ));<extra_id_13>', 'targets': array([32099,   415,    41,  9105,    24,   164,  3332,    18,   240,\n",
            "          41,  9105,    24,   164,  5677,    18,   589,   372,    41,\n",
            "        9105,    24,   164,  8381,    18,    53,    41,  9105,    24,\n",
            "         164,    24,   252,    18,  1100,    41,  9105,    24,   164,\n",
            "          24,   686,    18,   168,    41,  9105,    24,   164,    24,\n",
            "         883,    18,   671,    41,  9105,    24,   164,    24,  1024,\n",
            "          18,    71,    41,  9105,    24,   164, 10449,    18,    92,\n",
            "          74,    41,  9105,    24,   164,    24,  1325,    18,    74,\n",
            "          41,  9105,    24,   164,    24,  1482,    18,    36,    53,\n",
            "          41,  9105,    24,   164,    24,  2031,    18,    14,    41,\n",
            "        9105,    24,   164,    24,  1533,    18,     7,   170,    41,\n",
            "        9105,    24,   164,    24,  2698,    18], dtype=int32)}\n",
            "{'inputs_pretokenized': b'Creates a <i>mutable</i>,<extra_id_0> {@<extra_id_1> TreeSet} instance with the given comparator.<extra_id_2> p><b>Note:</b> if mutability is not required<extra_id_3> use {@code ImmutableSortedSet.orderedBy(comparator).build()}<extra_id_4> . <p><b><extra_id_5> for Java 7 and later:</<extra_id_6> > this method is now unnecessary and should be treated as deprecated. Instead,<extra_id_7> the {@code TreeSet} constructor directly, taking advantage of the new <<extra_id_8> =\"http://<extra_id_9> oo.gl/<extra_id_10> 2Wi\">\"diamon<extra_id_11> \" syntax</a>. One caveat to this is<extra_id_12> the<extra_id_13> TreeSet}<extra_id_14> uses<extra_id_15> null {@code Comparator<extra_id_16> mean \"<extra_id_17> ,\" whereas this factory rejects null. Clean your code accordingly<extra_id_18> @param<extra_id_19> the comparator<extra_id_20> use to sort the set<extra_id_21> return a new,<extra_id_22> {@code TreeSet} @throws NullPointer<extra_id_23> if {@code comparator} is<extra_id_24> public static <E> TreeSet<extra_id_25> E> newTreeSet(Comparator<? super E><extra_id_26> ) { return new TreeSet<extra_id_27> E>(<extra_id_28> (comparator)); }</s>', 'inputs': array([ 1365,    13,    40,    78,    18, 15738,    94,    78,    18,\n",
            "           6,    41,  9105,    24,   164,  3258,    18,   100,    41,\n",
            "        9105,    24,   164,  3332,    18,  4610,    87,   200,    53,\n",
            "           4,   240,  2336,     3,    41,  9105,    24,   164,  5677,\n",
            "          18,   335,   838,   202,    18,  3059,  3313,   202,    18,\n",
            "          25, 29812,    19,    50,   704,    41,  9105,    24,   164,\n",
            "        8381,    18,    64,   100,    82, 28665,   443,     3, 16115,\n",
            "         771,     5, 10674,     8,     3,   646,  2360,    41,  9105,\n",
            "          24,   164,    24,   252,    18,    77,    40,   101,   838,\n",
            "         202,   838,  9105,    24,   164,    24,   686,    18,    32,\n",
            "         162,  1282,    27,  1590,  3313,    41,  9105,    24,   164,\n",
            "          24,   883,    18,   393,    31,    68,    19,   569,  4926,\n",
            "          27,   106,    42,  5512,    62,  3794,     3,  1274,     6,\n",
            "          41,  9105,    24,   164,    24,  1024,    18,     4,   100,\n",
            "          82,  4610,    87,   426,   903,     6,  3661,  4456,    23,\n",
            "           4,    30,  2632,  9105,    24,   164, 10449,    18,     9,\n",
            "         378,   401,   173,    41,  9105,    24,   164,    24,  1325,\n",
            "          18,     7,  4725,     3,  4918,    33,    41,  9105,    24,\n",
            "         164,    24,  1482,    18,   307,  1054,    78,  1745,   378,\n",
            "         111, 13493,   720,    41,  9105,    24,   164,    24,  2031,\n",
            "          18,    91,  1691,    94,   127,    18,     3,  1235, 15526,\n",
            "          10,    31,    19,    41,  9105,    24,   164,    24,  1533,\n",
            "          18,     4,    41,  9105,    24,   164,    24,  2698,    18,\n",
            "        4610,    87,    41,  9105,    24,   164,    24,  3162,    18,\n",
            "         885,    41,  9105,    24,   164,    24,  2754,    18,    48,\n",
            "         100,    82,  1913,    41,  9105,    24,   164,    24,  1957,\n",
            "          18,  1477,    91,    41,  9105,    24,   164,    24,  3266,\n",
            "          18,   154,   378,  5050,    31,  1091, 10586,    16,    48,\n",
            "           3, 11845,    46,    92,  4844,    41,  9105,    24,   164,\n",
            "          24,  2476,    18,    21,    45,    41,  9105,    24,   164,\n",
            "          24,  3263,    18,     4,  2336,    41,  9105,    24,   164,\n",
            "          24,  2231,    18,    64,    10,  1204,     4,   109,    41,\n",
            "        9105,    24,   164,    24,  3234,    18,    36,    13,    30,\n",
            "           6,    41,  9105,    24,   164,    24,  3426,    18,   100,\n",
            "          82,  4610,    87,    21,   186,  1678,    41,  9105,    24,\n",
            "         164,    24,  2861,    18,    25,   100,    82,  2336,    87,\n",
            "          19,    41,  9105,    24,   164,    24,  3111,    18,    39,\n",
            "          79,    40,   379,    18,  4610,    41,  9105,    24,   164,\n",
            "          24,  2601,    18,   815,    18,    30, 22909,     5,  2418,\n",
            "         865,   397,   815,   838,  9105,    24,   164,    24,  3816,\n",
            "          18,   267,    11,    36,    30,  4610,    41,  9105,    24,\n",
            "         164,    24,  4524,    18,   815,    18,     5,    41,  9105,\n",
            "          24,   164,    24,  4942,    18,    14, 10674,   170,    12,\n",
            "          94,    16,    18], dtype=int32), 'targets_pretokenized': b'<extra_id_0> empty<extra_id_1> code<extra_id_2> <<extra_id_3> ,<extra_id_4> instead<extra_id_5> Note<extra_id_6> b<extra_id_7> use<extra_id_8> a href<extra_id_9> g<extra_id_10> iz<extra_id_11> d<extra_id_12> that<extra_id_13> {@code<extra_id_14> constructor<extra_id_15> a<extra_id_16> } to<extra_id_17> natural ordering<extra_id_18> .<extra_id_19> comparator<extra_id_20> to<extra_id_21> @<extra_id_22> empty<extra_id_23> Exception<extra_id_24> null<extra_id_25> <<extra_id_26> comparator<extra_id_27> <<extra_id_28> checkNotNull<extra_id_29>', 'targets': array([32099,   568,    41,  9105,    24,   164,  3332,    18,    92,\n",
            "          41,  9105,    24,   164,  5677,    18,  2632,  9105,    24,\n",
            "         164,  8381,    18,   154,    41,  9105,    24,   164,    24,\n",
            "         252,    18,   302,    41,  9105,    24,   164,    24,   686,\n",
            "          18,   557,    41,  9105,    24,   164,    24,   883,    18,\n",
            "         278,    41,  9105,    24,   164,    24,  1024,    18,    64,\n",
            "          41,  9105,    24,   164, 10449,    18,    13,  1551,    41,\n",
            "        9105,    24,   164,    24,  1325,    18,   691,    41,  9105,\n",
            "          24,   164,    24,  1482,    18,    72,   717,    41,  9105,\n",
            "          24,   164,    24,  2031,    18,   681,    41,  9105,    24,\n",
            "         164,    24,  1533,    18,    38,    41,  9105,    24,   164,\n",
            "          24,  2698,    18,   100,    82,    41,  9105,    24,   164,\n",
            "          24,  3162,    18,   426,    41,  9105,    24,   164,    24,\n",
            "        2754,    18,    13,    41,  9105,    24,   164,    24,  1957,\n",
            "          18,    12,    10,    41,  9105,    24,   164,    24,  3266,\n",
            "          18,  6064,  3754,    41,  9105,    24,   164,    24,  2476,\n",
            "          18,    77,    41,  9105,    24,   164,    24,  3263,    18,\n",
            "        2336,    41,  9105,    24,   164,    24,  2231,    18,    10,\n",
            "          41,  9105,    24,   164,    24,  3234,    18,    21,    41,\n",
            "        9105,    24,   164,    24,  3426,    18,   568,    41,  9105,\n",
            "          24,   164,    24,  2861,    18,   522,    41,  9105,    24,\n",
            "         164,    24,  3111,    18,    48,    41,  9105,    24,   164,\n",
            "          24,  2601,    18,  2632,  9105,    24,   164,    24,  3816,\n",
            "          18,  2336,    41,  9105,    24,   164,    24,  4524,    18,\n",
            "        2632,  9105,    24,   164,    24,  4942,    18,  5622,    41,\n",
            "        9105,    24,   164,    24,  4516,    18], dtype=int32)}\n",
            "{'inputs_pretokenized': b'Set the {@link RestTemplateCustomizer<extra_id_0> s} that should be applied to the {@link RestTemplate}. Customizers<extra_id_1> applied in the order that they were added after builder<extra_id_2> has been applied. Setting this value will replace<extra_id_3> configured customizers. @param restTemplateCustomizers the customizers to set<extra_id_4> return a new builder instance @<extra_id_5> #additionalCustomizer<extra_id_6> (RestTemplateCustomizer...) public RestTemplate<extra_id_7> customizers( RestTemplate<extra_id_8> ... restTemplateCustomizers) { Assert.notNull(restTemplateCustomizers, \"RestTemplate<extra_id_9> must<extra_id_10> be<extra_id_11> \"); return<extra_id_12> s(<extra_id_13> .<extra_id_14> (restTemplateCustomizers)); }</s>', 'inputs': array([  508,     4,   100,   146,  7498, 10138,    41,  9105,    24,\n",
            "         164,  3258,    18,   232,    87,    38,   106,    42,  2483,\n",
            "          10,     4,   100,   146,  7498,  1068,     7, 10138,    16,\n",
            "          41,  9105,    24,   164,  3332,    18,  2483,    26,     4,\n",
            "         405,    38,   420,   990,   631,   358,   696,    41,  9105,\n",
            "          24,   164,  5677,    18,   167,   533,  2483,     3,  5336,\n",
            "          31,    74,    65,   955,    41,  9105,    24,   164,  8381,\n",
            "          18,  1870, 27651,    16,     3,    21,    45,  9290, 10138,\n",
            "          16,     4, 27651,    16,    10,   109,    41,  9105,    24,\n",
            "         164,    24,   252,    18,    36,    13,    30,   696,   200,\n",
            "          21,    41,  9105,    24,   164,    24,   686,    18,   421,\n",
            "        9281, 10138,    41,  9105,    24,   164,    24,   883,    18,\n",
            "          14, 16241, 10138,  4861,    39,  7498,    41,  9105,    24,\n",
            "         164,    24,  1024,    18, 27651,    16,     5,  7498,    41,\n",
            "        9105,    24,   164, 10449,    18,   309,  9290, 10138,    16,\n",
            "           8,    11,  3648,     3,  3928,     5, 26807, 10138,    16,\n",
            "           6,    91, 16241,    41,  9105,    24,   164,    24,  1325,\n",
            "          18,   359,    41,  9105,    24,   164,    24,  1482,    18,\n",
            "          42,    41,  9105,    24,   164,    24,  2031,    18,    91,\n",
            "          15,    36,    41,  9105,    24,   164,    24,  1533,    18,\n",
            "         232,     5,    41,  9105,    24,   164,    24,  2698,    18,\n",
            "          77,    41,  9105,    24,   164,    24,  3162,    18,    14,\n",
            "       26807, 10138,    16,   170,    12,    94,    16,    18],\n",
            "      dtype=int32), 'targets_pretokenized': b'<extra_id_0> RestTemplateCustomizer<extra_id_1> are<extra_id_2> configuration<extra_id_3> any previously<extra_id_4> @<extra_id_5> see<extra_id_6> s<extra_id_7> Builder<extra_id_8> Customizer<extra_id_9> Customizers<extra_id_10> not<extra_id_11> null<extra_id_12> customizer<extra_id_13> Arrays<extra_id_14> asList<extra_id_15>', 'targets': array([32099,  7498, 10138,    41,  9105,    24,   164,  3332,    18,\n",
            "          63,    41,  9105,    24,   164,  5677,    18,   507,    41,\n",
            "        9105,    24,   164,  8381,    18,   185,  3478,    41,  9105,\n",
            "          24,   164,    24,   252,    18,    21,    41,  9105,    24,\n",
            "         164,    24,   686,    18,   342,    41,  9105,    24,   164,\n",
            "          24,   883,    18,   232,    41,  9105,    24,   164,    24,\n",
            "        1024,    18,  5247,    41,  9105,    24,   164, 10449,    18,\n",
            "           7, 10138,    41,  9105,    24,   164,    24,  1325,    18,\n",
            "           7, 10138,    16,    41,  9105,    24,   164,    24,  1482,\n",
            "          18,    50,    41,  9105,    24,   164,    24,  2031,    18,\n",
            "          48,    41,  9105,    24,   164,    24,  1533,    18, 27651,\n",
            "          41,  9105,    24,   164,    24,  2698,    18,  1078,    41,\n",
            "        9105,    24,   164,    24,  3162,    18,    62,   135,    41,\n",
            "        9105,    24,   164,    24,  2754,    18], dtype=int32)}\n",
            "{'inputs_pretokenized': b'Encodes {@code data<extra_id_0> as a JSON string. This applies<extra_id_1> and any necessary character escaping<extra_id_2> @param data the string to encode. Null will be interpreted<extra_id_3> an<extra_id_4> string.<extra_id_5> return the quoted<extra_id_6> public static String quote(String data)<extra_id_7> if<extra_id_8> data == null) { return \"\\\\\"\\\\\"\"; } try<extra_id_9> JSONStringer stringer = new JSONStringer(); string<extra_id_10> .open(JSONStringer.Scope.NULL, \"\"); stringer.value(data<extra_id_11> stringer<extra_id_12> close(JSONStringer.Scope.<extra_id_13> JSONStringer.Scope<extra_id_14> NULL, \"\"); return<extra_id_15> er.toString();<extra_id_16> catch (JSONException e<extra_id_17> { throw<extra_id_18> AssertionError(); } }</s>', 'inputs': array([17390,   100,    82,   142,    41,  9105,    24,   164,  3258,\n",
            "          18,    62,    13,   828,   191,     3,   113,  4214,    41,\n",
            "        9105,    24,   164,  3332,    18,    27,   185,  1500,   607,\n",
            "        8428,    41,  9105,    24,   164,  5677,    18,    21,    45,\n",
            "         142,     4,   191,    10,  2811,     3,  5483,    65,    42,\n",
            "        6251,    41,  9105,    24,   164,  8381,    18,    61,    41,\n",
            "        9105,    24,   164,    24,   252,    18,   191,     3,    41,\n",
            "        9105,    24,   164,    24,   686,    18,    36,     4,  8325,\n",
            "          41,  9105,    24,   164,    24,   883,    18,    39,    79,\n",
            "          44,  3869,     5,    49,   142,     8,    41,  9105,    24,\n",
            "         164,    24,  1024,    18,    25,    41,  9105,    24,   164,\n",
            "       10449,    18,   142,    86,    48,     8,    11,    36,  7171,\n",
            "        2351,    17,    12,   134,    41,  9105,    24,   164,    24,\n",
            "        1325,    18,   828,    49,   416,   191,   416,     9,    30,\n",
            "         828,    49,   416,    34,   191,    41,  9105,    24,   164,\n",
            "          24,  1482,    18,    77,  1781,     5,  2052,    49,   416,\n",
            "           3,  2119,     3,  4634,     6,  1914,   191,   416,     3,\n",
            "         255,     5,   418,    41,  9105,    24,   164,    24,  2031,\n",
            "          18,   191,   416,    41,  9105,    24,   164,    24,  1533,\n",
            "          18,   973,     5,  2052,    49,   416,     3,  2119,     3,\n",
            "          41,  9105,    24,   164,    24,  2698,    18,   828,    49,\n",
            "         416,     3,  2119,    41,  9105,    24,   164,    24,  3162,\n",
            "          18,  3474,     6,  1914,    36,    41,  9105,    24,   164,\n",
            "          24,  2754,    18,     7,   416,     3,   282,    34,    41,\n",
            "        9105,    24,   164,    24,  1957,    18,   195,    14,  8425,\n",
            "         117,    41,  9105,    24,   164,    24,  3266,    18,    11,\n",
            "         177,    41,  9105,    24,   164,    24,  2476,    18,  7787,\n",
            "          34,    12,    12,    94,    16,    18], dtype=int32), 'targets_pretokenized': b'<extra_id_0> }<extra_id_1> quotes<extra_id_2> .<extra_id_3> as<extra_id_4> empty<extra_id_5> @<extra_id_6> value<extra_id_7> {<extra_id_8> (<extra_id_9> {<extra_id_10> er<extra_id_11> );<extra_id_12> .<extra_id_13> NULL,<extra_id_14> .<extra_id_15> string<extra_id_16> }<extra_id_17> )<extra_id_18> new<extra_id_19>', 'targets': array([32099,    12,    41,  9105,    24,   164,  3332,    18,  3607,\n",
            "          41,  9105,    24,   164,  5677,    18,    77,    41,  9105,\n",
            "          24,   164,  8381,    18,    62,    41,  9105,    24,   164,\n",
            "          24,   252,    18,   568,    41,  9105,    24,   164,    24,\n",
            "         686,    18,    21,    41,  9105,    24,   164,    24,   883,\n",
            "          18,    74,    41,  9105,    24,   164,    24,  1024,    18,\n",
            "          11,    41,  9105,    24,   164, 10449,    18,    14,    41,\n",
            "        9105,    24,   164,    24,  1325,    18,    11,    41,  9105,\n",
            "          24,   164,    24,  1482,    18,     7,   416,    41,  9105,\n",
            "          24,   164,    24,  2031,    18,   734,    41,  9105,    24,\n",
            "         164,    24,  1533,    18,    77,    41,  9105,    24,   164,\n",
            "          24,  2698,    18,  3474,     6,    41,  9105,    24,   164,\n",
            "          24,  3162,    18,    77,    41,  9105,    24,   164,    24,\n",
            "        2754,    18,   191,    41,  9105,    24,   164,    24,  1957,\n",
            "          18,    12,    41,  9105,    24,   164,    24,  3266,    18,\n",
            "         267,    41,  9105,    24,   164,    24,  2476,    18,    30,\n",
            "          41,  9105,    24,   164,    24,  3263,    18], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgvnbVWU78nz"
      },
      "source": [
        "from mesh_tensorflow.transformer.learning_rate_schedules import learning_rate_schedule_noam\n",
        "\n",
        "#See https://github.com/google-research/text-to-text-transfer-transformer if you want to scale up the model\n",
        "MODEL_SIZE = \"small\"  \n",
        "\n",
        "MODEL_DIR = 'gs://code_review_automation/model_dumps'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 512, 16),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    learning_rate_schedule = learning_rate_schedule_noam,\n",
        "    save_checkpoints_steps=5000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmdx3v9z8DY6",
        "outputId": "46afa87b-4c67-401a-d40a-dfa1f557fb0f"
      },
      "source": [
        "!gsutil cp gs://code_review_automation/config/operative_config.gin ./operative_config.gin \n",
        "PATH_GIN_FILE = './operative_config.gin'\n",
        "import gin\n",
        "with gin.unlock_config():    \n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    TRAIN_STEPS = 200000\n",
        "    model.train(\"pretraining\", steps=TRAIN_STEPS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://code_review_automation/config/operative_config.gin...\n",
            "/ [0 files][    0.0 B/ 11.5 KiB]                                                \r/ [1 files][ 11.5 KiB/ 11.5 KiB]                                                \r\n",
            "Operation completed over 1 objects/11.5 KiB.                                     \n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/model_dumps', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.94.57.122:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.94.57.122:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.94.57.122:8470', '_evaluation_master': 'grpc://10.94.57.122:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f295259f290>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.94.57.122:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.94.57.122:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 3325952964593176449)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -7428069123610550159)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -5481182395898713551)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -9063078893331910187)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -7896114229662362592)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4946299466931690597)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 8924909524587357861)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8156840693174517394)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -7081980348688523714)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -90192932668827660)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -679990631001504466)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/t5/seqio/preprocessors.py:65: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('batch', 'batch'), ('d_ff', 'model'), ('heads', 'model'), ('experts', 'batch'), ('ensemble', 'ensemble'), ('vocab', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f295289d050>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 6.85e+08\n",
            " allreduce/[0]: 6.85e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 2.01e+08\n",
            "einsum: 8.11e+13\n",
            "einsum_unique: 8.11e+13\n",
            "output: 7.23e+11\n",
            " output/AddOperation: 1.34e+11\n",
            " output/BinaryOpWithBroadcasting: 8.98e+09\n",
            " output/BroadcastOperation: 4.05e+10\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 2.88e+11\n",
            " output/ImportOperation: 1.26e+07\n",
            " output/MinMaxOperation: 3.8e+07\n",
            " output/OneHotOperation: 2.61e+10\n",
            " output/RandomOperation: 5.92e+07\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 1.57e+10\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 5.43e+08\n",
            " output/ScalarMultiplyOperation: 7.17e+09\n",
            " output/ShiftOperation: 5.24e+05\n",
            " output/SlicewiseOperation: 1.47e+11\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 2.77e+10\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 7.15e+11\n",
            " output_unique/AddOperation: 1.33e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 8.93e+09\n",
            " output_unique/BroadcastOperation: 4.05e+10\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 2.84e+11\n",
            " output_unique/ImportOperation: 1.57e+06\n",
            " output_unique/MinMaxOperation: 4.98e+06\n",
            " output_unique/OneHotOperation: 2.54e+10\n",
            " output_unique/RandomOperation: 5.92e+07\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 1.55e+10\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 7.52e+07\n",
            " output_unique/ScalarMultiplyOperation: 7.08e+09\n",
            " output_unique/ShiftOperation: 5.24e+05\n",
            " output_unique/SlicewiseOperation: 1.45e+11\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 2.77e+10\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Bypassing TPUEstimator hook\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/model_dumps/model.ckpt-20400\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1076: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:773: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 20400...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 20400 into gs://code_review_automation/model_dumps/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 20400...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 40)\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 80)\n",
            "INFO:tensorflow:loss = 0.14160156, step = 20500\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 18)\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 58)\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 98)\n",
            "INFO:tensorflow:loss = 0.11328125, step = 20600 (154.739 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646252\n",
            "INFO:tensorflow:examples/sec: 330.881\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 37)\n",
            "INFO:tensorflow:Outfeed finished for iteration (2, 77)\n",
            "INFO:tensorflow:loss = 0.10205078, step = 20700 (154.072 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.649045\n",
            "INFO:tensorflow:examples/sec: 332.311\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 16)\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 56)\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 96)\n",
            "INFO:tensorflow:loss = 0.10058594, step = 20800 (154.742 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646237\n",
            "INFO:tensorflow:examples/sec: 330.873\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 35)\n",
            "INFO:tensorflow:Outfeed finished for iteration (4, 75)\n",
            "INFO:tensorflow:loss = 0.09082031, step = 20900 (153.423 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651793\n",
            "INFO:tensorflow:examples/sec: 333.718\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 14)\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 54)\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 94)\n",
            "INFO:tensorflow:loss = 0.18652344, step = 21000 (154.076 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.64903\n",
            "INFO:tensorflow:examples/sec: 332.303\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 33)\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 73)\n",
            "INFO:tensorflow:loss = 0.17578125, step = 21100 (154.651 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646615\n",
            "INFO:tensorflow:examples/sec: 331.067\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 12)\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 52)\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 92)\n",
            "INFO:tensorflow:loss = 0.17285156, step = 21200 (153.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651776\n",
            "INFO:tensorflow:examples/sec: 333.709\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (8, 31)\n",
            "INFO:tensorflow:Outfeed finished for iteration (8, 71)\n",
            "INFO:tensorflow:loss = 0.16015625, step = 21300 (154.062 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.649087\n",
            "INFO:tensorflow:examples/sec: 332.333\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 10)\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 50)\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 90)\n",
            "INFO:tensorflow:loss = 0.171875, step = 21400 (154.761 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646158\n",
            "INFO:tensorflow:examples/sec: 330.833\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 29)\n",
            "INFO:tensorflow:Outfeed finished for iteration (10, 69)\n",
            "INFO:tensorflow:loss = 0.171875, step = 21500 (153.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651765\n",
            "INFO:tensorflow:examples/sec: 333.704\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 8)\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 48)\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 88)\n",
            "INFO:tensorflow:loss = 0.16894531, step = 21600 (154.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.648584\n",
            "INFO:tensorflow:examples/sec: 332.075\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (12, 27)\n",
            "INFO:tensorflow:Outfeed finished for iteration (12, 67)\n",
            "INFO:tensorflow:loss = 0.17382812, step = 21700 (154.777 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646087\n",
            "INFO:tensorflow:examples/sec: 330.797\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 6)\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 46)\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 86)\n",
            "INFO:tensorflow:loss = 0.171875, step = 21800 (153.430 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.65177\n",
            "INFO:tensorflow:examples/sec: 333.706\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 25)\n",
            "INFO:tensorflow:Outfeed finished for iteration (14, 65)\n",
            "INFO:tensorflow:loss = 0.47851562, step = 21900 (154.085 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.648993\n",
            "INFO:tensorflow:examples/sec: 332.285\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 4)\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 44)\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 84)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 22000 (154.694 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646432\n",
            "INFO:tensorflow:examples/sec: 330.973\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (16, 23)\n",
            "INFO:tensorflow:Outfeed finished for iteration (16, 63)\n",
            "INFO:tensorflow:loss = 0.13085938, step = 22100 (153.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651774\n",
            "INFO:tensorflow:examples/sec: 333.708\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (17, 2)\n",
            "INFO:tensorflow:Outfeed finished for iteration (17, 42)\n",
            "INFO:tensorflow:Outfeed finished for iteration (17, 82)\n",
            "INFO:tensorflow:loss = 0.119628906, step = 22200 (154.092 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.648966\n",
            "INFO:tensorflow:examples/sec: 332.271\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 21)\n",
            "INFO:tensorflow:Outfeed finished for iteration (18, 61)\n",
            "INFO:tensorflow:loss = 0.12207031, step = 22300 (154.749 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646206\n",
            "INFO:tensorflow:examples/sec: 330.858\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 40)\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 80)\n",
            "INFO:tensorflow:loss = 0.10449219, step = 22400 (153.424 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651787\n",
            "INFO:tensorflow:examples/sec: 333.715\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 19)\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 59)\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 99)\n",
            "INFO:tensorflow:loss = 0.171875, step = 22500 (154.112 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.648878\n",
            "INFO:tensorflow:examples/sec: 332.226\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (21, 38)\n",
            "INFO:tensorflow:Outfeed finished for iteration (21, 78)\n",
            "INFO:tensorflow:loss = 0.16699219, step = 22600 (155.782 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.641923\n",
            "INFO:tensorflow:examples/sec: 328.665\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 16)\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 56)\n",
            "INFO:tensorflow:Outfeed finished for iteration (22, 96)\n",
            "INFO:tensorflow:loss = 0.17382812, step = 22700 (153.430 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651762\n",
            "INFO:tensorflow:examples/sec: 333.702\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (23, 35)\n",
            "INFO:tensorflow:Outfeed finished for iteration (23, 75)\n",
            "INFO:tensorflow:loss = 0.171875, step = 22800 (154.068 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.649064\n",
            "INFO:tensorflow:examples/sec: 332.321\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 14)\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 54)\n",
            "INFO:tensorflow:Outfeed finished for iteration (24, 94)\n",
            "INFO:tensorflow:loss = 0.1640625, step = 22900 (154.930 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.645456\n",
            "INFO:tensorflow:examples/sec: 330.473\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (25, 33)\n",
            "INFO:tensorflow:Outfeed finished for iteration (25, 73)\n",
            "INFO:tensorflow:loss = 0.16015625, step = 23000 (153.427 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651775\n",
            "INFO:tensorflow:examples/sec: 333.709\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (26, 12)\n",
            "INFO:tensorflow:Outfeed finished for iteration (26, 52)\n",
            "INFO:tensorflow:Outfeed finished for iteration (26, 92)\n",
            "INFO:tensorflow:loss = 0.16210938, step = 23100 (154.124 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.64883\n",
            "INFO:tensorflow:examples/sec: 332.201\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 31)\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 71)\n",
            "INFO:tensorflow:loss = 0.16601562, step = 23200 (154.759 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646164\n",
            "INFO:tensorflow:examples/sec: 330.836\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (28, 10)\n",
            "INFO:tensorflow:Outfeed finished for iteration (28, 50)\n",
            "INFO:tensorflow:Outfeed finished for iteration (28, 90)\n",
            "INFO:tensorflow:loss = 0.17773438, step = 23300 (153.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651781\n",
            "INFO:tensorflow:examples/sec: 333.712\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 29)\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 69)\n",
            "INFO:tensorflow:loss = 0.13085938, step = 23400 (154.132 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.648797\n",
            "INFO:tensorflow:examples/sec: 332.184\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (30, 8)\n",
            "INFO:tensorflow:Outfeed finished for iteration (30, 48)\n",
            "INFO:tensorflow:Outfeed finished for iteration (30, 88)\n",
            "INFO:tensorflow:loss = 0.047607422, step = 23500 (154.686 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646468\n",
            "INFO:tensorflow:examples/sec: 330.991\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (31, 27)\n",
            "INFO:tensorflow:Outfeed finished for iteration (31, 67)\n",
            "INFO:tensorflow:loss = 0.12109375, step = 23600 (153.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651782\n",
            "INFO:tensorflow:examples/sec: 333.713\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (32, 6)\n",
            "INFO:tensorflow:Outfeed finished for iteration (32, 46)\n",
            "INFO:tensorflow:Outfeed finished for iteration (32, 86)\n",
            "INFO:tensorflow:loss = 0.11621094, step = 23700 (154.043 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.649168\n",
            "INFO:tensorflow:examples/sec: 332.374\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (33, 25)\n",
            "INFO:tensorflow:Outfeed finished for iteration (33, 65)\n",
            "INFO:tensorflow:loss = 0.10058594, step = 23800 (154.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646139\n",
            "INFO:tensorflow:examples/sec: 330.823\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 4)\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 44)\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 84)\n",
            "INFO:tensorflow:loss = 0.18261719, step = 23900 (153.429 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651766\n",
            "INFO:tensorflow:examples/sec: 333.704\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (35, 23)\n",
            "INFO:tensorflow:Outfeed finished for iteration (35, 63)\n",
            "INFO:tensorflow:loss = 0.1796875, step = 24000 (154.028 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.649232\n",
            "INFO:tensorflow:examples/sec: 332.407\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 2)\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 42)\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 82)\n",
            "INFO:tensorflow:loss = 0.16210938, step = 24100 (154.636 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646681\n",
            "INFO:tensorflow:examples/sec: 331.101\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (37, 21)\n",
            "INFO:tensorflow:Outfeed finished for iteration (37, 61)\n",
            "INFO:tensorflow:loss = 0.1640625, step = 24200 (153.428 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651774\n",
            "INFO:tensorflow:examples/sec: 333.708\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 0)\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 40)\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 80)\n",
            "INFO:tensorflow:loss = 0.16894531, step = 24300 (154.066 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.649072\n",
            "INFO:tensorflow:examples/sec: 332.325\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 19)\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 59)\n",
            "INFO:tensorflow:Outfeed finished for iteration (39, 99)\n",
            "INFO:tensorflow:loss = 0.16894531, step = 24400 (154.672 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.646529\n",
            "INFO:tensorflow:examples/sec: 331.023\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (40, 38)\n",
            "INFO:tensorflow:Outfeed finished for iteration (40, 78)\n",
            "INFO:tensorflow:loss = 0.15820312, step = 24500 (153.425 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.651784\n",
            "INFO:tensorflow:examples/sec: 333.713\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (41, 17)\n",
            "INFO:tensorflow:Outfeed finished for iteration (41, 57)\n",
            "INFO:tensorflow:Outfeed finished for iteration (41, 97)\n",
            "INFO:tensorflow:loss = 0.16015625, step = 24600 (154.115 sec)\n",
            "INFO:tensorflow:global_step/sec: 0.648868\n",
            "INFO:tensorflow:examples/sec: 332.221\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (42, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC-wD7AkC4KT"
      },
      "source": [
        "# myModel = model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "578O2Q5NzUeJ"
      },
      "source": [
        "# Predicts targets from the given inputs.\n",
        "\n",
        "# Args:\n",
        "#   input_file: str, path to a text file containing newline-separated input\n",
        "#     prompts to predict from.\n",
        "#   output_file: str, path prefix of output file to write predictions to. Note\n",
        "#     the checkpoint step will be appended to the given filename.\n",
        "#   checkpoint_steps: int, list of ints, or None. If an int or list of ints,\n",
        "#     inference will be run on the checkpoint files in model_dir whose\n",
        "#     global steps are closest to the global steps provided. If None, run\n",
        "#     inference continuously waiting for new checkpoints. If -1, get the\n",
        "#     latest checkpoint from the model directory.\n",
        "#   beam_size: int, a number >= 1 specifying the number of beams to use for\n",
        "#     beam search.\n",
        "#   temperature: float, a value between 0 and 1 (must be 0 if beam_size > 1)\n",
        "#     0.0 means argmax, 1.0 means sample according to predicted distribution.\n",
        "#   keep_top_k: integer, a value between 1 and the vocabulary size. When\n",
        "#     sampling, only pick tokens that are in the k most likely.\n",
        "#   vocabulary: vocabularies.Vocabulary object to use for tokenization, or\n",
        "#     None to use the default SentencePieceVocabulary.\n",
        "\n",
        "\n",
        "# model.predict(input_file=\"gs://code_review_automation/dataset/data/test.source\", output_file=\"gs://code_review_automation/dataset/data/test.target\",checkpoint_steps=-1, beam_size=1, temperature=1.0, vocabulary=SentencePieceVocabulary(vocab_model_path, 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8E_KXpR_K_zA"
      },
      "source": [
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard\n",
        "\n",
        "# import tensorflow as tf\n",
        "# import datetime\n",
        "\n",
        "# # Clear any logs from previous runs\n",
        "# !rm -rf ./logs/ \n",
        "\n",
        "# %tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}