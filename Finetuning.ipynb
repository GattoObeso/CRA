{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masies/CRA/blob/main/Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1MRzBLtex2",
        "outputId": "351d3f38-3f44-4d5f-fc7a-ea9caaed30e4"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "#!pip install -qU t5\n",
        "!pip3 install git+https://github.com/google-research/text-to-text-transfer-transformer.git #extra_id_x support\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://example_comment\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/ef/60d7ba03b5c442309ef42e7d69959f73aacccd0d86008362a681c4698e83/pip-21.0.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.0.1\n",
            "Collecting git+https://github.com/google-research/text-to-text-transfer-transformer.git\n",
            "  Cloning https://github.com/google-research/text-to-text-transfer-transformer.git to /tmp/pip-req-build-htmpfa5q\n",
            "  Running command git clone -q https://github.com/google-research/text-to-text-transfer-transformer.git /tmp/pip-req-build-htmpfa5q\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (0.12.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (2.9.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (0.4.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.19-py3-none-any.whl (366 kB)\n",
            "\u001b[K     |████████████████████████████████| 366 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (1.1.5)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 17.3 MB/s \n",
            "\u001b[?25hCollecting seqio\n",
            "  Downloading seqio-0.0.3-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (1.15.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 29.0 MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.2.0.dev202104200106-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 49.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5==0.9.0) (1.8.1+cu101)\n",
            "Collecting transformers>=2.7.0\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 72.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (4.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.0) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 70.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.0) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.0) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.0) (3.10.1)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 78.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.0) (3.0.12)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5==0.9.0) (2018.9)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.9.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.9.0) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.7.0->t5==0.9.0) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->t5==0.9.0) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.0) (3.0.4)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.9.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.9.0) (1.0.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (0.1.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (0.3.3)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (20.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (0.29.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (5.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (3.12.4)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (2.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (54.2.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.0) (1.53.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.9.0) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.9.0) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (2.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (2.4.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.6.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (2.10.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.32.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.12.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (0.3.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (3.3.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.1.2)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (0.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (4.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.0) (3.1.0)\n",
            "Building wheels for collected packages: t5\n",
            "  Building wheel for t5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for t5: filename=t5-0.9.0-py3-none-any.whl size=152030 sha256=87e33cd98e8c36f1390395fb7c392ab61fe0838b7503bac66ac2e691381d781b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gh0rto_g/wheels/bf/e8/36/0d7b7d2aa6a91236ea133d24d501fb1faf73d6bf2579f05c96\n",
            "Successfully built t5\n",
            "Installing collected packages: tokenizers, tfds-nightly, tensorflow-text, sentencepiece, sacremoses, portalocker, mesh-tensorflow, transformers, seqio, sacrebleu, rouge-score, t5\n",
            "Successfully installed mesh-tensorflow-0.1.19 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.5.1 sacremoses-0.0.45 sentencepiece-0.1.95 seqio-0.0.3 t5-0.9.0 tensorflow-text-2.4.3 tfds-nightly-4.2.0.dev202104200106 tokenizers-0.10.2 transformers-4.5.1\n",
            "Running on TPU: grpc://10.98.60.74:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4hLh30Sn3PV"
      },
      "source": [
        "nq_tsv_path_code_code = {\n",
        "    \"train\":      'gs://code_review_automation/dataset/new/fineTuningDatasets/code_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/dataset/new/fineTuningDatasets/code_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_code_code = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_code_comment = {\n",
        "    \"train\":      'gs://code_review_automation/dataset/new/fineTuningDatasets/code_comment/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/dataset/new/fineTuningDatasets/code_comment/val.tsv'\n",
        "}\n",
        "num_nq_examples_code_comment = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_codeANDcomment_code = {\n",
        "    \"train\":      'gs://code_review_automation/dataset/new/fineTuningDatasets/codeANDcomment_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/dataset/new/fineTuningDatasets/codeANDcomment_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_codeANDcomment_code = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_marked_code = {\n",
        "    \"train\":      'gs://code_review_automation/dataset/new/fineTuningDatasets/marked_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/dataset/new/fineTuningDatasets/marked_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_marked_code = dict(train=134442, validation=16805)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNi7HPiOz27q",
        "outputId": "fb538bd5-d30b-43f4-f2b4-c5b7a023a093"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "\n",
        "vocab_model_path = 'gs://code_review_automation/CodeReviewModel/TestModel.model'\n",
        "vocab_path = 'gs://code_review_automation/CodeReviewModel/TestModel.vocab'\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}\n",
        "\n",
        "\n",
        "############### FIRST TASK ###############\n",
        "print(\"1st TASK : code 2 code\")\n",
        "\n",
        "def nq_dataset_code_code(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_code_code[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code(\"validation\").take(3)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code(\"train\").take(3)):\n",
        "  print(ex)\n",
        "\n",
        "def code_code_preprocessing(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join(['code2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "t5.data.TaskRegistry.remove('code_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"code_code\",\n",
        "    dataset_fn=nq_dataset_code_code,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[code_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_code_code\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"code_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############### SECOND TASK ###############\n",
        "print(\"2nd TASK : code 2 comment\")\n",
        "\n",
        "def nq_dataset_code_comment(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_code_comment[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_comment(\"validation\").take(3)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_comment(\"train\").take(3)):\n",
        "  print(ex)\n",
        "\n",
        "def code_comment_preprocessing(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code2comment: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('code_comment')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"code_comment\",\n",
        "    dataset_fn=nq_dataset_code_comment,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[code_comment_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_code_comment\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"code_comment\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)\n",
        "\n",
        "\n",
        "\n",
        "############### THIRD TASK ###############\n",
        "print(\"3rd TASK : code and comment 2 code\")\n",
        "\n",
        "def nq_dataset_codeANDcomment_code(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_codeANDcomment_code[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code(\"validation\").take(3)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code(\"train\").take(3)):\n",
        "  print(ex)\n",
        "\n",
        "def codeANDcomment_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code&comment2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('codeANDcomment_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"codeANDcomment_code\",\n",
        "    dataset_fn=nq_dataset_codeANDcomment_code,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[codeANDcomment_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_codeANDcomment_code\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"codeANDcomment_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)\n",
        "\n",
        "\n",
        "\n",
        "############### FOURTH TASK ###############\n",
        "print(\"4th TASK : marked code 2 code\")\n",
        "\n",
        "def nq_dataset_marked_code(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_marked_code[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_marked_code(\"validation\").take(3)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_marked_code(\"train\").take(3)):\n",
        "  print(ex)\n",
        "\n",
        "def marked_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['markedCode2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('marked_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"marked_code\",\n",
        "    dataset_fn=nq_dataset_marked_code,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[marked_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_marked_code\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"marked_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1st TASK : code 2 code\n",
            "A few raw validation examples...\n",
            "{'input': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }', 'output': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); } }); executor.submit(task); }'}\n",
            "{'input': b'public int hashCode() { return element.hashCode(); }', 'output': b'public int hashCode() { if (element == null) { return super.hashCode(); } return element.hashCode(); }'}\n",
            "{'input': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }', 'output': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (!Util.isBlank(domainClassExpression) && !Util.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(EEFExpressionUtils.SELF, this.variableManager.getVariables().get(EEFExpressionUtils.SELF)); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }'}\n",
            "A few raw training examples...\n",
            "{'input': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollection(input, s -> new LinkedList<>()); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }', 'output': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollectionUnbounded(input, LinkedList::new); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }'}\n",
            "{'input': b'public static Command<Set<Cookie>> getAllCookies() { return new Command<>(domainName + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", new TypeToken<Set<Cookie>>() {}.getType())); }', 'output': b'public static Command<Cookies> getAllCookies() { return new Command<>(DOMAIN_NAME + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", Cookies.class)); }'}\n",
            "{'input': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if (blockIn instanceof BlockPistonBase) { final IBlockState blockstate = this.getBlockState(pos); EnumFacing direction = (EnumFacing) blockstate.getValue(BlockDirectional.FACING); BlockPistonStructureHelper movedBlocks = new BlockPistonStructureHelper(this$, pos, direction, eventId == 0); List<BlockPos> blocks = new ArrayList<BlockPos>(); blocks.addAll(movedBlocks.getBlocksToDestroy()); blocks.addAll(movedBlocks.getBlocksToMove()); List<Location<org.spongepowered.api.world.World>> locations = new ArrayList<Location<org.spongepowered.api.world.World>>(); for (BlockPos block : blocks) { locations.add(new Location<>((org.spongepowered.api.world.World) this$, block.getX(), block.getY(), block.getZ())); } if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos, locations)) { return false; } } else { if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos)) { return false; } } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }', 'output': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if ((blockIn instanceof BlockPistonBase && SpongeCommonEventFactory.handlePistonEvent(this, list, obj, pos, blockIn, eventId, eventParam)) || SpongeCommonEventFactory.callChangeBlockEventPre(this, pos, NamedCause.of(NamedCause.BLOCK_EVENT, this)).isCancelled()) { return false; } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'code2code: public void saveOrder_shouldPassIfTheExistingDrugOrderMatchesTheConceptAndThereIsNoDrugOnThePreviousOrder() throws Exception { DrugOrder orderToDiscontinue = new DrugOrder(); orderToDiscontinue.setAction(Action.NEW); orderToDiscontinue.setPatient(Context.getPatientService().getPatient(7)); orderToDiscontinue.setConcept(Context.getConceptService().getConcept(5497)); orderToDiscontinue.setCareSetting(orderService.getCareSetting(1)); orderToDiscontinue.setOrderer(orderService.getOrder(1).getOrderer()); orderToDiscontinue.setEncounter(encounterService.getEncounter(3)); orderToDiscontinue.setDateActivated(new Date()); orderToDiscontinue.setScheduledDate(new Date()); orderToDiscontinue.setUrgency(Order.Urgency.ON_SCHEDULED_DATE); orderToDiscontinue.setEncounter(encounterService.getEncounter(3)); orderToDiscontinue.setOrderType(orderService.getOrderType(17)); orderToDiscontinue.setDrug(null); orderToDiscontinue.setDosingType(FreeTextDosingInstructions.class); orderToDiscontinue.setDosingInstructions(\"instructions\"); orderToDiscontinue.setOrderer(providerService.getProvider(1)); orderToDiscontinue.setDosingInstructions(\"2 for 5 days\"); orderToDiscontinue.setQuantity(10.0); orderToDiscontinue.setQuantityUnits(conceptService.getConcept(51)); orderToDiscontinue.setNumRefills(2); orderService.saveOrder(orderToDiscontinue, null); assertTrue(OrderUtilTest.isActiveOrder(orderToDiscontinue, null)); DrugOrder order = orderToDiscontinue.cloneForRevision(); order.setDateActivated(new Date()); order.setOrderer(providerService.getProvider(1)); order.setEncounter(encounterService.getEncounter(3)); order.setOrderReasonNonCoded(\"Discontinue this\"); orderService.saveOrder(order, null); Assert.assertNotNull(\"previous order should be discontinued\", orderToDiscontinue.getDateStopped()); }', 'inputs': array([   89,   111,   220,    20,    44,    71,   894,  1452,    25,\n",
            "        5354,  4789,  2159,  1041,  7287, 31165,  1452,  5343,  1041,\n",
            "        6783,   856,  6933,  2197,  1147, 31165,  1113,  1041,  8003,\n",
            "        1452,    43,   169,     7,    66,    15,     7, 31165,  1452,\n",
            "         398,   314,  8263, 16303,    16,    33,     7, 31165,  1452,\n",
            "          39,   398,   314,  8263, 16303,     8, 12518,     9,   871,\n",
            "           8,  5238,    18,   398,   314,  8263, 16303,     8,   138,\n",
            "        9560,     9,   242,     8,    62,  9560,   365,    81,    62,\n",
            "        9560, 21305,    18,   398,   314,  8263, 16303,     8,   138,\n",
            "        6783,     9,   242,     8,    62,  6783,   365,    81,    62,\n",
            "        6783,     9,  6097,  5996,   164,   398,   314,  8263, 16303,\n",
            "           8,   138, 20969,  5163,     9,  2425,   365,     8,    62,\n",
            "       20969,  5163,  4726,   398,   314,  8263, 16303,     8,   138,\n",
            "        1452,   424,     9,  2425,   365,     8, 13192,  6634, 13192,\n",
            "         424,    93,   398,   314,  8263, 16303,     8,   138, 31187,\n",
            "           9,  1683,  3380,   365,     8,    62, 31187,     9, 10811,\n",
            "         398,   314,  8263, 16303,     8, 10523, 24268,     9,    98,\n",
            "         879,    93,   398,   314,  8263, 16303,     8,   138,  5942,\n",
            "         488,     9,    98,   879,    93,   398,   314,  8263, 16303,\n",
            "           8,   138,  1446,  8385, 13370,     9,  1452,     8,  1446,\n",
            "        8385, 13370,     8,  1724,    25, 30939,    25,  2964,    18,\n",
            "         398,   314,  8263, 16303,     8,   138, 31187,     9,  1683,\n",
            "        3380,   365,     8,    62, 31187,     9, 10811,   398,   314,\n",
            "        8263, 16303,     8,   138,  1452,   132,     9,  2425,   365,\n",
            "           8, 13192,   132,     9,  3305,   164,   398,   314,  8263,\n",
            "       16303,     8,   138, 31165,     9,   353,    18,   398,   314,\n",
            "        8263, 16303,     8,   138,  4642,    19,   209,   132,     9,\n",
            "        5907,   593,  4642,    19,   209, 20916,     8,   142,    18,\n",
            "         398,   314,  8263, 16303,     8,   138,  4642,    19,   209,\n",
            "       20916,    46, 20032,    19,    78,   398,   314,  8263, 16303,\n",
            "           8,   138,  1452,   424,     9,  3403,   365,     8, 14400,\n",
            "        4726,   398,   314,  8263, 16303,     8,   138,  4642,    19,\n",
            "         209, 20916,    46,   111,    34,  1164,  2631,    78,   398,\n",
            "         314,  8263, 16303,     8,   138,  7725,     9, 17304,    18,\n",
            "         398,   314,  8263, 16303,     8,   138,  7725,  7329,     9,\n",
            "       20883,   365,     8,    62,  6783,     9,  7911,   164,   398,\n",
            "         314,  8263, 16303,     8,   138,  1611,  2614,  2483,    19,\n",
            "        4683,   398,   365,     8,  1609,  1452,     9,  2425,   314,\n",
            "        8263, 16303,    11,    49,    18, 13989,     9,  1452,   951,\n",
            "         509,     8, 13239,  1452,     9,  2425,   314,  8263, 16303,\n",
            "          11,    49,   164,     7, 31165,  1452,   398,    16,   398,\n",
            "         314,  8263, 16303,     8,  3446,   642,  6342,    39,   398,\n",
            "           8, 10523, 24268,     9,    98,   879,    93,   398,     8,\n",
            "         138,  1452,   424,     9,  3403,   365,     8, 14400,  4726,\n",
            "         398,     8,   138, 31187,     9,  1683,  3380,   365,     8,\n",
            "          62, 31187,     9, 10811,   398,     8,   138,  1452,  6914,\n",
            "        3560,   830,    94,    46,  8263, 16303,    36,    78,   398,\n",
            "         365,     8,  1609,  1452,     9,  2425,    11,    49,    18,\n",
            "        3898,     8, 22657,    46,  4661,   398,   104,    45,  5415,\n",
            "       16303,    94,    86,   398,   314,  8263, 16303,     8,  5434,\n",
            "       14514,    93,    13,     1], dtype=int32), 'targets_pretokenized': b'public void saveOrder_shouldPassIfTheExistingDrugOrderMatchesTheConceptAndThereIsNoDrugOnThePreviousOrder() throws Exception { DrugOrder orderToDiscontinue = new DrugOrder(); orderToDiscontinue.setAction(Action.NEW); orderToDiscontinue.setPatient(Context.getPatientService().getPatient(7)); orderToDiscontinue.setConcept(Context.getConceptService().getConcept(5497)); orderToDiscontinue.setCareSetting(orderService.getCareSetting(1)); orderToDiscontinue.setOrderer(orderService.getOrder(1).getOrderer()); orderToDiscontinue.setEncounter(encounterService.getEncounter(3)); orderToDiscontinue.setDateActivated(new Date()); orderToDiscontinue.setScheduledDate(new Date()); orderToDiscontinue.setUrgency(Order.Urgency.ON_SCHEDULED_DATE); orderToDiscontinue.setEncounter(encounterService.getEncounter(3)); orderToDiscontinue.setOrderType(orderService.getOrderType(17)); orderToDiscontinue.setDrug(null); orderToDiscontinue.setDosingType(FreeTextDosingInstructions.class); orderToDiscontinue.setDosingInstructions(\"instructions\"); orderToDiscontinue.setOrderer(providerService.getProvider(1)); orderToDiscontinue.setDosingInstructions(\"2 for 5 days\"); orderToDiscontinue.setQuantity(10.0); orderToDiscontinue.setQuantityUnits(conceptService.getConcept(51)); orderToDiscontinue.setNumRefills(2); orderService.saveOrder(orderToDiscontinue, null); assertTrue(OrderUtilTest.isActiveOrder(orderToDiscontinue, null)); DrugOrder order = orderToDiscontinue.cloneForDiscontinuing(); order.setDateActivated(new Date()); order.setOrderer(providerService.getProvider(1)); order.setEncounter(encounterService.getEncounter(3)); order.setOrderReasonNonCoded(\"Discontinue this\"); orderService.saveOrder(order, null); Assert.assertNotNull(\"previous order should be discontinued\", orderToDiscontinue.getDateStopped()); }', 'targets': array([   44,    71,   894,  1452,    25,  5354,  4789,  2159,  1041,\n",
            "        7287, 31165,  1452,  5343,  1041,  6783,   856,  6933,  2197,\n",
            "        1147, 31165,  1113,  1041,  8003,  1452,    43,   169,     7,\n",
            "          66,    15,     7, 31165,  1452,   398,   314,  8263, 16303,\n",
            "          16,    33,     7, 31165,  1452,    39,   398,   314,  8263,\n",
            "       16303,     8, 12518,     9,   871,     8,  5238,    18,   398,\n",
            "         314,  8263, 16303,     8,   138,  9560,     9,   242,     8,\n",
            "          62,  9560,   365,    81,    62,  9560, 21305,    18,   398,\n",
            "         314,  8263, 16303,     8,   138,  6783,     9,   242,     8,\n",
            "          62,  6783,   365,    81,    62,  6783,     9,  6097,  5996,\n",
            "         164,   398,   314,  8263, 16303,     8,   138, 20969,  5163,\n",
            "           9,  2425,   365,     8,    62, 20969,  5163,  4726,   398,\n",
            "         314,  8263, 16303,     8,   138,  1452,   424,     9,  2425,\n",
            "         365,     8, 13192,  6634, 13192,   424,    93,   398,   314,\n",
            "        8263, 16303,     8,   138, 31187,     9,  1683,  3380,   365,\n",
            "           8,    62, 31187,     9, 10811,   398,   314,  8263, 16303,\n",
            "           8, 10523, 24268,     9,    98,   879,    93,   398,   314,\n",
            "        8263, 16303,     8,   138,  5942,   488,     9,    98,   879,\n",
            "          93,   398,   314,  8263, 16303,     8,   138,  1446,  8385,\n",
            "       13370,     9,  1452,     8,  1446,  8385, 13370,     8,  1724,\n",
            "          25, 30939,    25,  2964,    18,   398,   314,  8263, 16303,\n",
            "           8,   138, 31187,     9,  1683,  3380,   365,     8,    62,\n",
            "       31187,     9, 10811,   398,   314,  8263, 16303,     8,   138,\n",
            "        1452,   132,     9,  2425,   365,     8, 13192,   132,     9,\n",
            "        3305,   164,   398,   314,  8263, 16303,     8,   138, 31165,\n",
            "           9,   353,    18,   398,   314,  8263, 16303,     8,   138,\n",
            "        4642,    19,   209,   132,     9,  5907,   593,  4642,    19,\n",
            "         209, 20916,     8,   142,    18,   398,   314,  8263, 16303,\n",
            "           8,   138,  4642,    19,   209, 20916,    46, 20032,    19,\n",
            "          78,   398,   314,  8263, 16303,     8,   138,  1452,   424,\n",
            "           9,  3403,   365,     8, 14400,  4726,   398,   314,  8263,\n",
            "       16303,     8,   138,  4642,    19,   209, 20916,    46,   111,\n",
            "          34,  1164,  2631,    78,   398,   314,  8263, 16303,     8,\n",
            "         138,  7725,     9, 17304,    18,   398,   314,  8263, 16303,\n",
            "           8,   138,  7725,  7329,     9, 20883,   365,     8,    62,\n",
            "        6783,     9,  7911,   164,   398,   314,  8263, 16303,     8,\n",
            "         138,  1611,  2614,  2483,    19,  4683,   398,   365,     8,\n",
            "        1609,  1452,     9,  2425,   314,  8263, 16303,    11,    49,\n",
            "          18, 13989,     9,  1452,   951,   509,     8, 13239,  1452,\n",
            "           9,  2425,   314,  8263, 16303,    11,    49,   164,     7,\n",
            "       31165,  1452,   398,    16,   398,   314,  8263, 16303,     8,\n",
            "        3446,   642,  8263, 13114,   289,   718,   209,    39,   398,\n",
            "           8, 10523, 24268,     9,    98,   879,    93,   398,     8,\n",
            "         138,  1452,   424,     9,  3403,   365,     8, 14400,  4726,\n",
            "         398,     8,   138, 31187,     9,  1683,  3380,   365,     8,\n",
            "          62, 31187,     9, 10811,   398,     8,   138,  1452,  6914,\n",
            "        3560,   830,    94,    46,  8263, 16303,    36,    78,   398,\n",
            "         365,     8,  1609,  1452,     9,  2425,    11,    49,    18,\n",
            "        3898,     8, 22657,    46,  4661,   398,   104,    45,  5415,\n",
            "       16303,    94,    86,   398,   314,  8263, 16303,     8,  5434,\n",
            "       14514,    93,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code2code: public void testItValidatesMaxSizeOfPhotoShareByMessage() throws MalformedURLException { SharePhotoContent sharePhotoContent = new SharePhotoContent.Builder().addPhoto(buildSharePhoto(\"<LINK_2>\")) .addPhoto(buildSharePhoto(\"<LINK_5>\")) .addPhoto(buildSharePhoto(\"<LINK_6>\")) .addPhoto(buildSharePhoto(\"<LINK_1>\")) .addPhoto(buildSharePhoto(\"<LINK_0>\")) .addPhoto(buildSharePhoto(\"<LINK_3>\")) .addPhoto(buildSharePhoto(\"<LINK_4>\")) .build(); ShareContentValidation.validateForMessage(sharePhotoContent); }', 'inputs': array([   89,   111,   220,    20,    44,    71,   317,  2845,  6196,\n",
            "          19, 19993,   834,  7795,  5559,   748,   511,    43,   169,\n",
            "       13752,    66,    15,     7,  5559,  7795,   890,  2719,  7795,\n",
            "         890,    16,    33,     7,  5559,  7795,   890,     8,   404,\n",
            "          81,   117,  7795,     9,   591,  5559,  7795,  2457,   184,\n",
            "        2697,   727,     7,     8,   117,  7795,     9,   591,  5559,\n",
            "        7795,  2457,   184, 16209,   727,     7,     8,   117,  7795,\n",
            "           9,   591,  5559,  7795,  2457,   184, 23559,   727,     7,\n",
            "           8,   117,  7795,     9,   591,  5559,  7795,  2457,   184,\n",
            "         985,   727,     7,     8,   117,  7795,     9,   591,  5559,\n",
            "        7795,  2457,   184,   248,   727,     7,     8,   117,  7795,\n",
            "           9,   591,  5559,  7795,  2457,   184,  5638,   727,     7,\n",
            "           8,   117,  7795,     9,   591,  5559,  7795,  2457,   184,\n",
            "        9864,   727,     7,     8,   591,    39,     7,  5559,   890,\n",
            "        3052,     8,  2855,   642,   511,     9,  7145,  7795,   890,\n",
            "          18,    13,     1], dtype=int32), 'targets_pretokenized': b'public void testItValidatesMaxSizeOfPhotoShareByMessage() { SharePhotoContent sharePhotoContent = new SharePhotoContent.Builder() .addPhoto(buildSharePhoto(\"<LINK_2>\")) .addPhoto(buildSharePhoto(\"<LINK_5>\")) .addPhoto(buildSharePhoto(\"<LINK_6>\")) .addPhoto(buildSharePhoto(\"<LINK_1>\")) .addPhoto(buildSharePhoto(\"<LINK_0>\")) .addPhoto(buildSharePhoto(\"<LINK_3>\")) .addPhoto(buildSharePhoto(\"<LINK_4>\")) .build(); ShareContentValidation.validateForMessage(sharePhotoContent); }', 'targets': array([   44,    71,   317,  2845,  6196,    19, 19993,   834,  7795,\n",
            "        5559,   748,   511,    43,    15,     7,  5559,  7795,   890,\n",
            "        2719,  7795,   890,    16,    33,     7,  5559,  7795,   890,\n",
            "           8,   404,    43,     7,     8,   117,  7795,     9,   591,\n",
            "        5559,  7795,  2457,   184,  2697,   727,     7,     8,   117,\n",
            "        7795,     9,   591,  5559,  7795,  2457,   184, 16209,   727,\n",
            "           7,     8,   117,  7795,     9,   591,  5559,  7795,  2457,\n",
            "         184, 23559,   727,     7,     8,   117,  7795,     9,   591,\n",
            "        5559,  7795,  2457,   184,   985,   727,     7,     8,   117,\n",
            "        7795,     9,   591,  5559,  7795,  2457,   184,   248,   727,\n",
            "           7,     8,   117,  7795,     9,   591,  5559,  7795,  2457,\n",
            "         184,  5638,   727,     7,     8,   117,  7795,     9,   591,\n",
            "        5559,  7795,  2457,   184,  9864,   727,     7,     8,   591,\n",
            "          39,     7,  5559,   890,  3052,     8,  2855,   642,   511,\n",
            "           9,  7145,  7795,   890,    18,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code2code: CircuitBreakerRegistry createCircuitBreakerRegistry( CircuitBreakerConfigurationProperties circuitBreakerProperties, RegistryEventConsumer<CircuitBreaker> circuitBreakerRegistryEventConsumer, CompositeCustomizer<CircuitBreakerConfigCustomizer> customizerMap) { Map<String, CircuitBreakerConfig> configs = circuitBreakerProperties.getConfigs() .entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, entry -> circuitBreakerProperties .createCircuitBreakerConfig(entry.getKey(), entry.getValue(), customizerMap))); return CircuitBreakerRegistry.of(configs, circuitBreakerRegistryEventConsumer, circuitBreakerProperties.getTags()); }', 'inputs': array([   89,   111,   220,    20,     7, 23186,  1576,   168, 23186,\n",
            "        1576,     9,     7, 23186,   423,   786,     7, 31326,   786,\n",
            "          11,     7,  1576,   566,  2252,    40, 23186,    32,     7,\n",
            "       31326,  1576,   566,  2252,    11,  6938, 10500,    40, 23186,\n",
            "         436, 10500,    32, 28141,   216,    12,    15,   400,    40,\n",
            "          50,    11,     7, 23186,   436,    32, 15903,    16,     7,\n",
            "       31326,   786,     8,  6477,    19,    43,     7,     8,  1795,\n",
            "          81,   589,    81,  1322,     9,  1763,     8,  6385,     9,\n",
            "         216,     8,   458,   948,  1163,    11,   527,   296,     7,\n",
            "       31326,   786,     7,     8,   396, 23186,   436,     9,   934,\n",
            "           8,  1163,   145,   527,     8,   639,   145, 28141,   216,\n",
            "        2024,    42,     7, 23186,  1576,     8,   676,     9,   967,\n",
            "          19,    11,     7, 31326,  1576,   566,  2252,    11,     7,\n",
            "       31326,   786,     8, 16508,    93,    13,     1], dtype=int32), 'targets_pretokenized': b'CircuitBreakerRegistry createCircuitBreakerRegistry( CircuitBreakerConfigurationProperties circuitBreakerProperties, RegistryEventConsumer<CircuitBreaker> circuitBreakerRegistryEventConsumer, CompositeCustomizer<CircuitBreakerConfigCustomizer> customizerMap) { Map<String, CircuitBreakerConfig> configs = circuitBreakerProperties.getConfigs() .entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, entry -> circuitBreakerProperties .createCircuitBreakerConfig(entry.getKey(), entry.getValue(), customizerMap))); return CircuitBreakerRegistry.of(configs, circuitBreakerRegistryEventConsumer, Map.copyOf(circuitBreakerProperties.getTags())); }', 'targets': array([    7, 23186,  1576,   168, 23186,  1576,     9,     7, 23186,\n",
            "         423,   786,     7, 31326,   786,    11,     7,  1576,   566,\n",
            "        2252,    40, 23186,    32,     7, 31326,  1576,   566,  2252,\n",
            "          11,  6938, 10500,    40, 23186,   436, 10500,    32, 28141,\n",
            "         216,    12,    15,   400,    40,    50,    11,     7, 23186,\n",
            "         436,    32, 15903,    16,     7, 31326,   786,     8,  6477,\n",
            "          19,    43,     7,     8,  1795,    81,   589,    81,  1322,\n",
            "           9,  1763,     8,  6385,     9,   216,     8,   458,   948,\n",
            "        1163,    11,   527,   296,     7, 31326,   786,     7,     8,\n",
            "         396, 23186,   436,     9,   934,     8,  1163,   145,   527,\n",
            "           8,   639,   145, 28141,   216,  2024,    42,     7, 23186,\n",
            "        1576,     8,   676,     9,   967,    19,    11,     7, 31326,\n",
            "        1576,   566,  2252,    11,   400,     8,  5291,     9, 31326,\n",
            "         786,     8, 16508,   878,    13,     1], dtype=int32)}\n",
            "2nd TASK : code 2 comment\n",
            "A few raw validation examples...\n",
            "{'input': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }', 'output': b'Also here applies the same: An alternative would be to get the current scene over the window: window.getScene() The benefit would be in reducing code (variable definitions and object injections)'}\n",
            "{'input': b'public int hashCode() { return element.hashCode(); }', 'output': b\"What I'm missing here is the check if the element is null. I know that the probability is very low, but still...\"}\n",
            "{'input': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }', 'output': b'Use Util.isBlank'}\n",
            "A few raw training examples...\n",
            "{'input': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollection(input, s -> new LinkedList<>()); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }', 'output': b'you can use unmarshallCollectionUnbounded() when the collection constructor does not need the size'}\n",
            "{'input': b'public static Command<Set<Cookie>> getAllCookies() { return new Command<>(domainName + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", new TypeToken<Set<Cookie>>() {}.getType())); }', 'output': b\"Selenium already has a org.openqa.selenium.Cookie. There will be lower friction with other parts of the Selenium APIs if we return extant Selenium types. I think it's fine to extend those types to be more meaningful if necessary.\"}\n",
            "{'input': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if (blockIn instanceof BlockPistonBase) { final IBlockState blockstate = this.getBlockState(pos); EnumFacing direction = (EnumFacing) blockstate.getValue(BlockDirectional.FACING); BlockPistonStructureHelper movedBlocks = new BlockPistonStructureHelper(this$, pos, direction, eventId == 0); List<BlockPos> blocks = new ArrayList<BlockPos>(); blocks.addAll(movedBlocks.getBlocksToDestroy()); blocks.addAll(movedBlocks.getBlocksToMove()); List<Location<org.spongepowered.api.world.World>> locations = new ArrayList<Location<org.spongepowered.api.world.World>>(); for (BlockPos block : blocks) { locations.add(new Location<>((org.spongepowered.api.world.World) this$, block.getX(), block.getY(), block.getZ())); } if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos, locations)) { return false; } } else { if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos)) { return false; } } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }', 'output': b\"You're not filtering block positions that have already been added, since there can be multiple duplications of locations being added.\"}\n",
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'code2comment: public static List<String> getCountryCodes (HttpServletRequest request) throws DocumentException { List<String> countryCodes = new ArrayList<>(); File dataFile = new File(request.getSession().getServletContext().getRealPath(\"files/country-code-iso-3166-all.xml\")); SAXReader reader = new SAXReader(); Document dataDoc = reader.read(dataFile); List<Node> nodes = dataDoc.selectNodes(\" for (Node node : nodes) { countryCodes.add(node.getStringValue().trim()); } return countryCodes; }', 'inputs': array([   89,   111,  6392,    20,    44,    83,   170,    40,    50,\n",
            "          32,    99, 21687,    19,    23,  2373,   229,   185,    12,\n",
            "         169,  2037,    66,    15,   170,    40,    50,    32,     7,\n",
            "       19468,    19,    16,    33,   266,   737,   375,   137,   253,\n",
            "          16,    33,   375,     9,   573,     8,  4114,    81,    62,\n",
            "        4555,    81, 16643,    46,  3335,    55,  6281,    35,   220,\n",
            "          35, 10515,  7024, 21940,    35,  1606,     8,   328,   598,\n",
            "        5928,  1093,  1106,    16,    33,  5928,  1093,    39,  2037,\n",
            "         137,  2125,    16,  1106,     8,   722,     9,   397,   253,\n",
            "          18,   170,    40,   346,    32,  1584,    16,   137,  2125,\n",
            "           8,  1201,  2858,    46,    34,    23,   346,   409,     7,\n",
            "          20,  1584,    12,    15,     7, 19468,    19,     8,   117,\n",
            "           9,   974,     8, 12455,    81,  1468,    93,    13,    42,\n",
            "           7, 19468,    19,    24,    13,     1], dtype=int32), 'targets_pretokenized': b'This does the job, but presents the user a long list of unsorted codes. Please make this a code => name map, so the user can choose from the country names.', 'targets': array([ 108,  236,   10,  914,   11,  112, 1566,   19,   10,  264,   17,\n",
            "        281,  141,   26, 1172, 4743, 6526,    8, 1548,  245,   36,   17,\n",
            "         89,   16,   32,   97,  295,   11,  133,   10,  264,   52, 2015,\n",
            "         76,   10, 4389,  824,    8,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code2comment: private static String propertiesAsString(Properties properties) { StringBuilder props = new StringBuilder(); boolean apos = false; for(Object obj : properties.keySet()) { String value = (String) properties.get(obj); if(apos) { props.append(\"\\'\"); } props.append((String) obj + \">\" + value); apos = true; } return props.toString(); }', 'inputs': array([  89,  111, 6392,   20,  124,   83,   53,  541, 4817,    9,  786,\n",
            "        541,   12,   15,  672, 2446,   16,   33,  672,   39,  193,   17,\n",
            "       1557,   16,  207,   24,   34,    9,  199,  791,    7,   20,  541,\n",
            "          8, 2499,  101,   15,   53,   80,   16,   23,   50,   12,  541,\n",
            "          8,   62,    9, 1263,   18,   28,    9,  157, 1557,   12,   15,\n",
            "       2446,    8,  231,   46,   29,   78,   13, 2446,    8,  231,    9,\n",
            "          9,   50,   12,  791,   61,   41,   32,   54,   61,   80,   18,\n",
            "         17, 1557,   16,  175,   24,   13,   42, 2446,    8,  260,   39,\n",
            "         13,    1], dtype=int32), 'targets_pretokenized': b'properties.get(obj).toString() would be safer in theory, because Properties can hold not only Strings', 'targets': array([  541,     8,    62,     9,  1263,   147,   260,    43,   140,\n",
            "          45, 13684,    31,  8690,    11,   240,  2127,    52,  2293,\n",
            "          56,   153,    53,    19,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code2comment: public boolean equals(Object obj) { if (obj instanceof GridProfileId) { final GridProfileId other = (GridProfileId) obj; if (this.gp.getPort() == other.gp.getPort()) { final String thisHost = this.gp.getHost(); final String otherHost = other.gp.getHost(); if (thisHost != null) { if (thisHost.equals(otherHost)) { return this.getMemberId().equals(other.getMemberId()); } } else { return (otherHost == null); } } } return false; }', 'inputs': array([   89,   111,  6392,    20,    44,   193,     7,   247,     9,\n",
            "         199,   791,    12,    15,    28,    23,  1263,   472,  4366,\n",
            "        2369,   183,    12,    15,    90,  4366,  2369,   183,   182,\n",
            "          16,    23,  2970,  2369,   183,    12,   791,    24,    28,\n",
            "          23,   188,     8, 11749,     8,  7465,    43,    85,   182,\n",
            "           8, 11749,     8,  7465,   101,    15,    90,    53,    36,\n",
            "        2309,    16,    36,     8, 11749,     8,  7416,    39,    90,\n",
            "          53,   182,  2309,    16,   182,     8, 11749,     8,  7416,\n",
            "          39,    28,    23,   188,  2309,   125,    49,    12,    15,\n",
            "          28,    23,   188,  2309,     8,   247,     9,  2109,  2309,\n",
            "         195,    15,    42,    36,     8, 15891,   183,    81,   247,\n",
            "           9,  2109,     8, 15891,   183,    93,    13,    13,   121,\n",
            "          15,    42,    23,  2109,  2309,    85,    49,    18,    13,\n",
            "          13,    13,    42,   207,    24,    13,     1], dtype=int32), 'targets_pretokenized': b\"Should we use getMemberId().getUniqueId() here instead of just getMemberId(), as that's what we are using to calculate the hashCode?.\", 'targets': array([ 4441,   354,    67,     7, 15891,   183,    81,    62, 14964,\n",
            "          43,   241,   285,    26,   166,     7, 15891,   183,   145,\n",
            "          64,    38,    29,    19,   204,   354,    63,   103,    14,\n",
            "        2405,    10,  2899,   176,     8,     1], dtype=int32)}\n",
            "3rd TASK : code and comment 2 code\n",
            "A few raw validation examples...\n",
            "{'input': b'<code>public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }</code><technical_language>applies same: alternative get current scene window: window.getScene() benefit in reducing code (variable definitions object injections)</technical_language>', 'output': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); } }); executor.submit(task); }'}\n",
            "{'input': b'<code>public int hashCode() { <START> return element.hashCode(); <END> }</code><technical_language>missing is check if element is null. I probability is low, still..</technical_language>', 'output': b'public int hashCode() { if (element == null) { return super.hashCode(); } return element.hashCode(); }'}\n",
            "{'input': b'<code>private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }</code><technical_language>Util.isBlank</technical_language>', 'output': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (!Util.isBlank(domainClassExpression) && !Util.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(EEFExpressionUtils.SELF, this.variableManager.getVariables().get(EEFExpressionUtils.SELF)); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }'}\n",
            "A few raw training examples...\n",
            "{'input': b'<code>public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: <START> return MarshallUtil.unmarshallCollection(input, s -> new LinkedList<>()); <END> case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }</code><technical_language>unmarshallCollectionUnbounded() collection constructor need size</technical_language>', 'output': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollectionUnbounded(input, LinkedList::new); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }'}\n",
            "{'input': b'<code><START> public static Command<Set<Cookie>> getAllCookies() { <END> return new Command<>(domainName + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", new TypeToken<Set<Cookie>>() {}.getType())); }</code><technical_language>Selenium a org.openqa.selenium.Cookie. friction other parts of Selenium APIs if return extant Selenium types. I fine extend types more meaningful if necessary</technical_language>', 'output': b'public static Command<Cookies> getAllCookies() { return new Command<>(DOMAIN_NAME + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", Cookies.class)); }'}\n",
            "{'input': b'<code>public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if (blockIn instanceof BlockPistonBase) { final IBlockState blockstate = this.getBlockState(pos); EnumFacing direction = (EnumFacing) blockstate.getValue(BlockDirectional.FACING); BlockPistonStructureHelper movedBlocks = new BlockPistonStructureHelper(this$, pos, direction, eventId == 0); List<BlockPos> blocks = new ArrayList<BlockPos>(); blocks.addAll(movedBlocks.getBlocksToDestroy()); blocks.addAll(movedBlocks.getBlocksToMove()); List<Location<org.spongepowered.api.world.World>> locations = new ArrayList<Location<org.spongepowered.api.world.World>>(); for (BlockPos block : blocks) { <START> locations.add(new Location<>((org.spongepowered.api.world.World) this$, block.getX(), block.getY(), block.getZ())); <END> } if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos, locations)) { return false; } } else { if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos)) { return false; } } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }</code><technical_language>filtering block positions added, multiple duplications of locations added</technical_language>', 'output': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if ((blockIn instanceof BlockPistonBase && SpongeCommonEventFactory.handlePistonEvent(this, list, obj, pos, blockIn, eventId, eventParam)) || SpongeCommonEventFactory.callChangeBlockEventPre(this, pos, NamedCause.of(NamedCause.BLOCK_EVENT, this)).isCancelled()) { return false; } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }'}\n",
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'code&comment2code: <code>public KualiDecimal getOtherNewTotalBilledForAwardPeriod(ContractsGrantsInvoiceDocument contractsGrantsInvoiceDocument) { KualiDecimal newTotalBilled = KualiDecimal.ZERO; <START> Map<String, String> fieldValuesForInvoice = new HashMap<String, String>(); <END> fieldValuesForInvoice.put(ArPropertyConstants.ContractsGrantsInvoiceDocumentFields.PROPOSAL_NUMBER, contractsGrantsInvoiceDocument.getInvoiceGeneralDetail().getProposalNumber().toString()); fieldValuesForInvoice.put(ArPropertyConstants.INVOICE_GENERAL_DETAIL+\".\"+ArPropertyConstants.BILLING_PERIOD, contractsGrantsInvoiceDocument.getInvoiceGeneralDetail().getBillingPeriod()); fieldValuesForInvoice.put(KFSPropertyConstants.DOCUMENT_NUMBER, SearchOperator.NOT + contractsGrantsInvoiceDocument.getDocumentNumber()); if (ObjectUtils.isNotNull(contractsGrantsInvoiceDocument.getFinancialSystemDocumentHeader()) && StringUtils.isNotBlank(contractsGrantsInvoiceDocument.getFinancialSystemDocumentHeader().getFinancialDocumentInErrorNumber())) { fieldValuesForInvoice.put(KFSPropertyConstants.DOCUMENT_NUMBER, SearchOperator.NOT + contractsGrantsInvoiceDocument.getFinancialSystemDocumentHeader().getFinancialDocumentInErrorNumber()); } Collection<ContractsGrantsInvoiceDocument> cgInvoiceDocuments = retrieveAllCGInvoicesByCriteria(fieldValuesForInvoice); for (ContractsGrantsInvoiceDocument cgInvoiceDocument: cgInvoiceDocuments) { for (InvoiceAccountDetail invAcctD : cgInvoiceDocument.getAccountDetails()) { newTotalBilled = newTotalBilled.add(invAcctD.getExpenditureAmount()); } } return newTotalBilled; }</code><technical_language>fyi, HashMap<>() worked...just save extra typing next time</technical_language>', 'inputs': array([   89,   767,  6392,   111,   220,    20,     7,     3,   171,\n",
            "       26482, 13760,  6523,     7, 24781,  1604,  3399, 10785,   244,\n",
            "         642,   239, 10114,  3612,     9,  5085,    19, 10976,    19,\n",
            "        9630,  1089,     7,  1912, 10976,    19,  9630,  1089,    12,\n",
            "          15, 26482, 13760,  6523,    33,  3399, 10785,   244,    16,\n",
            "       26482, 13760,  6523,     8,     2,  7155,    24,    60,  4011,\n",
            "          32,   400,    40,    50,    11,    53,    32, 16036,  6081,\n",
            "        9630,    16,    33,   697,    40,    50,    11,    53,   625,\n",
            "          60,  3921,    32, 16036,  6081,  9630,     8,   261,     9,\n",
            "       14819,   677,  1176,     8,  5085,    19, 10976,    19,  9630,\n",
            "        1089,  1828,     8,  6958,  4509,  4342,    25,  4682,    11,\n",
            "           7,  1912, 10976,    19,  9630,  1089,     8,    62,  9630,\n",
            "        8442,  3021,    81,    62,  7779,   654,    81,   260,    93,\n",
            "       16036,  6081,  9630,     8,   261,     9, 14819,   677,  1176,\n",
            "           8,  2150, 27538,    25, 25863,    25, 14552,  2198,     8,\n",
            "        2878, 14819,   677,  1176,     8,   399, 23694,  2890,    25,\n",
            "       22253,    11,     7,  1912, 10976,    19,  9630,  1089,     8,\n",
            "          62,  9630,  8442,  3021,    81,    62, 11478,  3612,    93,\n",
            "       16036,  6081,  9630,     8,   261,     9,   613,  4572,   677,\n",
            "        1176,     8,  7679,    25,  4682,    11,  4171,  3215,     8,\n",
            "        2889,    61,     7,  1912, 10976,    19,  9630,  1089,     8,\n",
            "        5803,   654,    93,    28,    23,   199,   725,     8, 19921,\n",
            "           9,  1912, 10976,    19,  9630,  1089,     8, 16872, 14826,\n",
            "        6119,  6369,   575,  1089,  1142,   101,   190,  3457,     8,\n",
            "       11215,     9,  1912, 10976,    19,  9630,  1089,     8, 16872,\n",
            "       14826,  6119,  6369,   575,  1089,  1142,    81, 16872, 14826,\n",
            "        6119,  6369,  1089,   563,   690,   654,  1050,    15, 16036,\n",
            "        6081,  9630,     8,   261,     9,   613,  4572,   677,  1176,\n",
            "           8,  7679,    25,  4682,    11,  4171,  3215,     8,  2889,\n",
            "          61,     7,  1912, 10976,    19,  9630,  1089,     8, 16872,\n",
            "       14826,  6119,  6369,   575,  1089,  1142,    81, 16872, 14826,\n",
            "        6119,  6369,  1089,   563,   690,   654,    93,    13,  1284,\n",
            "          40,  5085,    19, 10976,    19,  9630,  1089,    32,     7,\n",
            "       19540,  9630,  7495,    16,  1526,  1432, 17972,  9630,  6533,\n",
            "        3880,     9, 21482,  6081,  9630,    18,    34,    23,  5085,\n",
            "          19, 10976,    19,  9630,  1089,     7, 19540,  9630,  1089,\n",
            "          20,     7, 19540,  9630,  7495,    12,    15,    34,    23,\n",
            "        9630,  2248,  3021, 12033,  8923,    57,   283,     7,    20,\n",
            "           7, 19540,  9630,  1089,     8, 15592,  1711,   101,    15,\n",
            "          33,  3399, 10785,   244,    16,    33,  3399, 10785,   244,\n",
            "           8,   117,     9, 12952,  8923,    57,   283,     8,    62,\n",
            "        7078,  1042,    82,  7892,  3787,    93,    13,    13,    42,\n",
            "          33,  3399, 10785,   244,    24,    13,     4,     5, 20417,\n",
            "          82,    11,   697,  1307,    12,  1720,   416,  3378,   894,\n",
            "        1792,  7861,   525,   202,     6,     1], dtype=int32), 'targets_pretokenized': b'public KualiDecimal getOtherNewTotalBilledForAwardPeriod(ContractsGrantsInvoiceDocument contractsGrantsInvoiceDocument) { KualiDecimal newTotalBilled = KualiDecimal.ZERO; Map<String, String> fieldValuesForInvoice = new HashMap<>(); fieldValuesForInvoice.put(ArPropertyConstants.ContractsGrantsInvoiceDocumentFields.PROPOSAL_NUMBER, contractsGrantsInvoiceDocument.getInvoiceGeneralDetail().getProposalNumber().toString()); fieldValuesForInvoice.put(ArPropertyConstants.INVOICE_GENERAL_DETAIL+\".\"+ArPropertyConstants.BILLING_PERIOD, contractsGrantsInvoiceDocument.getInvoiceGeneralDetail().getBillingPeriod()); fieldValuesForInvoice.put(KFSPropertyConstants.DOCUMENT_NUMBER, SearchOperator.NOT + contractsGrantsInvoiceDocument.getDocumentNumber()); if (ObjectUtils.isNotNull(contractsGrantsInvoiceDocument.getFinancialSystemDocumentHeader()) && StringUtils.isNotBlank(contractsGrantsInvoiceDocument.getFinancialSystemDocumentHeader().getFinancialDocumentInErrorNumber())) { fieldValuesForInvoice.put(KFSPropertyConstants.DOCUMENT_NUMBER, SearchOperator.NOT + contractsGrantsInvoiceDocument.getFinancialSystemDocumentHeader().getFinancialDocumentInErrorNumber()); } Collection<ContractsGrantsInvoiceDocument> cgInvoiceDocuments = retrieveAllCGInvoicesByCriteria(fieldValuesForInvoice); for (ContractsGrantsInvoiceDocument cgInvoiceDocument: cgInvoiceDocuments) { for (InvoiceAccountDetail invAcctD : cgInvoiceDocument.getAccountDetails()) { newTotalBilled = newTotalBilled.add(invAcctD.getExpenditureAmount()); } } return newTotalBilled; }', 'targets': array([   44, 26482, 13760,  6523,     7, 24781,  1604,  3399, 10785,\n",
            "         244,   642,   239, 10114,  3612,     9,  5085,    19, 10976,\n",
            "          19,  9630,  1089,     7,  1912, 10976,    19,  9630,  1089,\n",
            "          12,    15, 26482, 13760,  6523,    33,  3399, 10785,   244,\n",
            "          16, 26482, 13760,  6523,     8,     2,  7155,    24,   400,\n",
            "          40,    50,    11,    53,    32, 16036,  6081,  9630,    16,\n",
            "          33,   697,   737, 16036,  6081,  9630,     8,   261,     9,\n",
            "       14819,   677,  1176,     8,  5085,    19, 10976,    19,  9630,\n",
            "        1089,  1828,     8,  6958,  4509,  4342,    25,  4682,    11,\n",
            "           7,  1912, 10976,    19,  9630,  1089,     8,    62,  9630,\n",
            "        8442,  3021,    81,    62,  7779,   654,    81,   260,    93,\n",
            "       16036,  6081,  9630,     8,   261,     9, 14819,   677,  1176,\n",
            "           8,  2150, 27538,    25, 25863,    25, 14552,  2198,     8,\n",
            "        2878, 14819,   677,  1176,     8,   399, 23694,  2890,    25,\n",
            "       22253,    11,     7,  1912, 10976,    19,  9630,  1089,     8,\n",
            "          62,  9630,  8442,  3021,    81,    62, 11478,  3612,    93,\n",
            "       16036,  6081,  9630,     8,   261,     9,   613,  4572,   677,\n",
            "        1176,     8,  7679,    25,  4682,    11,  4171,  3215,     8,\n",
            "        2889,    61,     7,  1912, 10976,    19,  9630,  1089,     8,\n",
            "        5803,   654,    93,    28,    23,   199,   725,     8, 19921,\n",
            "           9,  1912, 10976,    19,  9630,  1089,     8, 16872, 14826,\n",
            "        6119,  6369,   575,  1089,  1142,   101,   190,  3457,     8,\n",
            "       11215,     9,  1912, 10976,    19,  9630,  1089,     8, 16872,\n",
            "       14826,  6119,  6369,   575,  1089,  1142,    81, 16872, 14826,\n",
            "        6119,  6369,  1089,   563,   690,   654,  1050,    15, 16036,\n",
            "        6081,  9630,     8,   261,     9,   613,  4572,   677,  1176,\n",
            "           8,  7679,    25,  4682,    11,  4171,  3215,     8,  2889,\n",
            "          61,     7,  1912, 10976,    19,  9630,  1089,     8, 16872,\n",
            "       14826,  6119,  6369,   575,  1089,  1142,    81, 16872, 14826,\n",
            "        6119,  6369,  1089,   563,   690,   654,    93,    13,  1284,\n",
            "          40,  5085,    19, 10976,    19,  9630,  1089,    32,     7,\n",
            "       19540,  9630,  7495,    16,  1526,  1432, 17972,  9630,  6533,\n",
            "        3880,     9, 21482,  6081,  9630,    18,    34,    23,  5085,\n",
            "          19, 10976,    19,  9630,  1089,     7, 19540,  9630,  1089,\n",
            "          20,     7, 19540,  9630,  7495,    12,    15,    34,    23,\n",
            "        9630,  2248,  3021, 12033,  8923,    57,   283,     7,    20,\n",
            "           7, 19540,  9630,  1089,     8, 15592,  1711,   101,    15,\n",
            "          33,  3399, 10785,   244,    16,    33,  3399, 10785,   244,\n",
            "           8,   117,     9, 12952,  8923,    57,   283,     8,    62,\n",
            "        7078,  1042,    82,  7892,  3787,    93,    13,    13,    42,\n",
            "          33,  3399, 10785,   244,    24,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code&comment2code: <code>public void init(InstructorAttributes currentInstructor, CourseDetailsBundle courseDetails, List<InstructorAttributes> instructors, List<StudentAttributes> students) { this.currentInstructor = currentInstructor; this.courseDetails = courseDetails; this.instructors = instructors; boolean isDisabled = !currentInstructor.isAllowedForPrivilege( Const.ParamsNames.INSTRUCTOR_PERMISSION_GIVE_COMMENT_IN_SECTIONS); <START> String content = \"<span class=\\\\\"glyphicon glyphicon-comment glyphicon-primary\\\\\"></span>\"; <END> giveCommentButton = createButton(content, \"btn btn-default btn-xs icon-button pull-right\", \"button_add_comment\", null, \"\", \"tooltip\", null, isDisabled); isDisabled = !currentInstructor.isAllowedForPrivilege(Const.ParamsNames.INSTRUCTOR_PERMISSION_MODIFY_STUDENT); String onClick = \"if(toggleSendRegistrationKeysConfirmation(\\'\" + Sanitizer.sanitizeForJs(courseDetails.course.id) + \"\\')) \" + \"window.location.href=\\'\" + Sanitizer.sanitizeForJs(getInstructorCourseRemindLink()) + \"\\';\"; courseRemindButton = createButton(null, \"btn btn-primary\", \"button_remind\", null, Const.Tooltips.COURSE_REMIND, \"tooltip\", onClick, isDisabled); studentsTable = new CourseDetailsStudentsTable(); int studentIndex = 0; for (StudentAttributes student : students) { CourseDetailsStudentsTableRow row = createStudentsTableRow(studentIndex, student); studentsTable.getRows().add(row); studentIndex++; } }</code><technical_language>Is a more informative name content? I mean, I content of ElementTag (as attribute name suggests), is HTML in content? represent? Some sort of icon? (this too)</technical_language>', 'inputs': array([   89,   767,  6392,   111,   220,    20,     7,     3,   171,\n",
            "          71,  1423,     9,   563,  8723,   367,  1507,   282,   563,\n",
            "        8723,   367,    11, 16197,  1711,  1417,  1186,  1711,    11,\n",
            "         170,    40,   563,  8723,   367,  1507,    32, 11035,   367,\n",
            "          19,    11,   170,    40,  3541,  1507,    32,  7422,    12,\n",
            "          15,    36,     8,  1030,   563,  8723,   367,    16,   282,\n",
            "         563,  8723,   367,    24,    36,     8,  9486,  1711,    16,\n",
            "        1186,  1711,    24,    36,     8,   289,  8723,   367,    19,\n",
            "          16, 11035,   367,    19,    24,   193,     7, 28754,    16,\n",
            "         782,  1030,   563,  8723,   367,     8,   249,  4492,   642,\n",
            "       21501,     9, 12300,     8,  1685,  1433,     8,  2150, 22907,\n",
            "        3596,    25, 10388,    25,   965, 13159,    25, 12926,    25,\n",
            "        2150,    25, 17339,   284,    18,    60,  4011,    32,    53,\n",
            "         522,    16,  2928,  3536,    68,  3370, 12367,  3572,     7,\n",
            "       12367,  3572,    35,  6392,     7, 12367,  3572,    35,  8166,\n",
            "         268,  6449,  3536,  8368,    60,  3921,    32,   884,  4381,\n",
            "         818,    16,   168,   818,     9,   941,    11,    41,  3909,\n",
            "        3618,    35,  1481,  3618,    35,  5348,  2812,    35,  1709,\n",
            "        5241,    35,  1982,    86,    41,  1709,    25,   117,    25,\n",
            "        6392,    86,    49,    11,  8927,    41, 31260,    86,    49,\n",
            "          11,     7, 28754,    18,     7, 28754,    16,   782,  1030,\n",
            "         563,  8723,   367,     8,   249,  4492,   642, 21501,     9,\n",
            "       14102,     8,  1685,  1433,     8,  2150, 22907,  3596,    25,\n",
            "       10388,    25, 25497,    25, 26652,    18,    53,  2426,    16,\n",
            "          41,   467,     9, 17405,  5196,  3857,  2079, 19925, 20643,\n",
            "          61,     7, 31301,     8, 17264,   642,  7535,     9,  9486,\n",
            "        1711,     8,  9486,     8,   163,    12,    61,    41,    29,\n",
            "         195,    41,    61,    41,  3811,     8,  2130,     8,  6673,\n",
            "       12030,    61,     7, 31301,     8, 17264,   642,  7535,     9,\n",
            "       13627,  8723,   367,  8871,  2614,  1141,    94,  1530,   101,\n",
            "          61,    41,    29,    24,   366,  1186,  2614,  1141,    94,\n",
            "         818,    16,   168,   818,     9,   353,    11,    41,  3909,\n",
            "        3618,    35,  8166,    86,    41,  1709,    25,   165,  1141,\n",
            "          94,    86,    49,    11, 12300,     8, 15868,    19,     8,\n",
            "        7700, 17098,  4569,    25, 27782, 25305,    11,    41, 31260,\n",
            "          86,  2426,    11,     7, 28754,    18,  7422,   645,    16,\n",
            "          33, 16197,  1711, 11572,   645,    39,    75,  3939,   413,\n",
            "          16,   186,    34,    23,  3541,  1507,  3939,     7,    20,\n",
            "        7422,    12,    15, 16197,  1711, 11572, 12683,   565,    16,\n",
            "         168, 11572, 12683,     9,  6328,   413,    11,  3939,    18,\n",
            "        7422,   645,     8, 21137,    81,   117,     9,  1187,    18,\n",
            "        3939,   413,   848,    13,    13,     4,     5,  2197,    17,\n",
            "         178, 25087,    97,   522,   176,    48,  1300,    11,    48,\n",
            "         522,    26,  2656,  1195,    23,   756,   687,    97,  5808,\n",
            "         334,    21,  1613,    31,   522,   176,  2669,   176,  1840,\n",
            "        1222,    26,  2812,   176,    23,   188,   819,    12,     6,\n",
            "           1], dtype=int32), 'targets_pretokenized': b'public void init(InstructorAttributes currentInstructor, CourseDetailsBundle courseDetails, List<InstructorAttributes> instructors, List<StudentAttributes> students) { this.currentInstructor = currentInstructor; this.courseDetails = courseDetails; this.instructors = instructors; boolean isDisabled = !currentInstructor.isAllowedForPrivilege( Const.ParamsNames.INSTRUCTOR_PERMISSION_GIVE_COMMENT_IN_SECTIONS); String content = \"<span class=\\\\\"glyphicon glyphicon-comment glyphicon-primary\\\\\"></span>\"; giveCommentButton = createButton(content, \"btn btn-default btn-xs icon-button pull-right\", \"button_add_comment\", null, \"\", \"tooltip\", null, isDisabled); isDisabled = !currentInstructor.isAllowedForPrivilege(Const.ParamsNames.INSTRUCTOR_PERMISSION_MODIFY_STUDENT); String onClick = \"if(toggleSendRegistrationKeysConfirmation(\\'\" + sanitizeForJs(courseDetails.course.id) + \"\\')) \" + \"window.location.href=\\'\" + sanitizeForJs(getInstructorCourseRemindLink()) + \"\\';\"; courseRemindButton = createButton(null, \"btn btn-primary\", \"button_remind\", null, Const.Tooltips.COURSE_REMIND, \"tooltip\", onClick, isDisabled); studentsTable = new CourseDetailsStudentsTable(); int studentIndex = 0; List<CourseDetailsStudentsTableRow> studentTableRows = new ArrayList<CourseDetailsStudentsTableRow>(); for (StudentAttributes student : students) { CourseDetailsStudentsTableRow row = createStudentsTableRow(studentIndex, student); studentTableRows.add(row); studentIndex++; } studentsTable.setRows(studentTableRows); }', 'targets': array([   44,    71,  1423,     9,   563,  8723,   367,  1507,   282,\n",
            "         563,  8723,   367,    11, 16197,  1711,  1417,  1186,  1711,\n",
            "          11,   170,    40,   563,  8723,   367,  1507,    32, 11035,\n",
            "         367,    19,    11,   170,    40,  3541,  1507,    32,  7422,\n",
            "          12,    15,    36,     8,  1030,   563,  8723,   367,    16,\n",
            "         282,   563,  8723,   367,    24,    36,     8,  9486,  1711,\n",
            "          16,  1186,  1711,    24,    36,     8,   289,  8723,   367,\n",
            "          19,    16, 11035,   367,    19,    24,   193,     7, 28754,\n",
            "          16,   782,  1030,   563,  8723,   367,     8,   249,  4492,\n",
            "         642, 21501,     9, 12300,     8,  1685,  1433,     8,  2150,\n",
            "       22907,  3596,    25, 10388,    25,   965, 13159,    25, 12926,\n",
            "          25,  2150,    25, 17339,   284,    18,    53,   522,    16,\n",
            "        2928,  3536,    68,  3370, 12367,  3572,     7, 12367,  3572,\n",
            "          35,  6392,     7, 12367,  3572,    35,  8166,   268,  6449,\n",
            "        3536,  8368,   884,  4381,   818,    16,   168,   818,     9,\n",
            "         941,    11,    41,  3909,  3618,    35,  1481,  3618,    35,\n",
            "        5348,  2812,    35,  1709,  5241,    35,  1982,    86,    41,\n",
            "        1709,    25,   117,    25,  6392,    86,    49,    11,  8927,\n",
            "          41, 31260,    86,    49,    11,     7, 28754,    18,     7,\n",
            "       28754,    16,   782,  1030,   563,  8723,   367,     8,   249,\n",
            "        4492,   642, 21501,     9, 14102,     8,  1685,  1433,     8,\n",
            "        2150, 22907,  3596,    25, 10388,    25, 25497,    25, 26652,\n",
            "          18,    53,  2426,    16,    41,   467,     9, 17405,  5196,\n",
            "        3857,  2079, 19925, 20643,    61,     7, 17264,   642,  7535,\n",
            "           9,  9486,  1711,     8,  9486,     8,   163,    12,    61,\n",
            "          41,    29,   195,    41,    61,    41,  3811,     8,  2130,\n",
            "           8,  6673, 12030,    61,     7, 17264,   642,  7535,     9,\n",
            "       13627,  8723,   367,  8871,  2614,  1141,    94,  1530,   101,\n",
            "          61,    41,    29,    24,   366,  1186,  2614,  1141,    94,\n",
            "         818,    16,   168,   818,     9,   353,    11,    41,  3909,\n",
            "        3618,    35,  8166,    86,    41,  1709,    25,   165,  1141,\n",
            "          94,    86,    49,    11, 12300,     8, 15868,    19,     8,\n",
            "        7700, 17098,  4569,    25, 27782, 25305,    11,    41, 31260,\n",
            "          86,  2426,    11,     7, 28754,    18,  7422,   645,    16,\n",
            "          33, 16197,  1711, 11572,   645,    39,    75,  3939,   413,\n",
            "          16,   186,   170,    40,  8871,  1711, 11572, 12683,    32,\n",
            "        3939, 12683,    19,    16,    33,   266,    40,  8871,  1711,\n",
            "       11572, 12683,   625,    34,    23,  3541,  1507,  3939,     7,\n",
            "          20,  7422,    12,    15, 16197,  1711, 11572, 12683,   565,\n",
            "          16,   168, 11572, 12683,     9,  6328,   413,    11,  3939,\n",
            "          18,  3939, 12683,    19,     8,   117,     9,  1187,    18,\n",
            "        3939,   413,   848,    13,  7422,   645,     8, 18745,    19,\n",
            "           9,  6328, 12683,    19,    18,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code&comment2code: <code>public void close(final long timeoutMs) throws InterruptedException, TimeoutException, ExecutionException { <START> <END> }</code><technical_language>throw new NotImplementedException();</technical_language>', 'inputs': array([   89,   767,  6392,   111,   220,    20,     7,     3,   171,\n",
            "          71,  1081,     9,   230,   281,  1712,  8566,    12,   169,\n",
            "        2853,    66,    11,     7,  7502,    11,  5887,    66,    15,\n",
            "          60,  4011,    32,    60,  3921,    32,    13,     4,     5,\n",
            "        7548,    33,     7, 27318,    66,    39,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'public void close(final long timeoutMs) throws InterruptedException, TimeoutException, ExecutionException { throw new NotImplementedException(); }', 'targets': array([   44,    71,  1081,     9,   230,   281,  1712,  8566,    12,\n",
            "         169,  2853,    66,    11,     7,  7502,    11,  5887,    66,\n",
            "          15,   161,    33,     7, 27318,    66,    39,    13,     1],\n",
            "      dtype=int32)}\n",
            "4th TASK : marked code 2 code\n",
            "A few raw validation examples...\n",
            "{'input': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }', 'output': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); } }); executor.submit(task); }'}\n",
            "{'input': b'public int hashCode() { <START> return element.hashCode(); <END> }', 'output': b'public int hashCode() { if (element == null) { return super.hashCode(); } return element.hashCode(); }'}\n",
            "{'input': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }', 'output': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (!Util.isBlank(domainClassExpression) && !Util.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(EEFExpressionUtils.SELF, this.variableManager.getVariables().get(EEFExpressionUtils.SELF)); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }'}\n",
            "A few raw training examples...\n",
            "{'input': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: <START> return MarshallUtil.unmarshallCollection(input, s -> new LinkedList<>()); <END> case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }', 'output': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollectionUnbounded(input, LinkedList::new); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }'}\n",
            "{'input': b'<START> public static Command<Set<Cookie>> getAllCookies() { <END> return new Command<>(domainName + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", new TypeToken<Set<Cookie>>() {}.getType())); }', 'output': b'public static Command<Cookies> getAllCookies() { return new Command<>(DOMAIN_NAME + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", Cookies.class)); }'}\n",
            "{'input': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if (blockIn instanceof BlockPistonBase) { final IBlockState blockstate = this.getBlockState(pos); EnumFacing direction = (EnumFacing) blockstate.getValue(BlockDirectional.FACING); BlockPistonStructureHelper movedBlocks = new BlockPistonStructureHelper(this$, pos, direction, eventId == 0); List<BlockPos> blocks = new ArrayList<BlockPos>(); blocks.addAll(movedBlocks.getBlocksToDestroy()); blocks.addAll(movedBlocks.getBlocksToMove()); List<Location<org.spongepowered.api.world.World>> locations = new ArrayList<Location<org.spongepowered.api.world.World>>(); for (BlockPos block : blocks) { <START> locations.add(new Location<>((org.spongepowered.api.world.World) this$, block.getX(), block.getY(), block.getZ())); <END> } if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos, locations)) { return false; } } else { if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos)) { return false; } } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }', 'output': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if ((blockIn instanceof BlockPistonBase && SpongeCommonEventFactory.handlePistonEvent(this, list, obj, pos, blockIn, eventId, eventParam)) || SpongeCommonEventFactory.callChangeBlockEventPre(this, pos, NamedCause.of(NamedCause.BLOCK_EVENT, this)).isCancelled()) { return false; } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }'}\n",
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'markedCode2code: public String getTimestamp() { <START> return new SimpleDateFormat(\"yyyyMMddHHmmss\").format(new Date()); <END> }', 'inputs': array([ 4447,   830,   111,   220,    20,    44,    53,     7, 11867,\n",
            "          43,    15,    60,  4011,    32,    42,    33,     7,  1475,\n",
            "          46, 20830, 29615,   778,   579,     9,    98,   879,    93,\n",
            "          60,  3921,    32,    13,     1], dtype=int32), 'targets_pretokenized': b'public String getTimestamp() { return DATE_FORMAT.format(new Date()); }', 'targets': array([   44,    53,     7, 11867,    43,    15,    42, 15920,    25,\n",
            "        4889,     8,   579,     9,    98,   879,    93,    13,     1],\n",
            "      dtype=int32)}\n",
            "{'inputs_pretokenized': b'markedCode2code: public <T extends Item> T update(final T item) { final ItemConfiguration itemConfiguration = getItemConfiguration(item.getClass()); if (item.getVersion() == null) { return create(item); } final Collection<PropertyDescriptor> updatedUniqueConstraintPropertyDescriptors = new HashSet<>(); T previousItem = null; if (!itemConfiguration.uniqueConstraints().isEmpty()) { final ItemId itemId = itemConfiguration.getItemId(item); previousItem = readWithOnlyUniqueConstraintProperties(itemId, itemConfiguration); final Collection<UniqueConstraint> updatedUniqueConstraints = getUpdatedUniqueConstraints(item, previousItem, itemConfiguration); for (final UniqueConstraint uniqueConstraint : updatedUniqueConstraints) { updatedUniqueConstraintPropertyDescriptors.add(uniqueConstraint.propertyDescriptor()); } createUniqueConstraintIndexes(item, itemConfiguration, updatedUniqueConstraintPropertyDescriptors); } final long newVersion = item.getVersion() + 1; final Map<String, AttributeValue> attributeMap = getAttributeMap(item, itemConfiguration, newVersion); final Map<String, ExpectedAttributeValue> expectedResults = new HashMap<>(); expectedResults.put(VERSION_ATTRIBUTE, new ExpectedAttributeValue(new AttributeValue().withN(String.valueOf(item.getVersion())))); final String tableName = databaseSchemaHolder.schemaName() + \".\" + itemConfiguration.tableName(); final PutItemRequest itemRequest = new PutItemRequest().withTableName(tableName).withItem(attributeMap) .withExpected(expectedResults); try { amazonDynamoDbClient.putItem(itemRequest); if (!updatedUniqueConstraintPropertyDescriptors.isEmpty()) { deleteUniqueConstraintIndexes(previousItem, itemConfiguration, updatedUniqueConstraintPropertyDescriptors); } } catch (final ConditionalCheckFailedException conditionalCheckFailedException) { if (!updatedUniqueConstraintPropertyDescriptors.isEmpty()) { deleteUniqueConstraintIndexes(item, itemConfiguration, updatedUniqueConstraintPropertyDescriptors); } <START> throw new OptimisticLockException(\"Conflicting write detected while updating item\"); <END> } catch (final AmazonServiceException amazonServiceException) { if (!updatedUniqueConstraintPropertyDescriptors.isEmpty()) { deleteUniqueConstraintIndexes(item, itemConfiguration, updatedUniqueConstraintPropertyDescriptors); } throw new PersistenceResourceFailureException(\"Failure while attempting DynamoDb Put (update item)\", amazonServiceException); } item.setVersion(newVersion); return item; }', 'inputs': array([ 4447,   830,   111,   220,    20,    44,    60,   146,   272,\n",
            "        4264,    32,   468,   442,     9,   230,   468,   557,    12,\n",
            "          15,    90,  4264,   423,   557,   423,    16, 11032,   423,\n",
            "           9,   714,     8,   850,    93,    28,    23,   714,     8,\n",
            "        6128,    43,    85,    49,    12,    15,    42,   168,     9,\n",
            "         714,    18,    13,    90,  1284,    40,   677,  1573,    32,\n",
            "        1561, 30179,   677, 10179,    16,    33,  1635,   737,   468,\n",
            "        1175,   576,    16,    49,    24,    28,   387,   714,   423,\n",
            "           8,  7019,  5983,    81,   764,   101,    15,    90,     7,\n",
            "       14329, 18859,    16,   557,   423,     8, 14655,     9,   714,\n",
            "          18,  1175,   576,    16,   277,   811,  3075, 30179,   786,\n",
            "           9, 20714,    11,   557,   423,    18,    90,  1284,    40,\n",
            "       30179,    32,  1561, 30179,    19,    16,    99,  6771, 30179,\n",
            "          19,     9,   714,    11,  1175,   576,    11,   557,   423,\n",
            "          18,    34,    23,   230,     7, 30179,  1656,  3462,     7,\n",
            "          20,  1561, 30179,    19,    12,    15,  1561, 30179,   677,\n",
            "       10179,     8,   117,     9,  7019,  3462,     8,   844,  1573,\n",
            "          93,    13,   168, 30179,  7740,     9,   714,    11,   557,\n",
            "         423,    11,  1561, 30179,   677, 10179,    18,    13,    90,\n",
            "         281,    33,   954,    16,   557,     8,  6128,    43,    61,\n",
            "         643,    90,   400,    40,    50,    11,     7,  6543,    32,\n",
            "         687,   216,    16,     7,  2361,   216,     9,   714,    11,\n",
            "         557,   423,    11,    33,   954,    18,    90,   400,    40,\n",
            "          50,    11, 11701,  6543,    32,  1025,  2492,    16,    33,\n",
            "         697,   737,  1025,  2492,     8,   261,     9,  2681,    25,\n",
            "        5971,    11,    33, 11701,  6543,     9,    98,     7,  6543,\n",
            "          81,   720,   772,     9,    50,     8,   881,     9,   714,\n",
            "           8,  6128,  1050,   164,    90,    53,  5337,    16,   482,\n",
            "        1772,  2114,     8,  3068,   150,    43,    61,  5138,    61,\n",
            "         557,   423,     8,  8253,    39,    90,  3550,   576,   229,\n",
            "         557,   229,    16,    33,  3550,   576,   229,    81,   720,\n",
            "        5866,     9,  8253,   147,   720,   576,     9,  2581,   216,\n",
            "          12,     7,     8,   720,  4241,     9,  4127,  2492,    18,\n",
            "         123,    15,     7, 17624, 25008,  4631,  3366,   588,     8,\n",
            "         261,   576,     9,   714,   229,    18,    28,   387,  9800,\n",
            "       30179,   677, 10179,     8,   764,   101,    15,   975, 30179,\n",
            "        7740,     9,  4661,   576,    11,   557,   423,    11,  1561,\n",
            "       30179,   677, 10179,    18,    13,    13,   172,    23,   230,\n",
            "           7,  9899,  2054,  9870,  5599,  2054,  9870,    12,    15,\n",
            "          28,   387,  9800, 30179,   677, 10179,     8,   764,   101,\n",
            "          15,   975, 30179,  7740,     9,   714,    11,   557,   423,\n",
            "          11,  1561, 30179,   677, 10179,    18,    13,    60,  4011,\n",
            "          32,   161,    33,     7, 29424,    66,    46, 12178,   209,\n",
            "         377,  6420,   219,  3928,   557,    78,    60,  3921,    32,\n",
            "          13,   172,    23,   230,  2516,  7063,     7, 17624,  7063,\n",
            "          12,    15,    28,   387,  9800, 30179,   677, 10179,     8,\n",
            "         764,   101,    15,   975, 30179,  7740,     9,   714,    11,\n",
            "         557,   423,    11,  1561, 30179,   677, 10179,    18,    13,\n",
            "         161,    33,  6998,   571, 13677,    46,  3649,   219,  5336,\n",
            "           7, 25008,  4631,  3366,  3550,    23,  1123,   557,    12,\n",
            "          86,     7, 17624,  7063,    18,    13,   557,     8, 19968,\n",
            "           9,    98,   954,    18,    42,   557,    24,    13,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'public <T extends Item> T update(final T item) { final ItemConfiguration itemConfiguration = getItemConfiguration(item.getClass()); if (item.getVersion() == null) { return create(item); } final Collection<PropertyDescriptor> updatedUniqueConstraintPropertyDescriptors = new HashSet<>(); T previousItem = null; if (!itemConfiguration.uniqueConstraints().isEmpty()) { final ItemId itemId = itemConfiguration.getItemId(item); previousItem = readWithOnlyUniqueConstraintProperties(itemId, itemConfiguration); final Collection<UniqueConstraint> updatedUniqueConstraints = getUpdatedUniqueConstraints(item, previousItem, itemConfiguration); for (final UniqueConstraint uniqueConstraint : updatedUniqueConstraints) { updatedUniqueConstraintPropertyDescriptors.add(uniqueConstraint.propertyDescriptor()); } createUniqueConstraintIndexes(item, itemConfiguration, updatedUniqueConstraintPropertyDescriptors); } final long newVersion = item.getVersion() + 1; final Map<String, AttributeValue> attributeMap = getAttributeMap(item, itemConfiguration, newVersion); final Map<String, ExpectedAttributeValue> expectedResults = new HashMap<>(); expectedResults.put(VERSION_ATTRIBUTE, new ExpectedAttributeValue(new AttributeValue().withN(String.valueOf(item.getVersion())))); final String tableName = databaseSchemaHolder.schemaName() + \".\" + itemConfiguration.tableName(); final PutItemRequest itemRequest = new PutItemRequest().withTableName(tableName).withItem(attributeMap) .withExpected(expectedResults); boolean itemRequestSucceeded = false; try { amazonDynamoDbClient.putItem(itemRequest); itemRequestSucceeded = true; } catch (final ConditionalCheckFailedException conditionalCheckFailedException) { throw new OptimisticLockException(\"Conflicting write detected while updating item\"); } catch (final AmazonServiceException amazonServiceException) { throw new PersistenceResourceFailureException(\"Failure while attempting DynamoDb Put (update item)\", amazonServiceException); } finally { if (!itemRequestSucceeded) { try { deleteUniqueConstraintIndexes(item, itemConfiguration, updatedUniqueConstraintPropertyDescriptors); } catch (final Exception deleteUniqueConstraintIndexesException) { logger.error(deleteUniqueConstraintIndexesException.getMessage(), deleteUniqueConstraintIndexesException); } } } deleteUniqueConstraintIndexes(previousItem, itemConfiguration, updatedUniqueConstraintPropertyDescriptors); item.setVersion(newVersion); return item; }', 'targets': array([   44,    60,   146,   272,  4264,    32,   468,   442,     9,\n",
            "         230,   468,   557,    12,    15,    90,  4264,   423,   557,\n",
            "         423,    16, 11032,   423,     9,   714,     8,   850,    93,\n",
            "          28,    23,   714,     8,  6128,    43,    85,    49,    12,\n",
            "          15,    42,   168,     9,   714,    18,    13,    90,  1284,\n",
            "          40,   677,  1573,    32,  1561, 30179,   677, 10179,    16,\n",
            "          33,  1635,   737,   468,  1175,   576,    16,    49,    24,\n",
            "          28,   387,   714,   423,     8,  7019,  5983,    81,   764,\n",
            "         101,    15,    90,     7, 14329, 18859,    16,   557,   423,\n",
            "           8, 14655,     9,   714,    18,  1175,   576,    16,   277,\n",
            "         811,  3075, 30179,   786,     9, 20714,    11,   557,   423,\n",
            "          18,    90,  1284,    40, 30179,    32,  1561, 30179,    19,\n",
            "          16,    99,  6771, 30179,    19,     9,   714,    11,  1175,\n",
            "         576,    11,   557,   423,    18,    34,    23,   230,     7,\n",
            "       30179,  1656,  3462,     7,    20,  1561, 30179,    19,    12,\n",
            "          15,  1561, 30179,   677, 10179,     8,   117,     9,  7019,\n",
            "        3462,     8,   844,  1573,    93,    13,   168, 30179,  7740,\n",
            "           9,   714,    11,   557,   423,    11,  1561, 30179,   677,\n",
            "       10179,    18,    13,    90,   281,    33,   954,    16,   557,\n",
            "           8,  6128,    43,    61,   643,    90,   400,    40,    50,\n",
            "          11,     7,  6543,    32,   687,   216,    16,     7,  2361,\n",
            "         216,     9,   714,    11,   557,   423,    11,    33,   954,\n",
            "          18,    90,   400,    40,    50,    11, 11701,  6543,    32,\n",
            "        1025,  2492,    16,    33,   697,   737,  1025,  2492,     8,\n",
            "         261,     9,  2681,    25,  5971,    11,    33, 11701,  6543,\n",
            "           9,    98,     7,  6543,    81,   720,   772,     9,    50,\n",
            "           8,   881,     9,   714,     8,  6128,  1050,   164,    90,\n",
            "          53,  5337,    16,   482,  1772,  2114,     8,  3068,   150,\n",
            "          43,    61,  5138,    61,   557,   423,     8,  8253,    39,\n",
            "          90,  3550,   576,   229,   557,   229,    16,    33,  3550,\n",
            "         576,   229,    81,   720,  5866,     9,  8253,   147,   720,\n",
            "         576,     9,  2581,   216,    12,     7,     8,   720,  4241,\n",
            "           9,  4127,  2492,    18,   193,   557,   229, 23327,    16,\n",
            "         207,    24,   123,    15,     7, 17624, 25008,  4631,  3366,\n",
            "         588,     8,   261,   576,     9,   714,   229,    18,   557,\n",
            "         229, 23327,    16,   175,    24,    13,   172,    23,   230,\n",
            "           7,  9899,  2054,  9870,  5599,  2054,  9870,    12,    15,\n",
            "         161,    33,     7, 29424,    66,    46, 12178,   209,   377,\n",
            "        6420,   219,  3928,   557,    78,    13,   172,    23,   230,\n",
            "        2516,  7063,     7, 17624,  7063,    12,    15,   161,    33,\n",
            "        6998,   571, 13677,    46,  3649,   219,  5336,     7, 25008,\n",
            "        4631,  3366,  3550,    23,  1123,   557,    12,    86,     7,\n",
            "       17624,  7063,    18,    13,   713,    15,    28,   387,   714,\n",
            "         229, 23327,    12,    15,   123,    15,   975, 30179,  7740,\n",
            "           9,   714,    11,   557,   423,    11,  1561, 30179,   677,\n",
            "       10179,    18,    13,   172,    23,   230,     7,    66,   975,\n",
            "       30179,  7740,    66,    12,    15,   821,     8,   750,     9,\n",
            "        1607, 30179,  7740,    66,     8,   866,   145,   975, 30179,\n",
            "        7740,    66,    18,    13,    13,    13,   975, 30179,  7740,\n",
            "           9,  4661,   576,    11,   557,   423,    11,  1561, 30179,\n",
            "         677, 10179,    18,   557,     8, 19968,     9,    98,   954,\n",
            "          18,    42,   557,    24,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'markedCode2code: public LockResponse lock(LockRequest request) { <START> long startTime = System.nanoTime(); <END> LeasableLockResponse leasableResponse = delegate.leasableLock(request); LockResponse lockResponse = leasableResponse.getLockResponse(); Optional<Duration> leasePeriod = leasableResponse.getLeasePeriod(); if (lockResponse.wasSuccessful()) { updateLockLeases(lockResponse.getToken(), startTime, leasePeriod); } return lockResponse; }', 'inputs': array([ 4447,   830,   111,   220,    20,    44,  8639,   462,  1088,\n",
            "           9,  1967,   229,   185,    12,    15,    60,  4011,    32,\n",
            "         281,  5613,    16,   120,     8,  5616,    39,    60,  3921,\n",
            "          32,     7, 10901,   756,   512,  1967,   462,     7,  2838,\n",
            "         756,   512,   462,    16,  3252,     8,  2838,   756,   512,\n",
            "        1967,     9,   573,    18,  8639,   462,  1088,   462,    16,\n",
            "           7,  2838,   756,   512,   462,     8, 17355,   462,    39,\n",
            "        1510,    40,  3040,    32,     7, 17638,  3612,    16,     7,\n",
            "        2838,   756,   512,   462,     8,    62, 18895,  3612,    39,\n",
            "          28,    23,  2208,   462,     8,  9642, 13033,   101,    15,\n",
            "         442,  1967, 18895,    19,     9,  2208,   462,     8,  9056,\n",
            "         145,  5613,    11,     7, 17638,  3612,    18,    13,    42,\n",
            "        1088,   462,    24,    13,     1], dtype=int32), 'targets_pretokenized': b'public LockResponse lock(LockRequest request) { LeasableLockResponse leasableResponse = delegate.lockV2(request); LockResponse lockResponse = leasableResponse.getLockResponse(); Lease lease = leasableResponse.getLease(); if (lockResponse.wasSuccessful()) { LeasedLockToken leasedLockToken = LeasedLockToken.of(lockResponse.getToken(), lease); return ImmutableLockResponse.of(Optional.of(leasedLockToken)); } return LockResponse.timedOut(); }', 'targets': array([   44,  8639,   462,  1088,     9,  1967,   229,   185,    12,\n",
            "          15,     7, 10901,   756,   512,  1967,   462,     7,  2838,\n",
            "         756,   512,   462,    16,  3252,     8,  2208,   631,   111,\n",
            "           9,   573,    18,  8639,   462,  1088,   462,    16,     7,\n",
            "        2838,   756,   512,   462,     8, 17355,   462,    39,     7,\n",
            "       18895,     7, 17638,    16,     7,  2838,   756,   512,   462,\n",
            "           8,    62, 18895,    39,    28,    23,  2208,   462,     8,\n",
            "        9642, 13033,   101,    15,     7, 18895,    94,  1967,   935,\n",
            "           7, 17638,    94,  1967,   935,    16,     7, 18895,    94,\n",
            "        1967,   935,     8,   676,     9,  2208,   462,     8,  9056,\n",
            "         145,     7, 17638,    18,    42,  8399,  1967,   462,     8,\n",
            "         676,     9,  2382,     8,   676,     9, 17638,    94,  1967,\n",
            "         935,   164,    13,    42,  8639,   462,     8,   667,    94,\n",
            "        1761,    39,    13,     1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Qx699vN302"
      },
      "source": [
        "def _rate_num_input_examples(task):\n",
        "  if \"train\" in task.splits:\n",
        "    return float(task.num_input_examples(\"train\"))\n",
        "  elif \"validation\" in task.splits:\n",
        "    return float(task.num_input_examples(\"validation\"))\n",
        "  else:\n",
        "    raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"all_tasks\",\n",
        "    # [\"code_comment\"],\n",
        "    # [\"marked_code\"],\n",
        "    # [\"code_code\"],\n",
        "    # [\"codeANDcomment_code\"],\n",
        "    [\"codeANDcomment_code\", \"code_code\", \"code_comment\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        "     #default_rate=1.0\n",
        ")\n",
        "\n",
        "\n",
        "# from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular \n",
        "\n",
        "# from mesh_tensorflow.transformer.learning_rate_schedules import truncated_rsqrt\n",
        " \n",
        "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "starter_learning_rate = 0.05\n",
        "end_learning_rate = 0.001\n",
        "decay_steps = 10000\n",
        "\n",
        "learning_rate_fn = PolynomialDecay(\n",
        "    starter_learning_rate,\n",
        "    decay_steps,\n",
        "    end_learning_rate,\n",
        "    power=0.5)\n",
        "\n",
        "\n",
        "MODEL_SIZE = \"small\"\n",
        "\n",
        "############ CHANGE HERE ############\n",
        "MODEL_DIR = 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/polynomial'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://code_review_automation/model_dumps/'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 128, 200),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    ############ CHANGE HERE ############\n",
        "    learning_rate_schedule = learning_rate_fn,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=10000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guHsDBYHv69m",
        "outputId": "5166021f-8832-41a5-8a63-bdf70a7800a2"
      },
      "source": [
        "############ CHANGE HERE ############\n",
        "!gsutil cp gs://code_review_automation/fine_tuning/polynomial/operative_config.gin ./operative_config.gin \n",
        "PATH_GIN_FILE = '/content/operative_config.gin'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://code_review_automation/fine_tuning/polynomial/operative_config.gin...\n",
            "/ [0 files][    0.0 B/ 11.2 KiB]                                                \r/ [1 files][ 11.2 KiB/ 11.2 KiB]                                                \r\n",
            "Operation completed over 1 objects/11.2 KiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhmkUKWgNFAX",
        "outputId": "200a96b0-78df-4ccf-cf97-3b6845dc78f6"
      },
      "source": [
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 75000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"all_tasks\",\n",
        "        pretrained_model_dir=PRETRAINED_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://code_review_automation/model_dumps/operative_config.gin\n",
            "ERROR:root:Path not found: gs://code_review_automation/model_dumps/operative_config.gin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/polynomial', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.98.60.74:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.98.60.74:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.98.60.74:8470', '_evaluation_master': 'grpc://10.98.60.74:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f1d3da7c8d0>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.98.60.74:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.98.60.74:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 611828079442253204)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 4898463858140156874)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -638734622530197394)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4142439317658307879)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 2908957357688161356)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -7882450800288259589)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1526024672372314121)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, -7577610857267824893)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 5571325752867350454)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -1701676076311946199)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -8520141453847754328)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('vocab', 'model'), ('heads', 'model'), ('d_ff', 'model'), ('batch', 'batch'), ('experts', 'batch'), ('ensemble', 'ensemble')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1d3fde1d90>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 105     Total size: 60691328         Total slice_size: 60691328       \n",
            "INFO:tensorflow:Counters:\n",
            "allreduce: 6.85e+08\n",
            " allreduce/[0]: 6.85e+08\n",
            "  allreduce/[0]/einsum_op: 4.84e+08\n",
            "  allreduce/[0]/reduce_op: 2.01e+08\n",
            "einsum: 2.03e+13\n",
            "einsum_unique: 2.03e+13\n",
            "output: 1.87e+11\n",
            " output/AddOperation: 3.37e+10\n",
            " output/BinaryOpWithBroadcasting: 2.28e+09\n",
            " output/BroadcastOperation: 1.01e+10\n",
            " output/Constant: 8\n",
            " output/EinsumOperation: 7.47e+10\n",
            " output/ImportOperation: 3.15e+06\n",
            " output/MinMaxOperation: 3.78e+07\n",
            " output/OneHotOperation: 7.12e+09\n",
            " output/RandomOperation: 1.48e+07\n",
            " output/RangeOperation: 8.19e+03\n",
            " output/ReduceOperation: 4.07e+09\n",
            " output/ReshapeOperation: 6.91e+09\n",
            " output/ScalarAddOperation: 5.36e+08\n",
            " output/ScalarMultiplyOperation: 1.87e+09\n",
            " output/ShiftOperation: 1.31e+05\n",
            " output/SlicewiseOperation: 3.87e+10\n",
            " output/StackOperation: 1.35e+06\n",
            " output/StackedVariable: 1.35e+06\n",
            " output/StopGradient: 6.94e+09\n",
            " output/UnstackOperation: 1.35e+06\n",
            " output/Variable: 4.84e+08\n",
            "output_unique: 1.8e+11\n",
            " output_unique/AddOperation: 3.34e+10\n",
            " output_unique/BinaryOpWithBroadcasting: 2.24e+09\n",
            " output_unique/BroadcastOperation: 1.01e+10\n",
            " output_unique/Constant: 1\n",
            " output_unique/EinsumOperation: 7.14e+10\n",
            " output_unique/ImportOperation: 3.94e+05\n",
            " output_unique/MinMaxOperation: 4.78e+06\n",
            " output_unique/OneHotOperation: 6.42e+09\n",
            " output_unique/RandomOperation: 1.48e+07\n",
            " output_unique/RangeOperation: 1.02e+03\n",
            " output_unique/ReduceOperation: 3.89e+09\n",
            " output_unique/ReshapeOperation: 6.91e+09\n",
            " output_unique/ScalarAddOperation: 6.89e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.78e+09\n",
            " output_unique/ShiftOperation: 1.31e+05\n",
            " output_unique/SlicewiseOperation: 3.64e+10\n",
            " output_unique/StackOperation: 1.69e+05\n",
            " output_unique/StackedVariable: 1.69e+05\n",
            " output_unique/StopGradient: 6.94e+09\n",
            " output_unique/UnstackOperation: 1.69e+05\n",
            " output_unique/Variable: 6.05e+07\n",
            "variables: 6.07e+07\n",
            " variables/trainable: 6.05e+07\n",
            " variables/untrainable: 1.85e+05\n",
            "INFO:tensorflow:Initializing variables from gs://code_review_automation/model_dumps/model.ckpt-200000:\n",
            "INFO:tensorflow:Variables in gs://code_review_automation/model_dumps/model.ckpt-200000 but not in graph:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Variables in graph but not in gs://code_review_automation/model_dumps/model.ckpt-200000:\n",
            "INFO:tensorflow:\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Starting the session.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 200000...\n",
            "INFO:tensorflow:Saving checkpoints for 200000 into gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/polynomial/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 200000...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:773: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 200000...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 200000 into gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/polynomial/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 200000...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:loss = 0.16210938, step = 200100\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (1, 92)\n",
            "INFO:tensorflow:loss = 0.12695312, step = 200200 (32.025 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.12256\n",
            "INFO:tensorflow:examples/sec: 399.687\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.10205078, step = 200300 (31.908 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.13406\n",
            "INFO:tensorflow:examples/sec: 401.16\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (3, 84)\n",
            "INFO:tensorflow:loss = 0.10888672, step = 200400 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25531\n",
            "INFO:tensorflow:examples/sec: 416.68\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.10107422, step = 200500 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25534\n",
            "INFO:tensorflow:examples/sec: 416.683\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (5, 80)\n",
            "INFO:tensorflow:loss = 0.08886719, step = 200600 (30.716 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25562\n",
            "INFO:tensorflow:examples/sec: 416.719\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.11425781, step = 200700 (31.745 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15008\n",
            "INFO:tensorflow:examples/sec: 403.21\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (7, 72)\n",
            "INFO:tensorflow:loss = 0.11230469, step = 200800 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25519\n",
            "INFO:tensorflow:examples/sec: 416.664\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.10058594, step = 200900 (30.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.255\n",
            "INFO:tensorflow:examples/sec: 416.64\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (9, 68)\n",
            "INFO:tensorflow:loss = 0.08984375, step = 201000 (31.906 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.13418\n",
            "INFO:tensorflow:examples/sec: 401.175\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.100097656, step = 201100 (30.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25494\n",
            "INFO:tensorflow:examples/sec: 416.632\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (11, 60)\n",
            "INFO:tensorflow:loss = 0.10644531, step = 201200 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25524\n",
            "INFO:tensorflow:examples/sec: 416.67\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.087890625, step = 201300 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25506\n",
            "INFO:tensorflow:examples/sec: 416.648\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 56)\n",
            "INFO:tensorflow:loss = 0.10546875, step = 201400 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25528\n",
            "INFO:tensorflow:examples/sec: 416.675\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.10058594, step = 201500 (31.734 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15117\n",
            "INFO:tensorflow:examples/sec: 403.35\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (15, 49)\n",
            "INFO:tensorflow:loss = 0.09326172, step = 201600 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25509\n",
            "INFO:tensorflow:examples/sec: 416.652\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.10498047, step = 201700 (30.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25484\n",
            "INFO:tensorflow:examples/sec: 416.619\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (17, 45)\n",
            "INFO:tensorflow:loss = 0.09814453, step = 201800 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25524\n",
            "INFO:tensorflow:examples/sec: 416.67\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.09814453, step = 201900 (31.880 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.13675\n",
            "INFO:tensorflow:examples/sec: 401.504\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (19, 37)\n",
            "INFO:tensorflow:loss = 0.10205078, step = 202000 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25533\n",
            "INFO:tensorflow:examples/sec: 416.682\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.092285156, step = 202100 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25529\n",
            "INFO:tensorflow:examples/sec: 416.678\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (21, 33)\n",
            "INFO:tensorflow:loss = 0.092285156, step = 202200 (31.881 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.13669\n",
            "INFO:tensorflow:examples/sec: 401.497\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.09667969, step = 202300 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25519\n",
            "INFO:tensorflow:examples/sec: 416.664\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (23, 25)\n",
            "INFO:tensorflow:loss = 0.09863281, step = 202400 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25525\n",
            "INFO:tensorflow:examples/sec: 416.672\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.08691406, step = 202500 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25515\n",
            "INFO:tensorflow:examples/sec: 416.66\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (25, 21)\n",
            "INFO:tensorflow:loss = 0.091308594, step = 202600 (30.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25504\n",
            "INFO:tensorflow:examples/sec: 416.645\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.083496094, step = 202700 (31.869 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.13773\n",
            "INFO:tensorflow:examples/sec: 401.63\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 13)\n",
            "INFO:tensorflow:loss = 0.103515625, step = 202800 (30.724 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25486\n",
            "INFO:tensorflow:examples/sec: 416.622\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.09667969, step = 202900 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25506\n",
            "INFO:tensorflow:examples/sec: 416.647\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (29, 9)\n",
            "INFO:tensorflow:loss = 0.07763672, step = 203000 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25522\n",
            "INFO:tensorflow:examples/sec: 416.668\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.08105469, step = 203100 (31.890 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.13575\n",
            "INFO:tensorflow:examples/sec: 401.376\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (31, 1)\n",
            "INFO:tensorflow:loss = 0.095703125, step = 203200 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25522\n",
            "INFO:tensorflow:examples/sec: 416.668\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (32, 97)\n",
            "INFO:tensorflow:loss = 0.08886719, step = 203300 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25515\n",
            "INFO:tensorflow:examples/sec: 416.66\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07910156, step = 203400 (31.741 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15048\n",
            "INFO:tensorflow:examples/sec: 403.261\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 89)\n",
            "INFO:tensorflow:loss = 0.08984375, step = 203500 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25525\n",
            "INFO:tensorflow:examples/sec: 416.672\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.09326172, step = 203600 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25522\n",
            "INFO:tensorflow:examples/sec: 416.668\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (36, 85)\n",
            "INFO:tensorflow:loss = 0.08691406, step = 203700 (30.724 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25474\n",
            "INFO:tensorflow:examples/sec: 416.606\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.09814453, step = 203800 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25524\n",
            "INFO:tensorflow:examples/sec: 416.671\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (38, 77)\n",
            "INFO:tensorflow:loss = 0.087890625, step = 203900 (31.918 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.133\n",
            "INFO:tensorflow:examples/sec: 401.024\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.08935547, step = 204000 (30.726 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25457\n",
            "INFO:tensorflow:examples/sec: 416.585\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (40, 73)\n",
            "INFO:tensorflow:loss = 0.08642578, step = 204100 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25528\n",
            "INFO:tensorflow:examples/sec: 416.676\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.09375, step = 204200 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25535\n",
            "INFO:tensorflow:examples/sec: 416.685\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (42, 65)\n",
            "INFO:tensorflow:loss = 0.080078125, step = 204300 (32.007 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.12437\n",
            "INFO:tensorflow:examples/sec: 399.919\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0859375, step = 204400 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25517\n",
            "INFO:tensorflow:examples/sec: 416.662\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (44, 61)\n",
            "INFO:tensorflow:loss = 0.0859375, step = 204500 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25525\n",
            "INFO:tensorflow:examples/sec: 416.672\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.078125, step = 204600 (31.841 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.1406\n",
            "INFO:tensorflow:examples/sec: 401.996\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (46, 53)\n",
            "INFO:tensorflow:loss = 0.07470703, step = 204700 (30.716 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25555\n",
            "INFO:tensorflow:examples/sec: 416.711\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.08251953, step = 204800 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25538\n",
            "INFO:tensorflow:examples/sec: 416.689\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (48, 49)\n",
            "INFO:tensorflow:loss = 0.0859375, step = 204900 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25517\n",
            "INFO:tensorflow:examples/sec: 416.661\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.08105469, step = 205000 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25516\n",
            "INFO:tensorflow:examples/sec: 416.661\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (50, 41)\n",
            "INFO:tensorflow:loss = 0.080566406, step = 205100 (31.819 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.14282\n",
            "INFO:tensorflow:examples/sec: 402.281\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.091308594, step = 205200 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25513\n",
            "INFO:tensorflow:examples/sec: 416.657\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (52, 37)\n",
            "INFO:tensorflow:loss = 0.087402344, step = 205300 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25517\n",
            "INFO:tensorflow:examples/sec: 416.662\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.06982422, step = 205400 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25544\n",
            "INFO:tensorflow:examples/sec: 416.696\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (54, 29)\n",
            "INFO:tensorflow:loss = 0.091796875, step = 205500 (31.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.1488\n",
            "INFO:tensorflow:examples/sec: 403.046\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07714844, step = 205600 (30.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25495\n",
            "INFO:tensorflow:examples/sec: 416.633\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (56, 25)\n",
            "INFO:tensorflow:loss = 0.095703125, step = 205700 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25502\n",
            "INFO:tensorflow:examples/sec: 416.642\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07324219, step = 205800 (31.830 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.14173\n",
            "INFO:tensorflow:examples/sec: 402.141\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (58, 17)\n",
            "INFO:tensorflow:loss = 0.08105469, step = 205900 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25516\n",
            "INFO:tensorflow:examples/sec: 416.661\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.08300781, step = 206000 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25524\n",
            "INFO:tensorflow:examples/sec: 416.671\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (60, 13)\n",
            "INFO:tensorflow:loss = 0.072265625, step = 206100 (30.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25488\n",
            "INFO:tensorflow:examples/sec: 416.625\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07421875, step = 206200 (30.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25496\n",
            "INFO:tensorflow:examples/sec: 416.635\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (62, 6)\n",
            "INFO:tensorflow:loss = 0.080078125, step = 206300 (31.690 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15555\n",
            "INFO:tensorflow:examples/sec: 403.91\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07470703, step = 206400 (30.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25508\n",
            "INFO:tensorflow:examples/sec: 416.65\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (64, 2)\n",
            "INFO:tensorflow:loss = 0.079589844, step = 206500 (30.717 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25544\n",
            "INFO:tensorflow:examples/sec: 416.696\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (65, 98)\n",
            "INFO:tensorflow:loss = 0.080566406, step = 206600 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25532\n",
            "INFO:tensorflow:examples/sec: 416.681\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07910156, step = 206700 (31.705 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15408\n",
            "INFO:tensorflow:examples/sec: 403.723\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (67, 91)\n",
            "INFO:tensorflow:loss = 0.08886719, step = 206800 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25533\n",
            "INFO:tensorflow:examples/sec: 416.682\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0859375, step = 206900 (30.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25498\n",
            "INFO:tensorflow:examples/sec: 416.638\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (69, 87)\n",
            "INFO:tensorflow:loss = 0.084472656, step = 207000 (31.695 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15507\n",
            "INFO:tensorflow:examples/sec: 403.849\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.072265625, step = 207100 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25521\n",
            "INFO:tensorflow:examples/sec: 416.667\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (71, 80)\n",
            "INFO:tensorflow:loss = 0.08691406, step = 207200 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25535\n",
            "INFO:tensorflow:examples/sec: 416.685\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.0703125, step = 207300 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25522\n",
            "INFO:tensorflow:examples/sec: 416.668\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (73, 76)\n",
            "INFO:tensorflow:loss = 0.083984375, step = 207400 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25536\n",
            "INFO:tensorflow:examples/sec: 416.686\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.09326172, step = 207500 (31.821 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.14257\n",
            "INFO:tensorflow:examples/sec: 402.249\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (75, 68)\n",
            "INFO:tensorflow:loss = 0.08105469, step = 207600 (30.722 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.255\n",
            "INFO:tensorflow:examples/sec: 416.64\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.084472656, step = 207700 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25511\n",
            "INFO:tensorflow:examples/sec: 416.655\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (77, 64)\n",
            "INFO:tensorflow:loss = 0.07080078, step = 207800 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25539\n",
            "INFO:tensorflow:examples/sec: 416.69\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07373047, step = 207900 (31.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15275\n",
            "INFO:tensorflow:examples/sec: 403.552\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (79, 57)\n",
            "INFO:tensorflow:loss = 0.07470703, step = 208000 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25544\n",
            "INFO:tensorflow:examples/sec: 416.697\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.075683594, step = 208100 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2554\n",
            "INFO:tensorflow:examples/sec: 416.691\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (81, 53)\n",
            "INFO:tensorflow:loss = 0.064453125, step = 208200 (31.934 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.13143\n",
            "INFO:tensorflow:examples/sec: 400.823\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07128906, step = 208300 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25533\n",
            "INFO:tensorflow:examples/sec: 416.682\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (83, 45)\n",
            "INFO:tensorflow:loss = 0.078125, step = 208400 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25514\n",
            "INFO:tensorflow:examples/sec: 416.658\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.08251953, step = 208500 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25528\n",
            "INFO:tensorflow:examples/sec: 416.676\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (85, 41)\n",
            "INFO:tensorflow:loss = 0.07470703, step = 208600 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25526\n",
            "INFO:tensorflow:examples/sec: 416.673\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.087890625, step = 208700 (31.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15007\n",
            "INFO:tensorflow:examples/sec: 403.209\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (87, 33)\n",
            "INFO:tensorflow:loss = 0.08203125, step = 208800 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25534\n",
            "INFO:tensorflow:examples/sec: 416.683\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.079589844, step = 208900 (30.716 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25558\n",
            "INFO:tensorflow:examples/sec: 416.714\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (89, 29)\n",
            "INFO:tensorflow:loss = 0.08105469, step = 209000 (30.718 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25538\n",
            "INFO:tensorflow:examples/sec: 416.688\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.088378906, step = 209100 (31.823 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.14243\n",
            "INFO:tensorflow:examples/sec: 402.23\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (91, 21)\n",
            "INFO:tensorflow:loss = 0.072265625, step = 209200 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2553\n",
            "INFO:tensorflow:examples/sec: 416.678\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.084472656, step = 209300 (30.721 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25507\n",
            "INFO:tensorflow:examples/sec: 416.649\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (93, 17)\n",
            "INFO:tensorflow:loss = 0.08203125, step = 209400 (31.813 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.1433\n",
            "INFO:tensorflow:examples/sec: 402.342\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.08203125, step = 209500 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2553\n",
            "INFO:tensorflow:examples/sec: 416.679\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (95, 9)\n",
            "INFO:tensorflow:loss = 0.06591797, step = 209600 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25527\n",
            "INFO:tensorflow:examples/sec: 416.674\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.07910156, step = 209700 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25521\n",
            "INFO:tensorflow:examples/sec: 416.667\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (97, 5)\n",
            "INFO:tensorflow:loss = 0.07470703, step = 209800 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.2553\n",
            "INFO:tensorflow:examples/sec: 416.678\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (98, 97)\n",
            "INFO:tensorflow:loss = 0.080566406, step = 209900 (31.789 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.14569\n",
            "INFO:tensorflow:examples/sec: 402.648\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 210000...\n",
            "INFO:tensorflow:Saving checkpoints for 210000 into gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/polynomial/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 210000...\n",
            "INFO:tensorflow:loss = 0.08886719, step = 210000 (38.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.61201\n",
            "INFO:tensorflow:examples/sec: 334.337\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (100, 68)\n",
            "INFO:tensorflow:loss = 0.06689453, step = 210100 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25513\n",
            "INFO:tensorflow:examples/sec: 416.657\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 210100...\n",
            "INFO:tensorflow:Before Save.\n",
            "INFO:tensorflow:About to write a checkpoint\n",
            "INFO:tensorflow:Saving checkpoints for 210100 into gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/polynomial/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 210100...\n",
            "INFO:tensorflow:Done writing checkpoint.\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.075683594, step = 210200 (38.952 sec)\n",
            "INFO:tensorflow:global_step/sec: 2.56723\n",
            "INFO:tensorflow:examples/sec: 328.606\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (102, 34)\n",
            "INFO:tensorflow:loss = 0.08251953, step = 210300 (31.732 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.15139\n",
            "INFO:tensorflow:examples/sec: 403.378\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.06982422, step = 210400 (30.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25521\n",
            "INFO:tensorflow:examples/sec: 416.666\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (104, 30)\n",
            "INFO:tensorflow:loss = 0.0703125, step = 210500 (30.719 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25537\n",
            "INFO:tensorflow:examples/sec: 416.687\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:loss = 0.06933594, step = 210600 (31.856 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.1391\n",
            "INFO:tensorflow:examples/sec: 401.805\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (106, 22)\n",
            "INFO:tensorflow:loss = 0.07421875, step = 210700 (30.723 sec)\n",
            "INFO:tensorflow:global_step/sec: 3.25493\n",
            "INFO:tensorflow:examples/sec: 416.631\n",
            "INFO:tensorflow:Enqueue next (100) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (100) batch(es) of data from outfeed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAo_rui4HXcT",
        "outputId": "77c32bd9-5b8a-4fc2-bf47-7fe508305253"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 1024\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=-1\n",
        "    )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/constant/operative_config.gin\n",
            "ERROR:root:Path not found: gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/constant/operative_config.gin\n",
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
            "INFO:absl:Skipping packing/padding for 'codeANDcomment_code' since sequence length is None.\n",
            "INFO:absl:Skipping packing/padding for 'code_code' since sequence length is None.\n",
            "INFO:absl:Skipping packing/padding for 'code_comment' since sequence length is None.\n",
            "INFO:absl:Setting sequence lengths to {'inputs': 524, 'targets': 512}\n",
            "INFO:absl:Evaluating checkpoint step: 275000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/constant', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.18.88.194:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.18.88.194:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.18.88.194:8470', '_evaluation_master': 'grpc://10.18.88.194:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7fd25c8b3490>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.18.88.194:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.18.88.194:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 4336305650953998385)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -599585225783995410)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, -5020761268541364653)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3957946833186172758)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, -1991486504658618641)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, -7575742300386215126)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -3146560936301213311)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 87887378845326749)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -7587703400912978863)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6230232682736875635)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -5206734435434322916)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'codeANDcomment_code' with sequence lengths: {'inputs': 524, 'targets': 512}\n",
            "INFO:absl:Padding 'code_code' with sequence lengths: {'inputs': 524, 'targets': 512}\n",
            "INFO:absl:Padding 'code_comment' with sequence lengths: {'inputs': 524, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('ensemble', 'ensemble'), ('d_ff', 'model'), ('heads', 'model'), ('vocab', 'model'), ('batch', 'batch'), ('experts', 'batch')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7fd15a7f4810>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.59e+06\n",
            " allconcat/0: 8.59e+06\n",
            "  allconcat/0/reshape_op: 8.59e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.54e+13\n",
            "einsum_unique: 5.54e+13\n",
            "output: 5.55e+11\n",
            " output/AddOperation: 1.43e+11\n",
            " output/BinaryOpWithBroadcasting: 1.75e+09\n",
            " output/Constant: 3.3e+09\n",
            " output/EinsumOperation: 1.26e+11\n",
            " output/ImportOperation: 8.49e+06\n",
            " output/MinMaxOperation: 4.01e+07\n",
            " output/OneHotOperation: 3.53e+10\n",
            " output/RangeOperation: 8.38e+03\n",
            " output/ReduceOperation: 1.72e+08\n",
            " output/ReshapeOperation: 2.83e+10\n",
            " output/ScalarAddOperation: 6.99e+07\n",
            " output/ScalarMultiplyOperation: 2.09e+09\n",
            " output/ShiftOperation: 5.37e+05\n",
            " output/SlicewiseOperation: 1.71e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 4.05e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.3e+09\n",
            "output_unique: 5.53e+11\n",
            " output_unique/AddOperation: 1.43e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.7e+09\n",
            " output_unique/Constant: 3.3e+09\n",
            " output_unique/EinsumOperation: 1.26e+11\n",
            " output_unique/ImportOperation: 1.06e+06\n",
            " output_unique/MinMaxOperation: 5.48e+06\n",
            " output_unique/OneHotOperation: 3.46e+10\n",
            " output_unique/RangeOperation: 1.05e+03\n",
            " output_unique/ReduceOperation: 1.72e+08\n",
            " output_unique/ReshapeOperation: 2.83e+10\n",
            " output_unique/ScalarAddOperation: 2.38e+07\n",
            " output_unique/ScalarMultiplyOperation: 2e+09\n",
            " output_unique/ShiftOperation: 5.37e+05\n",
            " output_unique/SlicewiseOperation: 1.71e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 4.05e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.3e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/mixture/constant/model.ckpt-275000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:840: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: code&comment2code: <code>public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }</code><technical_language>applies same: alternative get current scene window: window.getScene() benefit in reducing code (variable definitions object injections)</technical_language>\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: code&comment2code: <code>public int hashCode() { <START> return element.hashCode(); <END> }</code><technical_language>missing is check if element is null. I probability is low, still..</technical_language>\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: code&comment2code: <code>private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }</code><technical_language>Util.isBlank</technical_language>\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && Util.isBlank(domainClassExpression) && Util.isBlank(switchExpression) && Util.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: code&comment2code: <code>public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }</code><technical_language>brokerName equal brokerName.toLowerCase() in case observers get notified connection is in map. call brokerConnections.remove(brokerName.toLowerCase(), connection) check return value. If remove fails log.debug give a hint happened</technical_language>\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: code&comment2code: <code>private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }</code><technical_language>Is this cast safe? indexOfNode - 1 return a CoreNode always? Asserts work in production code later, in months, classes changed, asserts condition false fails. replace assert a throw IllegalStateException or... whatever</technical_language>\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if ((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: code&comment2code: <code>public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }</code><technical_language>want trim password fully safe</technical_language>\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = password != null ? Secret.fromString(password) : null; this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: code&comment2code: <code>public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }</code><technical_language>set default log a warning</technical_language>\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { this.slaveConnectTimeout = 0; } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:decoded 64: code&comment2code: <code>private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }</code><technical_language>I copied, in general assertions in middle of test is a code smell. Tests structure: // // // then. Anyway, feel free it, I a copy other class</technical_language>\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); fail(\"Should throw an exception when validator is not valid.\"); } catch (SAXException ex) { fail(\"Xml validation failed.\"); } }\n",
            "INFO:tensorflow:decoded 128: code&comment2code: <code>public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }</code><technical_language>is this caught here? This throw top class need log it. loose context here</technical_language>\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.clusterMapConfig.clusterMapResourceStatePolicyFactory = clusterMapConfig.clusterMapResourceStatePolicyFactory; this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.clusterMapConfig.clusterMapResourceStatePolicyFactory = clusterMapConfig.clusterMapResourceStatePolicyFactory; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.clusterMapConfig.clusterMapResourceStatePolicyFactory = clusterMapConfig.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.clusterMapConfig.clusterMapResourceStatePolicyFactory = clusterMapConfig.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.networkStatePolicy = networkStatePolicyFactory.networkStatePolicy; this.network\n",
            "INFO:tensorflow:decoded 256: code&comment2code: <code>protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }</code><technical_language>I this, I find a works find out if LOB compression work :(</technical_language>\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: code&comment2code: <code>public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }</code><technical_language>I d is necessary here, simplified to: mockCellsWithPadding(0, 0, PADDING, 100);</technical_language>\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: code&comment2code: <code>public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }</code><technical_language>Check if address is null</technical_language>\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"XBee64 address cannot be null.\"); if (rssi < 0 || rssi > 255) throw new IllegalArgumentException(\"RSSI address cannot be less than 0.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: code&comment2code: <code>public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }</code><technical_language>want stats.json form webpack want asset chunks. This reverted 4-8 lines of text 4-18 megabytes of text. returned content is is expected method</technical_language>\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: code&comment2code: <code>public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }</code><technical_language>This is a public method; give example used? I thought need done in constructor is: if (instance ID provided) { cluster ID = get single cluster ID instance ID. check cluster ID is input cluster ID if provided, set cluster ID in options. } else { instance ID = get single instance ID cluster ID. set instance ID in options. }</technical_language>\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: code&comment2code: <code><START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }</code><technical_language>\"@OnClick\" butterknife instead (look for other existing fragments activities for reference ClientDetailsFragment). Change this for other function</technical_language>\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(String.format(\"<LINK_0>%s\", \"<LINK_0>\", \"<LINK_0>\", \"<LINK_0>\", link(String.format(\"<LINK_0>\", getClass().getSimpleName() + \": \"))); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: code&comment2code: <code>private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }</code><technical_language>related this issue, this sort, sorted</technical_language>\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (20, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (27, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 32768: code2code: private boolean isOpenParenthesis(SyntaxToken token) { return TokenUtils.isType(token, PHPPunctuator.LPARENTHESIS); }\n",
            "INFO:tensorflow:            -> private boolean isOpenParenthesis(SyntaxToken token) { return TokenUtils.isType(token, PHPPunctuator.LPARENTHESIS); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (34, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (41, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (48, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/codeANDcomment_code/accuracy at step 275000: 9.646\n",
            "INFO:absl:eval/code_code/accuracy at step 275000: 2.916\n",
            "INFO:absl:eval/code_comment/accuracy at step 275000: 0.161\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTr15bwE6YY-"
      },
      "source": [
        "if ON_CLOUD:\n",
        "  %reload_ext tensorboard\n",
        "  import tensorboard as tb\n",
        "tb.notebook.start(\"--logdir \" + MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}