{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Finetuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masies/CRA/blob/main/Finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1MRzBLtex2",
        "outputId": "17c1748e-5440-44b1-f1ea-9abaee72458a"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip3 install --upgrade pip\n",
        "#!pip install -qU t5\n",
        "!pip3 install git+https://github.com/google-research/text-to-text-transfer-transformer.git #extra_id_x support\n",
        "\n",
        "import functools\n",
        "import os\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import t5\n",
        "\n",
        "#Set the base dir(Google cloud bucket)\n",
        "BASE_DIR = \"gs://example_comment\" \n",
        "\n",
        "if not BASE_DIR or BASE_DIR == \"gs://\":\n",
        "  raise ValueError(\"You must enter a BASE_DIR.\")\n",
        "ON_CLOUD = True\n",
        "\n",
        "\n",
        "if ON_CLOUD:\n",
        "  import tensorflow_gcs_config\n",
        "  from google.colab import auth\n",
        "  # Set credentials for GCS reading/writing from Colab and TPU.\n",
        "  TPU_TOPOLOGY = \"2x2\"\n",
        "  try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    TPU_ADDRESS = tpu.get_master()\n",
        "    print('Running on TPU:', TPU_ADDRESS)\n",
        "  except ValueError:\n",
        "    raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "  auth.authenticate_user()\n",
        "  tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "  tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "# Improve logging.\n",
        "from contextlib import contextmanager\n",
        "import logging as py_logging\n",
        "\n",
        "if ON_CLOUD:\n",
        "  tf.get_logger().propagate = False\n",
        "  py_logging.root.setLevel('INFO')\n",
        "\n",
        "@contextmanager\n",
        "def tf_verbosity_level(level):\n",
        "  og_level = tf.logging.get_verbosity()\n",
        "  tf.logging.set_verbosity(level)\n",
        "  yield\n",
        "  tf.logging.set_verbosity(og_level)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pip\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/cf/0cc542fc93de2f3b9b53cb979c7d1118cffb93204afb46299a9f858e113f/pip-21.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 7.0MB/s \n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Found existing installation: pip 19.3.1\n",
            "    Uninstalling pip-19.3.1:\n",
            "      Successfully uninstalled pip-19.3.1\n",
            "Successfully installed pip-21.1\n",
            "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\u001b[0m\n",
            "\u001b[33mWARNING: Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\u001b[0m\n",
            "Collecting git+https://github.com/google-research/text-to-text-transfer-transformer.git\n",
            "  Cloning https://github.com/google-research/text-to-text-transfer-transformer.git to /tmp/pip-req-build-30e_p2iv\n",
            "  Running command git clone -q https://github.com/google-research/text-to-text-transfer-transformer.git /tmp/pip-req-build-30e_p2iv\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (0.12.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (2.9.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (0.4.0)\n",
            "Collecting mesh-tensorflow[transformer]>=0.1.13\n",
            "  Downloading mesh_tensorflow-0.1.19-py3-none-any.whl (366 kB)\n",
            "\u001b[K     |████████████████████████████████| 366 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.1.5)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.0.4-py2.py3-none-any.whl (22 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.4.1)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 21.0 MB/s \n",
            "\u001b[?25hCollecting seqio\n",
            "  Downloading seqio-0.0.3-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 31.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.14 in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.15.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 30.8 MB/s \n",
            "\u001b[?25hCollecting tfds-nightly\n",
            "  Downloading tfds_nightly-4.2.0.dev202104250106-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 42.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5==0.9.1) (1.8.1+cu101)\n",
            "Collecting transformers>=2.7.0\n",
            "  Downloading transformers-4.5.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (4.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (20.9)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 74.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5==0.9.1) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 72.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5==0.9.1) (2018.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.9.1) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=2.7.0->t5==0.9.1) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers>=2.7.0->t5==0.9.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->t5==0.9.1) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.1) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers>=2.7.0->t5==0.9.1) (1.24.3)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.9.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=2.7.0->t5==0.9.1) (1.0.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (5.1.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (0.3.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (0.1.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (3.12.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (20.3.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (0.29.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (56.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.1) (1.53.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.9.1) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.9.1) (2.4.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.1.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (2.4.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (0.2.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (3.3.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (2.4.1)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.6.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.28.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow-text->t5==0.9.1) (3.1.0)\n",
            "Building wheels for collected packages: t5\n",
            "  Building wheel for t5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for t5: filename=t5-0.9.1-py3-none-any.whl size=152018 sha256=6424e091cc860abeeb3b3e6dc3c04d4e5151b9637a0e3b66d6eaddd16b4a2165\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-l1chyq6e/wheels/bf/e8/36/0d7b7d2aa6a91236ea133d24d501fb1faf73d6bf2579f05c96\n",
            "Successfully built t5\n",
            "Installing collected packages: tokenizers, tfds-nightly, tensorflow-text, sentencepiece, sacremoses, portalocker, mesh-tensorflow, transformers, seqio, sacrebleu, rouge-score, t5\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/tokenizers\n",
            "  sysconfig: /usr/include/python3.7m/tokenizers\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/tfds-nightly\n",
            "  sysconfig: /usr/include/python3.7m/tfds-nightly\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/tensorflow-text\n",
            "  sysconfig: /usr/include/python3.7m/tensorflow-text\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/sentencepiece\n",
            "  sysconfig: /usr/include/python3.7m/sentencepiece\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/sacremoses\n",
            "  sysconfig: /usr/include/python3.7m/sacremoses\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/portalocker\n",
            "  sysconfig: /usr/include/python3.7m/portalocker\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/mesh-tensorflow\n",
            "  sysconfig: /usr/include/python3.7m/mesh-tensorflow\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/transformers\n",
            "  sysconfig: /usr/include/python3.7m/transformers\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/seqio\n",
            "  sysconfig: /usr/include/python3.7m/seqio\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/sacrebleu\n",
            "  sysconfig: /usr/include/python3.7m/sacrebleu\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/rouge-score\n",
            "  sysconfig: /usr/include/python3.7m/rouge-score\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/t5\n",
            "  sysconfig: /usr/include/python3.7m/t5\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33m  WARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\u001b[0m\n",
            "\u001b[33m  WARNING: Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\u001b[0m\n",
            "\u001b[33mWARNING: Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\u001b[0m\n",
            "\u001b[33mWARNING: Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\u001b[0m\n",
            "Successfully installed mesh-tensorflow-0.1.19 portalocker-2.0.0 rouge-score-0.0.4 sacrebleu-1.5.1 sacremoses-0.0.45 sentencepiece-0.1.95 seqio-0.0.3 t5-0.9.1 tensorflow-text-2.4.3 tfds-nightly-4.2.0.dev202104250106 tokenizers-0.10.2 transformers-4.5.1\n",
            "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "Running on TPU: grpc://10.73.70.58:8470\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4hLh30Sn3PV"
      },
      "source": [
        "nq_tsv_path_code_code = {\n",
        "    \"train\":      'gs://code_review_automation/dataset/new/fineTuningDatasets/code_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/dataset/new/fineTuningDatasets/code_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_code_code = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_code_comment = {\n",
        "    \"train\":      'gs://code_review_automation/dataset/new/fineTuningDatasets/code_comment/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/dataset/new/fineTuningDatasets/code_comment/val.tsv'\n",
        "}\n",
        "num_nq_examples_code_comment = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_codeANDcomment_code = {\n",
        "    \"train\":      'gs://code_review_automation/dataset/new/fineTuningDatasets/codeANDcomment_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/dataset/new/fineTuningDatasets/codeANDcomment_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_codeANDcomment_code = dict(train=134442, validation=16805)\n",
        "\n",
        "nq_tsv_path_marked_code = {\n",
        "    \"train\":      'gs://code_review_automation/dataset/new/fineTuningDatasets/marked_code/train.tsv',\n",
        "    \"validation\": 'gs://code_review_automation/dataset/new/fineTuningDatasets/marked_code/val.tsv'\n",
        "}\n",
        "num_nq_examples_marked_code = dict(train=134442, validation=16805)\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNi7HPiOz27q",
        "outputId": "1061c62c-021b-4473-b07c-187774283029"
      },
      "source": [
        "from t5.data import postprocessors as t5_postprocessors\n",
        "from t5.seqio import Feature,SentencePieceVocabulary\n",
        "\n",
        "# # Set the path of sentencepiece model and vocab files\n",
        "# # Must be the same used for the pre-trained phase\n",
        "\n",
        "vocab_model_path = 'gs://code_review_automation/CodeReviewModel/TestModel.model'\n",
        "vocab_path = 'gs://code_review_automation/CodeReviewModel/TestModel.vocab'\n",
        "\n",
        "TaskRegistry = t5.data.TaskRegistry\n",
        "TfdsTask = t5.data.TfdsTask\n",
        "\n",
        "def get_default_vocabulary():\n",
        "  return SentencePieceVocabulary(vocab_model_path, 100)\n",
        "\n",
        "DEFAULT_OUTPUT_FEATURES = {\n",
        "    \"inputs\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True, required=False),\n",
        "\n",
        "    \"targets\": Feature(\n",
        "        vocabulary=get_default_vocabulary(), add_eos=True)\n",
        "}\n",
        "\n",
        "\n",
        "############### FIRST TASK ###############\n",
        "print(\"1st TASK : code 2 code\")\n",
        "\n",
        "def nq_dataset_code_code(split, shuffle_files=True):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_code_code[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code(\"validation\").take(3)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_code(\"train\").take(3)):\n",
        "  print(ex)\n",
        "\n",
        "def code_code_preprocessing(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "        inputs = tf.strings.join(['code2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "t5.data.TaskRegistry.remove('code_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"code_code\",\n",
        "    dataset_fn=nq_dataset_code_code,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[code_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_code_code\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"code_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "############### SECOND TASK ###############\n",
        "print(\"2nd TASK : code 2 comment\")\n",
        "\n",
        "def nq_dataset_code_comment(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_code_comment[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_comment(\"validation\").take(3)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_code_comment(\"train\").take(3)):\n",
        "  print(ex)\n",
        "\n",
        "def code_comment_preprocessing(ds):\n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code2comment: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('code_comment')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"code_comment\",\n",
        "    dataset_fn=nq_dataset_code_comment,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[code_comment_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_code_comment\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"code_comment\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)\n",
        "\n",
        "\n",
        "\n",
        "############### THIRD TASK ###############\n",
        "print(\"3rd TASK : code and comment 2 code\")\n",
        "\n",
        "def nq_dataset_codeANDcomment_code(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_codeANDcomment_code[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code(\"validation\").take(3)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_codeANDcomment_code(\"train\").take(3)):\n",
        "  print(ex)\n",
        "\n",
        "def codeANDcomment_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['code&comment2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('codeANDcomment_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"codeANDcomment_code\",\n",
        "    dataset_fn=nq_dataset_codeANDcomment_code,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[codeANDcomment_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_codeANDcomment_code\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"codeANDcomment_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)\n",
        "\n",
        "\n",
        "\n",
        "############### FOURTH TASK ###############\n",
        "print(\"4th TASK : marked code 2 code\")\n",
        "\n",
        "def nq_dataset_marked_code(split, shuffle_files=False):\n",
        "  # We only have one file for each split.\n",
        "  del shuffle_files\n",
        "\n",
        "  # Load lines from the text file as examples.\n",
        "  ds = tf.data.TextLineDataset(nq_tsv_path_marked_code[split])\n",
        "  ds = ds.map(\n",
        "      functools.partial(tf.io.decode_csv, record_defaults=[\"string\",\"string\"],\n",
        "                        field_delim=\"\\t\", use_quote_delim=False),\n",
        "      num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "  \n",
        "  ds = ds.map(lambda *ex: dict(zip([\"input\", \"output\"], ex)))\n",
        "  return ds\n",
        "\n",
        "print(\"A few raw validation examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_marked_code(\"validation\").take(3)):\n",
        "  print(ex)\n",
        "print(\"A few raw training examples...\")\n",
        "for ex in tfds.as_numpy(nq_dataset_marked_code(\"train\").take(3)):\n",
        "  print(ex)\n",
        "\n",
        "def marked_code_preprocessing(ds):\n",
        "  \n",
        "  def to_inputs_and_targets(ex):\n",
        "\n",
        "        inputs = tf.strings.join(['markedCode2code: ' + ex['input']], separator=' ')\n",
        "        class_label = tf.strings.join([ex['output']], separator=' ')\n",
        "        return {'inputs': inputs, 'targets': class_label }\n",
        "    \n",
        "  return ds.map(to_inputs_and_targets, \n",
        "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "#Create a new training task\n",
        "t5.data.TaskRegistry.remove('marked_code')\n",
        "t5.data.TaskRegistry.add(\n",
        "    \"marked_code\",\n",
        "    dataset_fn=nq_dataset_marked_code,\n",
        "    splits=[\"train\", \"validation\"],\n",
        "    text_preprocessor=[marked_code_preprocessing],\n",
        "    output_features = DEFAULT_OUTPUT_FEATURES,\n",
        "    metric_fns=[t5.evaluation.metrics.accuracy],\n",
        "    num_input_examples=num_nq_examples_marked_code\n",
        ")\n",
        "\n",
        "nq_task = t5.data.TaskRegistry.get(\"marked_code\")\n",
        "ds = nq_task.get_dataset(split=\"train\", sequence_length={\"inputs\": 512, \"targets\": 512})\n",
        "print(\"A few preprocessed training examples...\")\n",
        "for ex in tfds.as_numpy(ds.take(3)):\n",
        "  print(ex)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1st TASK : code 2 code\n",
            "A few raw validation examples...\n",
            "{'input': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }', 'output': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); } }); executor.submit(task); }'}\n",
            "{'input': b'public int hashCode() { return element.hashCode(); }', 'output': b'public int hashCode() { if (element == null) { return super.hashCode(); } return element.hashCode(); }'}\n",
            "{'input': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }', 'output': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (!Util.isBlank(domainClassExpression) && !Util.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(EEFExpressionUtils.SELF, this.variableManager.getVariables().get(EEFExpressionUtils.SELF)); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }'}\n",
            "A few raw training examples...\n",
            "{'input': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollection(input, s -> new LinkedList<>()); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }', 'output': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollectionUnbounded(input, LinkedList::new); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }'}\n",
            "{'input': b'public static Command<Set<Cookie>> getAllCookies() { return new Command<>(domainName + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", new TypeToken<Set<Cookie>>() {}.getType())); }', 'output': b'public static Command<Cookies> getAllCookies() { return new Command<>(DOMAIN_NAME + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", Cookies.class)); }'}\n",
            "{'input': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if (blockIn instanceof BlockPistonBase) { final IBlockState blockstate = this.getBlockState(pos); EnumFacing direction = (EnumFacing) blockstate.getValue(BlockDirectional.FACING); BlockPistonStructureHelper movedBlocks = new BlockPistonStructureHelper(this$, pos, direction, eventId == 0); List<BlockPos> blocks = new ArrayList<BlockPos>(); blocks.addAll(movedBlocks.getBlocksToDestroy()); blocks.addAll(movedBlocks.getBlocksToMove()); List<Location<org.spongepowered.api.world.World>> locations = new ArrayList<Location<org.spongepowered.api.world.World>>(); for (BlockPos block : blocks) { locations.add(new Location<>((org.spongepowered.api.world.World) this$, block.getX(), block.getY(), block.getZ())); } if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos, locations)) { return false; } } else { if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos)) { return false; } } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }', 'output': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if ((blockIn instanceof BlockPistonBase && SpongeCommonEventFactory.handlePistonEvent(this, list, obj, pos, blockIn, eventId, eventParam)) || SpongeCommonEventFactory.callChangeBlockEventPre(this, pos, NamedCause.of(NamedCause.BLOCK_EVENT, this)).isCancelled()) { return false; } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'code2code: private AdminClient brokerAdminClient(KafkaProperties kafkaProperties) { Properties props = new Properties(); props.put(BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapKafkaServer()); props.put(SECURITY_PROTOCOL_CONFIG, DEFAULT_SECURITY_PROTOCOL); props.put(REQUEST_TIMEOUT_MS_CONFIG, kafkaProperties.getKafkaServerRequestTimeoutMillis()); if (kafkaProperties.isSaslEnabled()) { props.put(\"sasl.mechanism\", \"PLAIN\"); props.put(\"security.protocol\", \"SASL_PLAINTEXT\"); props.put(\"sasl.jaas.config\", kafkaProperties.getSaslJaasConfig()); } return AdminClient.create(props); }', 'inputs': array([   89,   111,   220,    20,   124,     7, 14497,  6455, 14497,\n",
            "           9, 13710,   786, 13603,   786,    12,    15,  2127,  2446,\n",
            "          16,    33,  2127,    39,  2446,     8,   261,     9, 21595,\n",
            "       11055,  8176,    25,  5372,   284,    25,  5379,    11, 13603,\n",
            "         786,     8,    62,  8572, 13710,  1064,    93,  2446,     8,\n",
            "         261,     9, 11637,    25, 13681,    25,  5379,    11,  4551,\n",
            "          25, 11637,    25, 13681,    18,  2446,     8,   261,     9,\n",
            "        3561,    25,  7370,    25,  4136,    25,  5379,    11, 13603,\n",
            "         786,     8,    62, 13710,  1064,   229, 25178,    93,    28,\n",
            "          23, 10187,   786,     8,   249, 31588,  2228,   101,    15,\n",
            "        2446,     8,   261,    46,    19,   756,   694,     8,  2475,\n",
            "       19759, 16749,    86,    41,  9132,    78,  2446,     8,   261,\n",
            "          46,  1736,     8,  5792,    86,    41, 27563,    25,  9132,\n",
            "        4017,    78,  2446,     8,   261,    46,    19,   756,   694,\n",
            "           8, 23726,     8,   967,    86, 13603,   786,     8,    62,\n",
            "       31588, 18583,   756,   436,    93,    13,    42,     7, 14497,\n",
            "           8,   396,     9,  4943,    18,    13,     1], dtype=int32), 'targets_pretokenized': b'private AdminClient brokerAdminClient(KafkaProperties kafkaProperties) { Properties props = new Properties(); props.put(BOOTSTRAP_SERVERS_CONFIG, kafkaProperties.getBootstrapKafkaServer()); props.put(SECURITY_PROTOCOL_CONFIG, DEFAULT_SECURITY_PROTOCOL); props.put(REQUEST_TIMEOUT_MS_CONFIG, kafkaProperties.getKafkaServerRequestTimeoutMillis()); if (kafkaProperties.isSaslEnabled()) { props.put(SASL_MECHANISM, kafkaProperties.getSaslMechanism()); props.put(SECURITY_PROTOCOL_CONFIG, kafkaProperties.getSaslProtocol()); props.put(SASL_JAAS_CONFIG, kafkaProperties.getSaslJaasConfig()); } return AdminClient.create(props); }', 'targets': array([  124,     7, 14497,  6455, 14497,     9, 13710,   786, 13603,\n",
            "         786,    12,    15,  2127,  2446,    16,    33,  2127,    39,\n",
            "        2446,     8,   261,     9, 21595, 11055,  8176,    25,  5372,\n",
            "         284,    25,  5379,    11, 13603,   786,     8,    62,  8572,\n",
            "       13710,  1064,    93,  2446,     8,   261,     9, 11637,    25,\n",
            "       13681,    25,  5379,    11,  4551,    25, 11637,    25, 13681,\n",
            "          18,  2446,     8,   261,     9,  3561,    25,  7370,    25,\n",
            "        4136,    25,  5379,    11, 13603,   786,     8,    62, 13710,\n",
            "        1064,   229, 25178,    93,    28,    23, 10187,   786,     8,\n",
            "         249, 31588,  2228,   101,    15,  2446,     8,   261,     9,\n",
            "       27563,    25,  5524, 25035, 10847, 15316,    11, 13603,   786,\n",
            "           8,    62, 31588, 20928,    93,  2446,     8,   261,     9,\n",
            "       11637,    25, 13681,    25,  5379,    11, 13603,   786,     8,\n",
            "          62, 31588,  3660,    93,  2446,     8,   261,     9, 27563,\n",
            "          25, 17076,    25,  5379,    11, 13603,   786,     8,    62,\n",
            "       31588, 18583,   756,   436,    93,    13,    42,     7, 14497,\n",
            "           8,   396,     9,  4943,    18,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code2code: public void testGetUserPropertyValues_Caching() throws UserStoreException, NamingException, IOException, MalformedObjectNameException, InstanceNotFoundException { ReadOnlyLDAPUserStoreManager readOnlyLDAPUserStoreManager1 = getReadOnlyLDAPUserStoreManager(); ReadWriteLDAPUserStoreManager readWriteLDAPUserStoreManager1 = getReadWriteDAPUserStoreManager(); Map<String, String> claims = new HashMap<String, String>(); claims.put(SNAME_CLAIM, USER_UPDATED_LAST_NAME); claims.put(U_NAME_CLAIM, USER_NAME_1); if (!readWriteLDAPUserStoreManager1.isExistingUser(USER_NAME_1)) { readWriteLDAPUserStoreManager1.doAddUser(USER_NAME_1, \"test1\", new String[0], claims, \"defult\"); } boolean isAuthenticated = false; try { rename(USER_NAME_1, USER_NAME_2); } catch (Exception e) { e.printStackTrace(); } isAuthenticated = readOnlyLDAPUserStoreManager1.doAuthenticate(USER_UPDATED_LAST_NAME, \"test1\"); Assert.assertTrue(isAuthenticated); Map<String, String> userProps = readOnlyLDAPUserStoreManager1 .getUserPropertyValues(USER_NAME_1, new String[] { CN_ATTR }, \"default\"); Assert.assertNotNull(userProps); rename(USER_NAME_2, USER_NAME_1); try { readOnlyLDAPUserStoreManager1.getUserClaimValue(USER_UPDATED_LAST_NAME, SNAME_CLAIM, \"default\"); Assert.fail(\"The user search should fail, due to cache holding previous DN for the user\"); } catch (UserStoreException expectedException) { } clearCache(readOnlyLDAPUserStoreManager1); String lastName = readOnlyLDAPUserStoreManager1.getUserClaimValue(USER_UPDATED_LAST_NAME, SNAME_CLAIM, \"default\"); Assert.assertNotNull(lastName); }', 'inputs': array([   89,   111,   220,    20,    44,    71,   317,  1397,   641,\n",
            "       24596,    25,  9859,    43,   169,  1194,  1470,    66,    11,\n",
            "       16864,    11,   331,    11, 18881, 10218,    66,    11,     7,\n",
            "         893,  2934,    66,    15,     7,  8004, 20876,   641,  1470,\n",
            "         433,     7, 12194, 20876,   641,  1470,   433,   131,    16,\n",
            "          99,  8004, 20876,   641,  1470,   433,    39,     7, 28041,\n",
            "       20876,   641,  1470,   433,   277,  2445, 20876,   641,  1470,\n",
            "         433,   131,    16,    99, 28041, 24056,   641,  1470,   433,\n",
            "          39,   400,    40,    50,    11,    53,    32, 13541,    16,\n",
            "          33,   697,    40,    50,    11,    53,   625, 13541,     8,\n",
            "         261,     9,   284,   796,    25,   371,  2421,  9412,    11,\n",
            "       12714,    25, 20069,    25,  7645,    25,   796,    18, 13541,\n",
            "           8,   261,     9,  1446,    25,   796,    25,   371,  2421,\n",
            "        9412,    11, 12714,    25,   796, 15188,    28,   387,   722,\n",
            "        2445, 20876,   641,  1470,   433,   364,   249,  7287,   641,\n",
            "           9,  3079,    25,   796,    25, 11312,    15,   277,  2445,\n",
            "       20876,   641,  1470,   433,   364,  1493,  2147,   641,     9,\n",
            "        3079,    25,   796,  6696,    41,   528,  3401,    33,    53,\n",
            "        4885, 13541,    11,    41,  2945,  3168,    57,    78,    13,\n",
            "         193,     7, 26479,    16,   207,    24,   123,    15,  4788,\n",
            "           9,  3079,    25,   796,  6696, 12714,    25,   796,    25,\n",
            "        1173,    13,   172,    23,    66,   107,    12,    15,   107,\n",
            "           8,   955,    39,    13,     7, 26479,    16,     7, 12194,\n",
            "       20876,   641,  1470,   433,   364,  1493, 19572,     9,  3079,\n",
            "          25, 20069,    25,  7645,    25,   796,    11,    41,   528,\n",
            "        3850,  3898,     8, 16655,     9, 26479,    18,   400,    40,\n",
            "          50,    11,    53,    32,   264,  3598,    16,     7, 12194,\n",
            "       20876,   641,  1470,   433,   131,     7,     8,  5109, 24596,\n",
            "           9,  3079,    25,   796,  6696,    33,    53,   100,    15,\n",
            "           7, 11574,    25,  7371,    13,    11,    41,  1481,    78,\n",
            "        3898,     8, 22657,     9,   428,  3598,    18,  4788,     9,\n",
            "        3079,    25,   796, 18311, 12714,    25,   796, 15188,   123,\n",
            "          15,     7, 12194, 20876,   641,  1470,   433,   364,  5109,\n",
            "       12705,   233,     9,  3079,    25, 20069,    25,  7645,    25,\n",
            "         796,    11,  1181,   796,    25,   371,  2421,  9412,    11,\n",
            "          41,  1481,    78,  3898,     8,  6788,    46,  1041,   264,\n",
            "         773,   104,  1071,    11,  1708,    14,   829,  5280,  1175,\n",
            "           7,  6878,    34,    10,   264,    78,    13,   172,    23,\n",
            "         641,  1470,    66,  1025,    66,    12,    15,    13,     7,\n",
            "       15465,     9, 12194, 20876,   641,  1470,   433,  1363,    53,\n",
            "        7014,    16,     7, 12194, 20876,   641,  1470,   433,   364,\n",
            "        5109, 12705,   233,     9,  3079,    25, 20069,    25,  7645,\n",
            "          25,   796,    11,  1181,   796,    25,   371,  2421,  9412,\n",
            "          11,    41,  1481,    78,  3898,     8, 22657,     9,  8393,\n",
            "          18,    13,     1], dtype=int32), 'targets_pretokenized': b'public void testGetUserPropertyValues_Caching() throws UserStoreException, NamingException, IOException, MalformedObjectNameException, InstanceNotFoundException { ReadOnlyLDAPUserStoreManager readOnlyLDAPUserStoreManager1 = getReadOnlyLDAPUserStoreManager(); ReadWriteLDAPUserStoreManager readWriteLDAPUserStoreManager1 = getReadWriteDAPUserStoreManager(); Map<String, String> claims = new HashMap<String, String>(); claims.put(SNAME_CLAIM, USER_UPDATED_LAST_NAME); claims.put(U_NAME_CLAIM, USER_NAME_1); startTenantFlow(TEST_TENANT_1, TEST_TENANT_DOMAIN_1); if (!readWriteLDAPUserStoreManager1.isExistingUser(USER_NAME_1)) { readWriteLDAPUserStoreManager1.doAddUser(USER_NAME_1, \"test1\", new String[0], claims, \"defult\"); } boolean isAuthenticated = false; try { rename(USER_NAME_1, USER_NAME_2); } catch (Exception e) { log.error(\"Error in renaming LDAP user \" + USER_NAME_1, e); } isAuthenticated = readOnlyLDAPUserStoreManager1.doAuthenticate(USER_UPDATED_LAST_NAME, \"test1\"); Assert.assertTrue(isAuthenticated); Map<String, String> userProps = readOnlyLDAPUserStoreManager1 .getUserPropertyValues(USER_NAME_1, new String[] { CN_ATTR }, \"default\"); Assert.assertNotNull(userProps); rename(USER_NAME_2, USER_NAME_1); try { readOnlyLDAPUserStoreManager1.getUserClaimValue(USER_UPDATED_LAST_NAME, SNAME_CLAIM, \"default\"); Assert.fail(\"The user search should fail, due to cache holding previous DN for the user, \" + \"and a UserStoreException should have been thrown.\"); } catch (UserStoreException expectedException) { } clearCache(readOnlyLDAPUserStoreManager1); String lastName = readOnlyLDAPUserStoreManager1 .getUserClaimValue(USER_UPDATED_LAST_NAME, SNAME_CLAIM, \"default\"); Assert.assertNotNull(lastName); PrivilegedCarbonContext.endTenantFlow(); }', 'targets': array([   44,    71,   317,  1397,   641, 24596,    25,  9859,    43,\n",
            "         169,  1194,  1470,    66,    11, 16864,    11,   331,    11,\n",
            "       18881, 10218,    66,    11,     7,   893,  2934,    66,    15,\n",
            "           7,  8004, 20876,   641,  1470,   433,     7, 12194, 20876,\n",
            "         641,  1470,   433,   131,    16,    99,  8004, 20876,   641,\n",
            "        1470,   433,    39,     7, 28041, 20876,   641,  1470,   433,\n",
            "         277,  2445, 20876,   641,  1470,   433,   131,    16,    99,\n",
            "       28041, 24056,   641,  1470,   433,    39,   400,    40,    50,\n",
            "          11,    53,    32, 13541,    16,    33,   697,    40,    50,\n",
            "          11,    53,   625, 13541,     8,   261,     9,   284,   796,\n",
            "          25,   371,  2421,  9412,    11, 12714,    25, 20069,    25,\n",
            "        7645,    25,   796,    18, 13541,     8,   261,     9,  1446,\n",
            "          25,   796,    25,   371,  2421,  9412,    11, 12714,    25,\n",
            "         796, 15188,   274,  8110,  2813,     9,  5811,    25, 23869,\n",
            "        6696,     7,  5811,    25, 23869,    25, 13797, 15188,    28,\n",
            "         387,   722,  2445, 20876,   641,  1470,   433,   364,   249,\n",
            "        7287,   641,     9,  3079,    25,   796,    25, 11312,    15,\n",
            "         277,  2445, 20876,   641,  1470,   433,   364,  1493,  2147,\n",
            "         641,     9,  3079,    25,   796,  6696,    41,   528,  3401,\n",
            "          33,    53,  4885, 13541,    11,    41,  2945,  3168,    57,\n",
            "          78,    13,   193,     7, 26479,    16,   207,    24,   123,\n",
            "          15,  4788,     9,  3079,    25,   796,  6696, 12714,    25,\n",
            "         796,    25,  1173,    13,   172,    23,    66,   107,    12,\n",
            "          15,   451,     8,   750,    46,   690,    31, 14817,  8708,\n",
            "         264,    41,    61, 12714,    25,   796,  6696,   107,    18,\n",
            "          13,     7, 26479,    16,     7, 12194, 20876,   641,  1470,\n",
            "         433,   364,  1493, 19572,     9,  3079,    25, 20069,    25,\n",
            "        7645,    25,   796,    11,    41,   528,  3850,  3898,     8,\n",
            "       16655,     9, 26479,    18,   400,    40,    50,    11,    53,\n",
            "          32,   264,  3598,    16,     7, 12194, 20876,   641,  1470,\n",
            "         433,   131,     7,     8,  5109, 24596,     9,  3079,    25,\n",
            "         796,  6696,    33,    53,   100,    15,     7, 11574,    25,\n",
            "        7371,    13,    11,    41,  1481,    78,  3898,     8, 22657,\n",
            "           9,   428,  3598,    18,  4788,     9,  3079,    25,   796,\n",
            "       18311, 12714,    25,   796, 15188,   123,    15,     7, 12194,\n",
            "       20876,   641,  1470,   433,   364,  5109, 12705,   233,     9,\n",
            "        3079,    25, 20069,    25,  7645,    25,   796,    11,  1181,\n",
            "         796,    25,   371,  2421,  9412,    11,    41,  1481,    78,\n",
            "        3898,     8,  6788,    46,  1041,   264,   773,   104,  1071,\n",
            "          11,  1708,    14,   829,  5280,  1175,     7,  6878,    34,\n",
            "          10,   264,    11,    41,    61,    41,   630,    17,  1194,\n",
            "        1470,    66,   104,    73,   487,   809,     8,    78,    13,\n",
            "         172,    23,   641,  1470,    66,  1025,    66,    12,    15,\n",
            "          13,     7, 15465,     9, 12194, 20876,   641,  1470,   433,\n",
            "        1363,    53,  7014,    16,     7, 12194, 20876,   641,  1470,\n",
            "         433,   131,     7,     8,  5109, 12705,   233,     9,  3079,\n",
            "          25, 20069,    25,  7645,    25,   796,    11,  1181,   796,\n",
            "          25,   371,  2421,  9412,    11,    41,  1481,    78,  3898,\n",
            "           8, 22657,     9,  8393,    18,     7, 17428, 29336,   242,\n",
            "           8,  1042,  8110,  2813,    39,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code2code: public void exceptionInCleanupClosesTransactionManager() { RuntimeException cause = new RuntimeException(\"VALID REASON\"); doThrow(cause).when(mockCallback).runWithRetry(); setInitializationStatus(true, true, true, true); assertClosedWitoutInitializingWithinTwoSeconds(); Assertions.assertThatThrownBy(() -> manager.runTaskWithRetry($ -> null)) .isInstanceOf(IllegalStateException.class) .hasCause(cause); }', 'inputs': array([   89,   111,   220,    20,    44,    71,   356,   563, 14469,\n",
            "        3647,    19,  1486,   433,    43,    15,     7,  1047,  1062,\n",
            "          16,    33,     7,  1047,    46, 16162,     7, 27015,    78,\n",
            "           7, 31152,     9,  6302,   147,  3036,     9,  4244,  1502,\n",
            "         147,  1400,   811,  5589,    39,   127,  9761,   744,     9,\n",
            "         294,    11,   175,    11,   175,    11,   175,    18,  1698,\n",
            "        6065,  1196,   913,   113, 19578, 14868,  2887,  5124,    39,\n",
            "           7, 17506,     8, 18007, 20267,   748,     9,    43,   296,\n",
            "        1732,     8,  1400,   867,   811,  5589,     9,     2,   296,\n",
            "          49,   195,     7,     8, 29403,     9, 10129,    66,     8,\n",
            "         142,    12,     7,     8,  1427,  8141,     9,  6302,    18,\n",
            "          13,     1], dtype=int32), 'targets_pretokenized': b'public void exceptionInCleanupClosesTransactionManager() { RuntimeException cause = new RuntimeException(\"VALID REASON\"); doThrow(cause).when(mockCallback).runWithRetry(any(SerializableTransactionManager.class)); everythingInitialized(); assertNotInitializedWithinTwoSecondsBecauseClosed(); assertTrue(((SerializableTransactionManager.InitializeCheckingWrapper) manager).isClosedByCallbackFailure()); Assertions.assertThatThrownBy(() -> manager.runTaskWithRetry($ -> null)) .isInstanceOf(IllegalStateException.class) .hasCause(cause); }', 'targets': array([   44,    71,   356,   563, 14469,  3647,    19,  1486,   433,\n",
            "          43,    15,     7,  1047,  1062,    16,    33,     7,  1047,\n",
            "          46, 16162,     7, 27015,    78,     7, 31152,     9,  6302,\n",
            "         147,  3036,     9,  4244,  1502,   147,  1400,   811,  5589,\n",
            "           9,  3741,     9,  5357,  1486,   433,     8,   142,   164,\n",
            "        1398,  8910,    39,  1698,  1942,  8910, 14868,  2887,  5124,\n",
            "       28652,  6065,    39, 13989,  5456,  5357,  1486,   433,     8,\n",
            "       18003, 16775,  1418,    12,  1732,   147, 12568,   748,  1502,\n",
            "        3649,    93,     7, 17506,     8, 18007, 20267,   748,     9,\n",
            "          43,   296,  1732,     8,  1400,   867,   811,  5589,     9,\n",
            "           2,   296,    49,   195,     7,     8, 29403,     9, 10129,\n",
            "          66,     8,   142,    12,     7,     8,  1427,  8141,     9,\n",
            "        6302,    18,    13,     1], dtype=int32)}\n",
            "2nd TASK : code 2 comment\n",
            "A few raw validation examples...\n",
            "{'input': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }', 'output': b'Also here applies the same: An alternative would be to get the current scene over the window: window.getScene() The benefit would be in reducing code (variable definitions and object injections)'}\n",
            "{'input': b'public int hashCode() { return element.hashCode(); }', 'output': b\"What I'm missing here is the check if the element is null. I know that the probability is very low, but still...\"}\n",
            "{'input': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }', 'output': b'Use Util.isBlank'}\n",
            "A few raw training examples...\n",
            "{'input': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollection(input, s -> new LinkedList<>()); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }', 'output': b'you can use unmarshallCollectionUnbounded() when the collection constructor does not need the size'}\n",
            "{'input': b'public static Command<Set<Cookie>> getAllCookies() { return new Command<>(domainName + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", new TypeToken<Set<Cookie>>() {}.getType())); }', 'output': b\"Selenium already has a org.openqa.selenium.Cookie. There will be lower friction with other parts of the Selenium APIs if we return extant Selenium types. I think it's fine to extend those types to be more meaningful if necessary.\"}\n",
            "{'input': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if (blockIn instanceof BlockPistonBase) { final IBlockState blockstate = this.getBlockState(pos); EnumFacing direction = (EnumFacing) blockstate.getValue(BlockDirectional.FACING); BlockPistonStructureHelper movedBlocks = new BlockPistonStructureHelper(this$, pos, direction, eventId == 0); List<BlockPos> blocks = new ArrayList<BlockPos>(); blocks.addAll(movedBlocks.getBlocksToDestroy()); blocks.addAll(movedBlocks.getBlocksToMove()); List<Location<org.spongepowered.api.world.World>> locations = new ArrayList<Location<org.spongepowered.api.world.World>>(); for (BlockPos block : blocks) { locations.add(new Location<>((org.spongepowered.api.world.World) this$, block.getX(), block.getY(), block.getZ())); } if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos, locations)) { return false; } } else { if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos)) { return false; } } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }', 'output': b\"You're not filtering block positions that have already been added, since there can be multiple duplications of locations being added.\"}\n",
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'code2comment: protected RefundsResponse executeFutureBehaviourStrategy() { return getPaymentRefundsService.getLedgerTransactionTransactions(account, paymentId); }', 'inputs': array([   89,   111,  6392,    20,   395,     7, 29605,    19,   462,\n",
            "         896,  1997, 21641,  2161,    43,    15,    42,    99,  5567,\n",
            "       29605,    19,   365,     8,    62, 20814,  1486, 13727,     9,\n",
            "        4429,    11,  7594,   183,    18,    13,     1], dtype=int32), 'targets_pretokenized': b'might be more obvious while reading the code if it was: suggestion return executeLedgerOnlyStrategy();', 'targets': array([  386,    45,   178,  4491,   219,  1152,    10,    89,    28,\n",
            "          37,   179,    20,  4453,    42,   896, 20814,  3075,  2161,\n",
            "          39,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code2comment: public void replaceWithMoreThanMaxItems() { List<Object> items = createItems(); String[] messageItems = ReplacementUtils.replaceWith(PROPERTY_NAME, items); validateMessageContainsProperties(messageItems); assertTrue(messageItems[1].contains(String.valueOf(items.size()))); }', 'inputs': array([   89,   111,  6392,    20,    44,    71,     7, 27325,  7342,\n",
            "       14097,  2012,  1986,    43,    15,   170,    40,   199,    32,\n",
            "         927,    16,   168,  1986,    39,    53,   100,   313,  1986,\n",
            "          16,     7,  8716,   725,     8, 27325,     9,  3361,    25,\n",
            "         796,    11,   927,    18,  1831,   511,  7341,   786,     9,\n",
            "         992,  1986,    18, 13989,     9,   992,  1986,  8059,   808,\n",
            "           9,    50,     8,   881,     9,  3590,     8,   270,  7321,\n",
            "          13,     1], dtype=int32), 'targets_pretokenized': b'Also interesting to see that the items after the max one are not contained in the message', 'targets': array([ 601, 4886,   14,  307,   38,   10,  927,  340,   10,  684,  128,\n",
            "         63,   56, 2908,   31,   10,  313,    1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code2comment: public Long save(GlobalId globalId) { Long lookup = getIfExists(globalId); if (lookup != null) { return lookup; } return insert(globalId); }', 'inputs': array([  89,  111, 6392,   20,   44, 1080,  894,    9, 3806,  183, 2325,\n",
            "        183,   12,   15, 1080, 2675,   16,   99, 2159, 5484,    9, 4299,\n",
            "        183,   18,   28,   23, 4452,  125,   49,   12,   15,   42, 2675,\n",
            "         24,   13,   42, 1520,    9, 4299,  183,   18,   13,    1],\n",
            "      dtype=int32), 'targets_pretokenized': b'moze return lookup != null ? lookup : insert(globalId)', 'targets': array([   7, 4631, 6964,   42, 2675,  125,   49,  405, 2675,    7,   20,\n",
            "       1520,    9, 4299,  183,   12,    1], dtype=int32)}\n",
            "3rd TASK : code and comment 2 code\n",
            "A few raw validation examples...\n",
            "{'input': b'<code>public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }</code><technical_language>applies same: alternative get current scene window: window.getScene() benefit in reducing code (variable definitions object injections)</technical_language>', 'output': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); } }); executor.submit(task); }'}\n",
            "{'input': b'<code>public int hashCode() { <START> return element.hashCode(); <END> }</code><technical_language>missing is check if element is null. I probability is low, still..</technical_language>', 'output': b'public int hashCode() { if (element == null) { return super.hashCode(); } return element.hashCode(); }'}\n",
            "{'input': b'<code>private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }</code><technical_language>Util.isBlank</technical_language>', 'output': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (!Util.isBlank(domainClassExpression) && !Util.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(EEFExpressionUtils.SELF, this.variableManager.getVariables().get(EEFExpressionUtils.SELF)); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }'}\n",
            "A few raw training examples...\n",
            "{'input': b'<code>public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: <START> return MarshallUtil.unmarshallCollection(input, s -> new LinkedList<>()); <END> case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }</code><technical_language>unmarshallCollectionUnbounded() collection constructor need size</technical_language>', 'output': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollectionUnbounded(input, LinkedList::new); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }'}\n",
            "{'input': b'<code><START> public static Command<Set<Cookie>> getAllCookies() { <END> return new Command<>(domainName + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", new TypeToken<Set<Cookie>>() {}.getType())); }</code><technical_language>Selenium a org.openqa.selenium.Cookie. friction other parts of Selenium APIs if return extant Selenium types. I fine extend types more meaningful if necessary</technical_language>', 'output': b'public static Command<Cookies> getAllCookies() { return new Command<>(DOMAIN_NAME + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", Cookies.class)); }'}\n",
            "{'input': b'<code>public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if (blockIn instanceof BlockPistonBase) { final IBlockState blockstate = this.getBlockState(pos); EnumFacing direction = (EnumFacing) blockstate.getValue(BlockDirectional.FACING); BlockPistonStructureHelper movedBlocks = new BlockPistonStructureHelper(this$, pos, direction, eventId == 0); List<BlockPos> blocks = new ArrayList<BlockPos>(); blocks.addAll(movedBlocks.getBlocksToDestroy()); blocks.addAll(movedBlocks.getBlocksToMove()); List<Location<org.spongepowered.api.world.World>> locations = new ArrayList<Location<org.spongepowered.api.world.World>>(); for (BlockPos block : blocks) { <START> locations.add(new Location<>((org.spongepowered.api.world.World) this$, block.getX(), block.getY(), block.getZ())); <END> } if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos, locations)) { return false; } } else { if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos)) { return false; } } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }</code><technical_language>filtering block positions added, multiple duplications of locations added</technical_language>', 'output': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if ((blockIn instanceof BlockPistonBase && SpongeCommonEventFactory.handlePistonEvent(this, list, obj, pos, blockIn, eventId, eventParam)) || SpongeCommonEventFactory.callChangeBlockEventPre(this, pos, NamedCause.of(NamedCause.BLOCK_EVENT, this)).isCancelled()) { return false; } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }'}\n",
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'code&comment2code: <code>public boolean isMultisimSupported(String callingPackage) { if (!TelephonyPermissions.checkCallingOrSelfReadPhoneState(mApp, getDefaultPhone().getSubId(), callingPackage, \"isMultisimSupported\")) { return false; } final long identity = Binder.clearCallingIdentity(); try { return <START> isMultisimSupported(); <END> } finally { Binder.restoreCallingIdentity(identity); } }</code><technical_language>nit: rename isMultisimSupportedInternal() isMultisimSupportedWithPremissionChecked()</technical_language>', 'inputs': array([   89,   767,  6392,   111,   220,    20,     7,     3,   171,\n",
            "         193,    21,  3900, 15594,  6022,     9,    50,   745,  1552,\n",
            "          12,    15,    28,   387, 22886,  5443, 18853,   320,  3696,\n",
            "           8,  1545, 22276,  1329,  8317,  1873,  5179,   518,     9,\n",
            "         156,  1714,    11, 14975,  5179,    81,  8259,   183,   145,\n",
            "         745,  1552,    11,    41,   249,  3900, 15594,  6022,   727,\n",
            "          15,    42,   207,    24,    13,    90,   281,  3902,    16,\n",
            "           7,  5388,     8,  1539, 22276,  4067,    39,   123,    15,\n",
            "          42,    60,  4011,    32,    21,  3900, 15594,  6022,    39,\n",
            "          60,  3921,    32,    13,   713,    15,     7,  5388,     8,\n",
            "       10405, 22276,  4067,     9,  6130,    18,    13,    13,     4,\n",
            "           5,   159,   913,    20,  4788,    21,  3900, 15594,  6022,\n",
            "        2606,    43,    21,  3900, 15594,  6022,   811,  3997,  8369,\n",
            "        7429,    43,     6,     1], dtype=int32), 'targets_pretokenized': b'public boolean isMultisimSupported(String callingPackage) { if (!TelephonyPermissions.checkCallingOrSelfReadPhoneState(mApp, getDefaultPhone().getSubId(), callingPackage, \"isMultisimSupported\")) { return false; } final long identity = Binder.clearCallingIdentity(); try { return isMultisimSupportedInternal(); } finally { Binder.restoreCallingIdentity(identity); } }', 'targets': array([   44,   193,    21,  3900, 15594,  6022,     9,    50,   745,\n",
            "        1552,    12,    15,    28,   387, 22886,  5443, 18853,   320,\n",
            "        3696,     8,  1545, 22276,  1329,  8317,  1873,  5179,   518,\n",
            "           9,   156,  1714,    11, 14975,  5179,    81,  8259,   183,\n",
            "         145,   745,  1552,    11,    41,   249,  3900, 15594,  6022,\n",
            "         727,    15,    42,   207,    24,    13,    90,   281,  3902,\n",
            "          16,     7,  5388,     8,  1539, 22276,  4067,    39,   123,\n",
            "          15,    42,    21,  3900, 15594,  6022,  2606,    39,    13,\n",
            "         713,    15,     7,  5388,     8, 10405, 22276,  4067,     9,\n",
            "        6130,    18,    13,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code&comment2code: <code>private static boolean loadSourceFiles(ISessionInfoVisitor infoStore, IExecutionDataVisitor dataStore, File... reports) { Boolean isCurrentVersionFormat = null; for (File report : reports) { if (report.isFile()) { try { JacocoReportReader jacocoReportReader = new JacocoReportReader(report).readJacocoReport(dataStore, infoStore); isCurrentVersionFormat = jacocoReportReader.useCurrentBinaryFormat(); } catch (IOException e) { throw new SonarException(String.format(\"Unable to read %s\", report.getAbsolutePath()), e); } } } <START> return BooleanUtils.isNotFalse(isCurrentVersionFormat); <END> }</code><technical_language>I miss test case in place, code obvious</technical_language>', 'inputs': array([   89,   767,  6392,   111,   220,    20,     7,     3,   854,\n",
            "          83,   193,   769, 15526,    19,     9,   358,  1009,   370,\n",
            "        3640,  1174,  1470,    11,    48,  2514,   251,  3640,   137,\n",
            "        1470,    11,   375,   416,  8051,    12,    15,  1255,    21,\n",
            "        2842,   954,  1386,    16,    49,    24,    34,    23,   253,\n",
            "        2065,     7,    20,  8051,    12,    15,    28,    23,  3398,\n",
            "           8, 10096,   101,    15,   123,    15,  9754,  3352,  3352,\n",
            "        2337,  1093,     7, 14841,  2337,  1093,    16,    33,  9754,\n",
            "        3352,  3352,  2337,  1093,     9,  3398,   147,   722, 18583,\n",
            "        3352,  3352,  2337,     9,   397,  1470,    11,  1174,  1470,\n",
            "          18,    21,  2842,   954,  1386,    16,     7, 14841,  2337,\n",
            "        1093,     8,  1907,  2842,  3720,  1386,    39,    13,   172,\n",
            "          23,   780,   107,    12,    15,   161,    33, 15702,    66,\n",
            "           9,    50,     8,   579,    46,  1735,    14,   277,   595,\n",
            "          19,    86,  2065,     8,  3438,   101,    11,   107,    18,\n",
            "          13,    13,    13,    60,  4011,    32,    42,  1255,   725,\n",
            "           8,   249,  1942, 10632,     9,   249,  2842,   954,  1386,\n",
            "          18,    60,  3921,    32,    13,     4,     5,   358,  9285,\n",
            "         317,   136,    31,  1052,    11,    89,  4491,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'private static boolean loadSourceFiles(ISessionInfoVisitor infoStore, IExecutionDataVisitor dataStore, File... reports) { Boolean isCurrentVersionFormat = null; for (File report : reports) { if (report.isFile()) { JacocoReportReader jacocoReportReader = new JacocoReportReader(report).readJacocoReport(dataStore, infoStore); boolean reportFormatIsCurrent = jacocoReportReader.useCurrentBinaryFormat(); if (isCurrentVersionFormat == null) { isCurrentVersionFormat = reportFormatIsCurrent; } else if (!isCurrentVersionFormat.equals(reportFormatIsCurrent)) { throw new IllegalStateException(\"You are trying to merge two different JaCoCo binary formats. Please use only one version of JaCoCo.\"); } } } return BooleanUtils.isNotFalse(isCurrentVersionFormat); }', 'targets': array([  124,    83,   193,   769, 15526,    19,     9,   358,  1009,\n",
            "         370,  3640,  1174,  1470,    11,    48,  2514,   251,  3640,\n",
            "         137,  1470,    11,   375,   416,  8051,    12,    15,  1255,\n",
            "          21,  2842,   954,  1386,    16,    49,    24,    34,    23,\n",
            "         253,  2065,     7,    20,  8051,    12,    15,    28,    23,\n",
            "        3398,     8, 10096,   101,    15,  9754,  3352,  3352,  2337,\n",
            "        1093,     7, 14841,  2337,  1093,    16,    33,  9754,  3352,\n",
            "        3352,  2337,  1093,     9,  3398,   147,   722, 18583,  3352,\n",
            "        3352,  2337,     9,   397,  1470,    11,  1174,  1470,    18,\n",
            "         193,  2065,  1386,  2197,  2842,    16,     7, 14841,  2337,\n",
            "        1093,     8,  1907,  2842,  3720,  1386,    39,    28,    23,\n",
            "         249,  2842,   954,  1386,    85,    49,    12,    15,    21,\n",
            "        2842,   954,  1386,    16,  2065,  1386,  2197,  2842,    24,\n",
            "          13,   121,    28,   387,   249,  2842,   954,  1386,     8,\n",
            "         247,     9,  3398,  1386,  2197,  2842,   195,    15,   161,\n",
            "          33,  1740,    66,    46,  2762,    63,   753,    14,  2414,\n",
            "         288,   337, 29521,  1684,  5347,     8,  1548,    67,   153,\n",
            "         128,   308,    26, 29521,     8,    78,    13,    13,    13,\n",
            "          42,  1255,   725,     8,   249,  1942, 10632,     9,   249,\n",
            "        2842,   954,  1386,    18,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'code&comment2code: <code>private void testConnection(URL url) throws IOException { try { URLConnection connection = (URLConnection) ProxyConfiguration.open(url); <START> connection.setConnectTimeout(20000); END> connection.connect(); if(connection instanceof HttpURLConnection) { int responseCode = ((HttpURLConnection)connection).getResponseCode(); if(HttpURLConnection.HTTP_OK != responseCode) { throw new HttpRetryException(\"Invalid response code (\" + responseCode + \") from URL: \" + url.toString(), responseCode); } } else { Util.copyStreamAndClose(connection.getInputStream(),new NullOutputStream()); } } catch (SSLHandshakeException e) { if (e.getMessage().contains(\"PKIX path building failed\")) throw new IOException(\"Failed to validate the SSL certificate of \"+url,e); } }</code><technical_language>Is this fixed 20 seconds deliberately? reuse default ProxyConfiguration</technical_language>', 'inputs': array([   89,   767,  6392,   111,   220,    20,     7,     3,   854,\n",
            "          71,   317,   736,     9,   908,   649,    12,   169,   331,\n",
            "          15,   123,    15,  9181,   483,    16,    23,  9169,    12,\n",
            "        7091,   423,     8,  1750,     9,   698,    18,    60,  4011,\n",
            "          32,   483,     8,    19, 20091,     9, 16396,    18,  9636,\n",
            "          32,   483,     8,  3059,    39,    28,     9,  2018,   472,\n",
            "        1787,  4122,    12,    15,    75,     7, 14785,    16,    23,\n",
            "           9,  1058,  4122,    12,  2018,   147, 12601,    39,    28,\n",
            "           9,  1058,  4122,     8,  3502,    25,  2927,   125,     7,\n",
            "       14785,    12,    15,   161,    33,  3069,  5589,    66,    46,\n",
            "        1314,   301,    89,     7,    46,    61,     7, 14785,    61,\n",
            "           7,   223,    76,   634,    20,    41,    61,   649,     8,\n",
            "         260,   145,     7, 14785,    18,    13,    13,   121,    15,\n",
            "           7,   951,     8,  2246,   734,   856,  3647,     9,  2018,\n",
            "           8,  2982,   145,    98,  7025,   963,    93,    13,    13,\n",
            "         172,    23,  5277, 10421,    66,   107,    12,    15,    28,\n",
            "          23,   134,     8,   866,    81,   808,    46, 26005,   271,\n",
            "        3218,  1612,   727,   161,    33,   331,    46,  2169,    14,\n",
            "        1831,    10,  3800,  2043,    26,  1464,   698,    11,   134,\n",
            "          18,    13,    13,     4,     5,  2197,    36,  1346,  3108,\n",
            "        2004, 24738,   176,  4125,   252,  7091,   423,     6,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'private void testConnection(URL url) throws IOException { try { URLConnection connection = (URLConnection) ProxyConfiguration.open(url); if(connection instanceof HttpURLConnection) { int responseCode = ((HttpURLConnection)connection).getResponseCode(); if(HttpURLConnection.HTTP_OK != responseCode) { throw new HttpRetryException(\"Invalid response code (\" + responseCode + \") from URL: \" + url, responseCode); } } else { Util.copyStreamAndClose(connection.getInputStream(),new NullOutputStream()); } } catch (SSLHandshakeException e) { if (e.getMessage().contains(\"PKIX path building failed\")) throw new IOException(\"Failed to validate the SSL certificate of \"+url,e); } }', 'targets': array([  124,    71,   317,   736,     9,   908,   649,    12,   169,\n",
            "         331,    15,   123,    15,  9181,   483,    16,    23,  9169,\n",
            "          12,  7091,   423,     8,  1750,     9,   698,    18,    28,\n",
            "           9,  2018,   472,  1787,  4122,    12,    15,    75,     7,\n",
            "       14785,    16,    23,     9,  1058,  4122,    12,  2018,   147,\n",
            "       12601,    39,    28,     9,  1058,  4122,     8,  3502,    25,\n",
            "        2927,   125,     7, 14785,    12,    15,   161,    33,  3069,\n",
            "        5589,    66,    46,  1314,   301,    89,     7,    46,    61,\n",
            "           7, 14785,    61,     7,   223,    76,   634,    20,    41,\n",
            "          61,   649,    11,     7, 14785,    18,    13,    13,   121,\n",
            "          15,     7,   951,     8,  2246,   734,   856,  3647,     9,\n",
            "        2018,     8,  2982,   145,    98,  7025,   963,    93,    13,\n",
            "          13,   172,    23,  5277, 10421,    66,   107,    12,    15,\n",
            "          28,    23,   134,     8,   866,    81,   808,    46, 26005,\n",
            "         271,  3218,  1612,   727,   161,    33,   331,    46,  2169,\n",
            "          14,  1831,    10,  3800,  2043,    26,  1464,   698,    11,\n",
            "         134,    18,    13,    13,     1], dtype=int32)}\n",
            "4th TASK : marked code 2 code\n",
            "A few raw validation examples...\n",
            "{'input': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }', 'output': b'public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); } }); executor.submit(task); }'}\n",
            "{'input': b'public int hashCode() { <START> return element.hashCode(); <END> }', 'output': b'public int hashCode() { if (element == null) { return super.hashCode(); } return element.hashCode(); }'}\n",
            "{'input': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }', 'output': b'private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (!Util.isBlank(domainClassExpression) && !Util.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(EEFExpressionUtils.SELF, this.variableManager.getVariables().get(EEFExpressionUtils.SELF)); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }'}\n",
            "A few raw training examples...\n",
            "{'input': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: <START> return MarshallUtil.unmarshallCollection(input, s -> new LinkedList<>()); <END> case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }', 'output': b'public Collection readObject(ObjectInput input) throws IOException, ClassNotFoundException { int magicNumber = input.readUnsignedByte(); switch (magicNumber) { case ARRAY_LIST: return MarshallUtil.unmarshallCollection(input, ArrayList::new); case LINKED_LIST: return MarshallUtil.unmarshallCollectionUnbounded(input, LinkedList::new); case SINGLETON_LIST: return Collections.singletonList(input.readObject()); case EMPTY_LIST: return Collections.emptyList(); case HASH_SET: return MarshallUtil.unmarshallCollection(input, s -> new HashSet<>()); case TREE_SET: Comparator<Object> comparator = (Comparator<Object>) input.readObject(); return MarshallUtil.unmarshallCollection(input, s -> new TreeSet<>(comparator)); case SINGLETON_SET: return Collections.singleton(input.readObject()); case SYNCHRONIZED_SET: return Collections.synchronizedSet( MarshallUtil.unmarshallCollection(input, s -> new HashSet<>())); case ARRAY_DEQUE: return MarshallUtil.unmarshallCollection(input, ArrayDeque::new); case READ_ONLY_SEGMENT_AWARE_COLLECTION: return MarshallUtil.unmarshallCollection(input, ArrayList::new); default: throw new IllegalStateException(\"Unknown Set type: \" + magicNumber); } }'}\n",
            "{'input': b'<START> public static Command<Set<Cookie>> getAllCookies() { <END> return new Command<>(domainName + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", new TypeToken<Set<Cookie>>() {}.getType())); }', 'output': b'public static Command<Cookies> getAllCookies() { return new Command<>(DOMAIN_NAME + \".getAllCookies\", ImmutableMap.of(), map(\"cookies\", Cookies.class)); }'}\n",
            "{'input': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if (blockIn instanceof BlockPistonBase) { final IBlockState blockstate = this.getBlockState(pos); EnumFacing direction = (EnumFacing) blockstate.getValue(BlockDirectional.FACING); BlockPistonStructureHelper movedBlocks = new BlockPistonStructureHelper(this$, pos, direction, eventId == 0); List<BlockPos> blocks = new ArrayList<BlockPos>(); blocks.addAll(movedBlocks.getBlocksToDestroy()); blocks.addAll(movedBlocks.getBlocksToMove()); List<Location<org.spongepowered.api.world.World>> locations = new ArrayList<Location<org.spongepowered.api.world.World>>(); for (BlockPos block : blocks) { <START> locations.add(new Location<>((org.spongepowered.api.world.World) this$, block.getX(), block.getY(), block.getZ())); <END> } if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos, locations)) { return false; } } else { if (SpongeCommonEventFactory.handleChangeBlockEventPre(this, pos)) { return false; } } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }', 'output': b'public boolean onAddBlockEvent(WorldServer.ServerBlockEventList list, Object obj, BlockPos pos, Block blockIn, int eventId, int eventParam) { if ((blockIn instanceof BlockPistonBase && SpongeCommonEventFactory.handlePistonEvent(this, list, obj, pos, blockIn, eventId, eventParam)) || SpongeCommonEventFactory.callChangeBlockEventPre(this, pos, NamedCause.of(NamedCause.BLOCK_EVENT, this)).isCancelled()) { return false; } if (CauseTracker.ENABLED) { final CauseTracker causeTracker = this.getCauseTracker(); final PhaseData currentPhase = causeTracker.getCurrentPhaseData(); final IPhaseState phaseState = currentPhase.state; if (phaseState.getPhase().ignoresBlockEvent(phaseState)) { return list.add((BlockEventData) obj); } final BlockEventData blockEventData = (BlockEventData) obj; final PhaseContext context = currentPhase.context; IMixinBlockEventData blockEvent = (IMixinBlockEventData) blockEventData; phaseState.getPhase().addNotifierToBlockEvent(phaseState, context, causeTracker, pos, blockEvent); } return list.add((BlockEventData) obj); }'}\n",
            "A few preprocessed training examples...\n",
            "{'inputs_pretokenized': b'markedCode2code: public List<PermissionSubject> getPermissionCheckSubjects() { List<PermissionSubject> listPermissionSubjects = new ArrayList<>(); <START> if (!isImageProvided()) { <END> listPermissionSubjects.add(new PermissionSubject(getParameters().getStorageDomainId(), VdcObjectType.Storage, ActionGroup.CREATE_DISK)); } else { listPermissionSubjects.add(new PermissionSubject(getParameters().getImageId(), VdcObjectType.Disk, ActionGroup.CREATE_DISK)); } return listPermissionSubjects; }', 'inputs': array([ 4447,   830,   111,   220,    20,    44,   170,    40,  2761,\n",
            "        4372,    32,    99,  2761,  2054,  4372,    19,    43,    15,\n",
            "         170,    40,  2761,  4372,    32,   141,  2761,  4372,    19,\n",
            "          16,    33,   266,   737,    60,  4011,    32,    28,   387,\n",
            "         249,   833, 13566,   101,    15,    60,  3921,    32,   141,\n",
            "        2761,  4372,    19,     8,   117,     9,    98,     7,  2761,\n",
            "        4372,     9,  8920,    81, 17439,  3078,   183,   145,  1056,\n",
            "        5345, 11686,     8,  2748,    11,  3514,   638,     8,  4932,\n",
            "          25, 27709,   164,    13,   121,    15,   141,  2761,  4372,\n",
            "          19,     8,   117,     9,    98,     7,  2761,  4372,     9,\n",
            "        8920,    81,  7127,   183,   145,  1056,  5345, 11686,     8,\n",
            "        5838,    11,  3514,   638,     8,  4932,    25, 27709,   164,\n",
            "          13,    42,   141,  2761,  4372,    19,    24,    13,     1],\n",
            "      dtype=int32), 'targets_pretokenized': b'public List<PermissionSubject> getPermissionCheckSubjects() { List<PermissionSubject> listPermissionSubjects = new ArrayList<>(); if (isImageProvided()) { listPermissionSubjects.add(new PermissionSubject(getParameters().getImageId(), VdcObjectType.Disk, ActionGroup.CREATE_DISK)); } else { listPermissionSubjects.add(new PermissionSubject(getParameters().getStorageDomainId(), VdcObjectType.Storage, ActionGroup.CREATE_DISK)); } return listPermissionSubjects; }', 'targets': array([   44,   170,    40,  2761,  4372,    32,    99,  2761,  2054,\n",
            "        4372,    19,    43,    15,   170,    40,  2761,  4372,    32,\n",
            "         141,  2761,  4372,    19,    16,    33,   266,   737,    28,\n",
            "          23,   249,   833, 13566,   101,    15,   141,  2761,  4372,\n",
            "          19,     8,   117,     9,    98,     7,  2761,  4372,     9,\n",
            "        8920,    81,  7127,   183,   145,  1056,  5345, 11686,     8,\n",
            "        5838,    11,  3514,   638,     8,  4932,    25, 27709,   164,\n",
            "          13,   121,    15,   141,  2761,  4372,    19,     8,   117,\n",
            "           9,    98,     7,  2761,  4372,     9,  8920,    81, 17439,\n",
            "        3078,   183,   145,  1056,  5345, 11686,     8,  2748,    11,\n",
            "        3514,   638,     8,  4932,    25, 27709,   164,    13,    42,\n",
            "         141,  2761,  4372,    19,    24,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'markedCode2code: void afterNamesPerGroupChanged() { <START> String namesNumber = namesPerGroup.getText().toString().trim(); <END> if (namesPerGroup.isFocused() && isValid(namesNumber)) { numGroups.setText(getOffset(namesNumber)); } dialog.getActionButton(DialogAction.POSITIVE).setEnabled(isValid(namesNumber)); }', 'inputs': array([ 4447,   830,   111,   220,    20,    71,   340,   150,  6694,\n",
            "         638,  2602,    43,    15,    60,  4011,    32,    53,   824,\n",
            "         654,    16,    97,  6694,   638,     8,  1216,    81,   260,\n",
            "          81,  1468,    39,    60,  3921,    32,    28,    23,   155,\n",
            "        6694,   638,     8,   249, 20337,    43,   190,  7057,     9,\n",
            "        4521,   654,   195,    15,   945,  3120,     8,  1021,     9,\n",
            "        9010,     9,  4521,   654,   164,    13,  1484,     8,  6959,\n",
            "         818,     9,  1960,   871,     8, 12336,   147,  5369,     9,\n",
            "        5261,     9,  4521,   654,   164,    13,     1], dtype=int32), 'targets_pretokenized': b'void afterNamesPerGroupChanged() { String namesPerGroupInput = namesPerGroup.getText().toString().trim(); if (namesPerGroup.isFocused() && isValid(namesNumber)) { numGroups.setText(getOffset(namesNumber)); } dialog.getActionButton(DialogAction.POSITIVE).setEnabled(isValid(namesNumber)); }', 'targets': array([   71,   340,   150,  6694,   638,  2602,    43,    15,    53,\n",
            "          97,  6694,   638,   994,    16,    97,  6694,   638,     8,\n",
            "        1216,    81,   260,    81,  1468,    39,    28,    23,   155,\n",
            "        6694,   638,     8,   249, 20337,    43,   190,  7057,     9,\n",
            "        4521,   654,   195,    15,   945,  3120,     8,  1021,     9,\n",
            "        9010,     9,  4521,   654,   164,    13,  1484,     8,  6959,\n",
            "         818,     9,  1960,   871,     8, 12336,   147,  5369,     9,\n",
            "        5261,     9,  4521,   654,   164,    13,     1], dtype=int32)}\n",
            "{'inputs_pretokenized': b'markedCode2code: protected void deallocate(Event event) { log.info(\"Deallocating [{}:{}]\", event.getResourceType(), event.getResourceId()); AllocationRequest request = new AllocationRequest(event); try { allocator.deallocate(request); log.info(\"Deallocator [{}] handled request [{}]\", allocator, request); eventService.publish(EventVO.reply(event)); } catch (AllocationException e) { String errorMessage = \"Failed to deallocate: \" + e.getMessage(); eventService.publish(EventVO.reply(event).withTransitioningMessage(errorMessage).withTransitioning(Event.TRANSITIONING_ERROR)); } <START> eventService.publish(EventVO.reply(event)); <END> }', 'inputs': array([ 4447,   830,   111,   220,    20,   395,    71,  2368,  6314,\n",
            "           9,   566,   499,    12,    15,   451,     8,   812,    46,\n",
            "        4942, 13539,  3558, 21985,    96,    20,  5228,  4143,   499,\n",
            "           8, 16566,   145,   499,     8, 21673,    93,     7, 10442,\n",
            "         229,   185,    16,    33,     7, 10442,   229,     9,   944,\n",
            "          18,   123,    15,     7,  1154, 10150,     8,  2355,  6314,\n",
            "           9,   573,    18,   451,     8,   812,    46, 18879, 10150,\n",
            "       12611,  3221,   185,     7, 13093,     7,  1154, 10150,    11,\n",
            "         185,    18,   499,   365,     8,  7488,     9,   566,  7879,\n",
            "           8,  9904,     9,   944,   164,    13,   172,    23, 10442,\n",
            "          66,   107,    12,    15,    53,  9743,    16,    41,  2169,\n",
            "          14,  2368,  6314,    20,    41,    61,   107,     8,   866,\n",
            "          39,   499,   365,     8,  7488,     9,   566,  7879,     8,\n",
            "        9904,     9,   944,   147,   720,  4361,   209,   511,     9,\n",
            "       14324,   147,   720,  4361,   209,     9,   566,     8, 31922,\n",
            "        2890,    25,  1944,   164,    13,    60,  4011,    32,   499,\n",
            "         365,     8,  7488,     9,   566,  7879,     8,  9904,     9,\n",
            "         944,   164,    60,  3921,    32,    13,     1], dtype=int32), 'targets_pretokenized': b'protected void deallocate(Event event) { log.info(\"Deallocating [{}:{}]\", event.getResourceType(), event.getResourceId()); AllocationRequest request = new AllocationRequest(event); try { allocator.deallocate(request); log.info(\"Deallocator [{}] handled request [{}]\", allocator, request); eventService.publish(EventVO.reply(event)); } catch (FailedToAllocate e) { String errorMessage = \"Failed to deallocate: \" + e.getMessage(); eventService.publish(EventVO.reply(event).withTransitioningMessage(errorMessage).withTransitioning(Event.TRANSITIONING_ERROR)); } }', 'targets': array([  395,    71,  2368,  6314,     9,   566,   499,    12,    15,\n",
            "         451,     8,   812,    46,  4942, 13539,  3558, 21985,    96,\n",
            "          20,  5228,  4143,   499,     8, 16566,   145,   499,     8,\n",
            "       21673,    93,     7, 10442,   229,   185,    16,    33,     7,\n",
            "       10442,   229,     9,   944,    18,   123,    15,     7,  1154,\n",
            "       10150,     8,  2355,  6314,     9,   573,    18,   451,     8,\n",
            "         812,    46, 18879, 10150, 12611,  3221,   185,     7, 13093,\n",
            "           7,  1154, 10150,    11,   185,    18,   499,   365,     8,\n",
            "        7488,     9,   566,  7879,     8,  9904,     9,   944,   164,\n",
            "          13,   172,    23,  2169,   314, 18923,   107,    12,    15,\n",
            "          53,  9743,    16,    41,  2169,    14,  2368,  6314,    20,\n",
            "          41,    61,   107,     8,   866,    39,   499,   365,     8,\n",
            "        7488,     9,   566,  7879,     8,  9904,     9,   944,   147,\n",
            "         720,  4361,   209,   511,     9, 14324,   147,   720,  4361,\n",
            "         209,     9,   566,     8, 31922,  2890,    25,  1944,   164,\n",
            "          13,    13,     1], dtype=int32)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Qx699vN302"
      },
      "source": [
        "def _rate_num_input_examples(task):\n",
        "  if \"train\" in task.splits:\n",
        "    return float(task.num_input_examples(\"train\"))\n",
        "  elif \"validation\" in task.splits:\n",
        "    return float(task.num_input_examples(\"validation\"))\n",
        "  else:\n",
        "    raise ValueError(\"Task %s does not have a train or validation split.\" % (task.name))\n",
        "\n",
        "\n",
        "t5.data.MixtureRegistry.remove(\"all_tasks\")\n",
        "t5.data.MixtureRegistry.add(\n",
        "    \"all_tasks\",\n",
        "    # [\"code_comment\"],\n",
        "    [\"marked_code\"],\n",
        "    # [\"code_code\"],\n",
        "    # [\"codeANDcomment_code\"],\n",
        "    # [\"codeANDcomment_code\", \"code_code\", \"code_comment\"],\n",
        "    default_rate=_rate_num_input_examples\n",
        "     #default_rate=1.0\n",
        ")\n",
        "\n",
        "\n",
        "from mesh_tensorflow.transformer.learning_rate_schedules import slanted_triangular \n",
        "\n",
        "# from mesh_tensorflow.transformer.learning_rate_schedules import truncated_rsqrt\n",
        " \n",
        "# from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
        "\n",
        "# starter_learning_rate = 0.05\n",
        "# end_learning_rate = 0.001\n",
        "# decay_steps = 10000\n",
        "\n",
        "# learning_rate_fn = PolynomialDecay(\n",
        "#     starter_learning_rate,\n",
        "#     decay_steps,\n",
        "#     end_learning_rate,\n",
        "#     power=0.5)\n",
        "\n",
        "\n",
        "MODEL_SIZE = \"small\"\n",
        "\n",
        "############ CHANGE HERE ############\n",
        "MODEL_DIR = 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code'\n",
        "\n",
        "# Specify the pre-trained dir which must contain the pre-trained models, the operative_config.gin file and the checkpoint file as well\n",
        "PRETRAINED_DIR='gs://code_review_automation/model_dumps/'\n",
        "\n",
        "\n",
        "model_parallelism, train_batch_size, keep_checkpoint_max = {\n",
        "    \"small\": (1, 128, 200),\n",
        "    \"base\": (2, 128, 8),\n",
        "    \"large\": (8, 64, 4),\n",
        "    \"3B\": (8, 16, 1),\n",
        "    \"11B\": (8, 16, 1)}[MODEL_SIZE]\n",
        "\n",
        "tf.io.gfile.makedirs(MODEL_DIR)\n",
        "\n",
        "model = t5.models.MtfModel(\n",
        "    model_dir=MODEL_DIR,\n",
        "    tpu=TPU_ADDRESS,\n",
        "    tpu_topology=TPU_TOPOLOGY,\n",
        "    model_parallelism=model_parallelism,\n",
        "    batch_size=train_batch_size,\n",
        "    ############ CHANGE HERE ############\n",
        "    learning_rate_schedule = slanted_triangular,\n",
        "    sequence_length={\"inputs\": 512, \"targets\": 512},\n",
        "    save_checkpoints_steps=10000,\n",
        "    keep_checkpoint_max=keep_checkpoint_max if ON_CLOUD else None,\n",
        "    iterations_per_loop=100,\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guHsDBYHv69m",
        "outputId": "878e144c-261a-4f0f-a0c6-0176f1d9992d"
      },
      "source": [
        "############ CHANGE HERE ############\n",
        "!gsutil cp gs://code_review_automation/fine_tuning/slanted/operative_config.gin ./operative_config.gin \n",
        "PATH_GIN_FILE = '/content/operative_config.gin'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://code_review_automation/fine_tuning/slanted/operative_config.gin...\n",
            "/ [0 files][    0.0 B/ 11.6 KiB]                                                \r/ [1 files][ 11.6 KiB/ 11.6 KiB]                                                \r\n",
            "Operation completed over 1 objects/11.6 KiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhmkUKWgNFAX",
        "outputId": "698eb268-5f3f-4536-d7ac-ab8e5a2d3870"
      },
      "source": [
        "import gin\n",
        "\n",
        "with gin.unlock_config():\n",
        "    gin.parse_config_file(PATH_GIN_FILE)\n",
        "    #RUN FINE-TUNING\n",
        "    FINETUNE_STEPS = 300000\n",
        "    model.finetune(\n",
        "        mixture_or_task_name=\"all_tasks\",\n",
        "        pretrained_model_dir=PRETRAINED_DIR,\n",
        "        finetune_steps=FINETUNE_STEPS\n",
        "    )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://code_review_automation/model_dumps/operative_config.gin\n",
            "ERROR:root:Path not found: gs://code_review_automation/model_dumps/operative_config.gin\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
            "INFO:tensorflow:training_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAo_rui4HXcT",
        "outputId": "7c4cff0b-62e1-44fe-daa4-6703ca6843ef"
      },
      "source": [
        "# Use a larger batch size for evaluation, which requires less memory.\n",
        "model.batch_size = 1024\n",
        "model.eval(\n",
        "    mixture_or_task_name=\"all_tasks\",\n",
        "    checkpoint_steps=[220000, 230000, 240000, 250000, 260000, 270000, 280000, 290000, 300000, 310000, 325500, 335500, 345500, 355500, 365500, 375500, 385500, 395500, 405500, 415500, 425500, 435500, 437400, 447400, 457400, 467400, 477400, 487400, 497400, 500000]\n",
        "    )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:system_path_file_exists:gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/operative_config.gin\n",
            "ERROR:root:Path not found: gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/operative_config.gin\n",
            "/usr/local/lib/python3.7/dist-packages/seqio/preprocessors.py:90: UserWarning: Creating resources inside a function passed to Dataset.map() is not supported. Create each resource outside the function, and capture it inside the function to use it.\n",
            "  _tokenize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
            "INFO:absl:Skipping packing/padding for 'marked_code' since sequence length is None.\n",
            "INFO:absl:Setting sequence lengths to {'inputs': 513, 'targets': 512}\n",
            "INFO:absl:Evaluating checkpoint step: 220000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f11ff9153d0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-220000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = password != null ? Secret.fromString(password) : null; this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { this.slaveConnectTimeout = 0; } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (Exception e) { logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 220000: 3.148\n",
            "INFO:absl:Evaluating checkpoint step: 230000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f120456ccd0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-230000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { this.slaveConnectTimeout = 0; } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (Exception e) { logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, HALF_WIDTH); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"rssi cannot be null.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (sourceAddress == null) throw new NullPointerException(\"RSSI value must be between 0 and 255.\"); if (rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 255.\"); if (receiveOptions < 0) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); if (receivedData < 0) throw new IllegalArgumentException(\" received data must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 230000: 4.808\n",
            "INFO:absl:Evaluating checkpoint step: 240000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f120475db50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-240000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if ((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = Math.min(slaveConnectTimeout, 0); }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); fail(\"Should not be able to validate the schema with UUID.\"); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); this.disks.addAll(this.disks); this.disks.addAll(this.disks); this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100)); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0) throw new IllegalArgumentException(\"rssi cannot be negative.\"); if (receiveOptions < 0) throw new IllegalArgumentException(\"Receive options value cannot be null.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { String url = \"<LINK_0>\"; Link.create(link(url)); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(compare(filterExprNoAlias, Qualifier.replaceMilestoneAliases(filterExpr))) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 240000: 5.546\n",
            "INFO:absl:Evaluating checkpoint step: 250000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f120156ad90>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-250000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).showErrorScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public synchronized void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } synchronized (brokerConnections) { for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if ((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IOException | HardwareStateException e) { logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; List<String> createTableList = new ArrayList<String>(); for (final String createTable : createTableList) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, CURSOR_STYLE); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"64-bit source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); if (sourceAddress == null) throw new IllegalArgumentException(\"64-bit source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 255.\"); if (receiveOptions > 255) throw new IllegalArgumentException(\"ReceiveOptions value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { return options.getClusterName(); } try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(Comparator.comparing(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 250000: 5.814\n",
            "INFO:absl:Evaluating checkpoint step: 260000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f12010270d0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-260000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && StringUtils.isBlank(domainClassExpression) && StringUtils.isBlank( switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() != config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = Math.max(0, this.slaveConnectTimeout); }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (Exception e) { logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : createTableStatement, defaultCreateTableStatement) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, ROW_NUMBER); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { String s = streamToString(getStatsFromWebpack()); if (s == null) { return null; } } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 260000: 5.492\n",
            "INFO:absl:Evaluating checkpoint step: 270000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1201093310>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-270000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { int result = element.hashCode(); result = 31 * result + (element.hashCode() != null ? element.hashCode() : 0); return result; }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && StringUtils.isBlank(domainClassExpression) && StringUtils.isBlank( switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public boolean removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { final MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return false; } final String brokerNameWithoutBroker = brokerConnections.remove(brokerName); if (brokerNameWithoutBroker) { for (final MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } return true; } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = (password != null) ? Secret.fromString(password) : null; this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); fail(\"Validation should have thrown an exception\"); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.ports = new HashMap<String, String>(); this.disks.put(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig.get(this.clusterMapConfig\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; @Override public void run(final String createTable) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, DOUBLE); mockCellsWithPadding(1, 0, PADDING, DOUBLE); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return StatsAssets.streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 270000: 5.927\n",
            "INFO:absl:Evaluating checkpoint step: 280000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1202b7ff90>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-280000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public boolean removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { final MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return false; } return connection.brokerRemoved(connection); } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { if (config.getMaxChildren() == 0) { addSiblingNode(indexOfNode - 1); return; } } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = password == null ? null : Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = Math.max(0, slaveConnectTimeout); }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (NoSuchAlgorithmException | InvalidStateException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<String, Disk>(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return getStatsFromWebpack(); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier, true)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 280000: 5.855\n",
            "INFO:absl:Evaluating checkpoint step: 290000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f12034c9290>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-290000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && StringUtils.isBlank(domainClassExpression) && StringUtils.isBlank(switchExpression) && StringUtils.isBlank(switchExpression.trim())) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public boolean removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return false; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } return true; }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(Constants.DEFAULT_INDEX_BUILDER_XML_SCHEMA_NS_URI); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (NullPointerException | HardwareStateNotFoundException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } catch (JSONException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Guid, Disk>(diskJSONArray.length()); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 1D); mockCellsWithPadding(1, 0, PADDING, 2D); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public Object goToweb (View view) { link(\"<LINK_0>\"); return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 290000: 6.105\n",
            "INFO:absl:Evaluating checkpoint step: 300000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1200709e50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-300000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = password == null ? null : Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { final SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); final URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); fail(\"Validation should have failed because: \" + schemaResource.toString()); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (JSONException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, Disk>(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try (final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 20.0); mockCellsWithPadding(1, 0, PADDING, 150, 20.0); mockCellsWithPadding(2, 0, PADDING, 20.0); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"64-bit source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new 16RuntimeException( \"16-bit source address cannot be empty.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { return options.getClusterName(); } try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 300000: 6.201\n",
            "INFO:absl:Evaluating checkpoint step: 310000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1202cb51d0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-310000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { final MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { this.slaveConnectTimeout = DEFAULT_slaveConnectTimeout; } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (JSONException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Guid, Disk>(diskJSONArray.length()); populatePorts(diskJSONArray.length()); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 1d); mockCellsWithPadding(1, 0, PADDING, 2d); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(compare(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(compare(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 310000: 6.206\n",
            "INFO:absl:Evaluating checkpoint step: 325500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f120216cd50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-325500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(window); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public boolean removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { final MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return false; } return brokerConnections.remove(brokerName); } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Util.fixEmptyAndTrim(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { final SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); final URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); final InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); final Source source = new StreamSource(xmlResource); final Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks.clear(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; final List<String> createTablecommentsOnColumn = createTablecommentsOnColumn.stream() .map(connection -> connection.createStatement() .flatMap(connection -> connection.createStatement().execute(connection)) .collect(Collectors.toList()); if (createTablecommentsOnColumn.size() > 0) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTablecommentsOnColumn); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, INITIALI ⁇ E); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"ReceiveOptions value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 325500: 6.379\n",
            "INFO:absl:Evaluating checkpoint step: 335500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1201889050>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-335500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && !domainClassExpression.trim().isEmpty() && !switchExpression.trim().isEmpty()) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Util.fixEmptyAndTrim(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { this.slaveConnectTimeout = 0; } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { final SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); final URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, CapacityHelper>(); this.disks.put(this.rawCapacityInBytes, calculateRawCapacityInBytes()); this.disks.put(this.rawCapacityInBytes, calculateRawCapacityInBytes()); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; try (final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); int width = 0; mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 335500: 6.367\n",
            "INFO:absl:Evaluating checkpoint step: 345500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f12000a6550>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-345500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.id().hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && StringUtils.isBlank(domainClassExpression.trim()) && StringUtils.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public boolean removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { final MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return false; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } return true; } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); fail(\"Validation failed\"); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.dataNodeStatePolicy = new HashMap<Disk, Datacenter>(); this.disks.put(this.dataNodeStatePolicy, clusterMapConfig); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : createTableStatement.split(defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(filterExprNoAlias(filterExpr)) .limit(filterCount(allModelIssues, filterExprNoAlias(filterExpr)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 345500: 6.135\n",
            "INFO:absl:Evaluating checkpoint step: 355500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f12021e5290>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-355500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); String err = task.getException().cause(task.getException()).window(window).returnToScene(createScene.get()).build(); errorComponent.cause(err).showErrorScene(err); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && StringUtils.isBlank(domainClassExpression) && StringUtils.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { final MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } CoreNode latestNode = latestBranch.get(indexOfNode - 1); if (latestNode != null && latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { this.slaveConnectTimeout = DEFAULT_SLAVE_JENKINS_CONNECTION_TIMEOUT; } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { this.dataNodeStatePolicy = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(diskJSONArray.length()); this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks.addAll(diskJSONArray.clone()); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : createTableStatement; defaultCreateTableStatement.executeUpdate(createTable); } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 355500: 6.117\n",
            "INFO:absl:Evaluating checkpoint step: 365500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f120065d3d0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-365500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(ticks.get()); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && StringUtils.isBlank(domainClassExpression.trim()) && StringUtils.isBlank(switchExpression.trim())) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() != config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Util.fixEmptyAndTrim(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); try (InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (NullPointerException | InvalidConfigurationException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(diskJSONArray.length()); populatePorts(disks); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(sort(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 365500: 6.242\n",
            "INFO:absl:Evaluating checkpoint step: 375500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1202af6f50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-375500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return Objects.hash(element, name, attributes); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && StringUtils.isBlank(domainClassExpression) && StringUtils.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { final MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { this.slaveConnectTimeout = 0; return; } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error parsing cluster map state policy when instantiating a node: {}\", e); throw new IllegalStateException(\"Error parsing cluster map state policy when instantiating a node: \" + clusterMapConfig, e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks.clear(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 375500: 6.201\n",
            "INFO:absl:Evaluating checkpoint step: 385500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1201b37f10>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-385500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && StringUtils.isBlank(domainClassExpression) && StringUtils.isBlank(switchExpression)) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public boolean removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return false; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } return true; }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); try (InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName)) { Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.dataNodeStatePolicy = new HashMap<String, DataNodeStatePolicy>(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : createTableStatements(entity, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { return options.getClusterName(); } try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 385500: 6.415\n",
            "INFO:absl:Evaluating checkpoint step: 395500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f12018a91d0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-395500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); causeComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); try (InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (Exception e) { logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, DataNodeConfig>(); this.disks.put(diskJSONArray.length(), clusterMapConfig); populateReadWriteInBytes(disks, clusterMapConfig); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; @Nullable  Statement statement = conn.createStatement() ; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try { statement.executeUpdate(createTable); } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 395500: 6.635\n",
            "INFO:absl:Evaluating checkpoint step: 405500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1203305690>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-405500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); Animations.createShakeWindowAnimation(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } brokerConnections.remove(brokerName); } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, DataNode>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.put(i, clusterMapConfig); } validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; @SuppressWarnings(\"unchecked\") final List<String> createTableIterable = Arrays.asList(createTableStatement, defaultCreateTableStatement); for (final String createTable : createTableIterable) { try (final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id for options: \" + options.getClusterName()); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 405500: 6.516\n",
            "INFO:absl:Evaluating checkpoint step: 415500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f120160d410>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-415500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); CompletableFuture.completedFuture(errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return HashUtil.combineHashCodes(super.hashCode(), element.hashCode()); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.remove(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = password != null ? Secret.fromString(password) : null; this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { this.slaveConnectTimeout = 0; return; } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error creating resource state policy when instantiating a data node\", e); throw new IllegalStateException(\"Error creating resource state policy when instantiating a data node\", e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<String, Integer>(); this.disks.put(this.disks.size(), 0); populateReadWriteBuffers(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : Collections.singletonList(createTableStatement, defaultCreateTableStatement)) { try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineCount(allModelIssues, filterExprNoAlias)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 415500: 6.641\n",
            "INFO:absl:Evaluating checkpoint step: 425500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1200aeff50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-425500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); Animations.createShakeWindowAnimation(window).play(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (null != domainClassExpression && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } if (brokerConnections.remove(brokerName)) { for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if ((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = Math.max(0, slaveConnectTimeout); }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, Integer>(); this.disks.addAll(diskJSONArray.length()); Collections.sort(this.disks, new Comparator<Disk>() { @Override public int compare(Disk disk, Disk disk) { return disk.length() - 1; } }); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.minimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 425500: 6.629\n",
            "INFO:absl:Evaluating checkpoint step: 435500\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1201ae4a50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-435500\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new ArrayList<Disk>(diskJSONArray.length()); this.disks.addAll(diskJSONArray.length()); this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 435500: 6.659\n",
            "INFO:absl:Evaluating checkpoint step: 437400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f12021b0350>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-437400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, Integer>(); this.disks.put(diskJSONArray.length(), clusterMapConfig); populateReadWriteInBytes(diskJSONArray.length(), clusterMapConfig); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 437400: 6.802\n",
            "INFO:absl:Evaluating checkpoint step: 447400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1200fe4a10>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-447400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, Integer>(); this.disks.put(diskJSONArray.length(), clusterMapConfig); populateReadWriteInBytes(diskJSONArray.length(), clusterMapConfig); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 447400: 6.802\n",
            "INFO:absl:Evaluating checkpoint step: 457400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1201e983d0>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-457400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } catch (JSONException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks.clear(); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try (final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 457400: 6.659\n",
            "INFO:absl:Evaluating checkpoint step: 467400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1201af9610>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-467400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, Integer>(); this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks.put(this.rawCapacityInBytes, calculateRawCapacityInBytes()); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } try (InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 467400: 6.915\n",
            "INFO:absl:Evaluating checkpoint step: 477400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f11ff9f4910>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-477400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } brokerConnections.remove(brokerName); for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (Exception e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, Set<Disk>>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.put(i, new HashSet<Disk>(diskJSONArray.getJSONObject(i))); } validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } try (InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 477400: 6.843\n",
            "INFO:absl:Evaluating checkpoint step: 487400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1203828310>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-487400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (latestBranch.get(indexOfNode - 1).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (Exception e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, String>(); this.disks.put(this.disks.size(), diskJSONArray.length()); this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = Collections.unmodifiableMap(this.disks); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(compare(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(compare(filterExprNoAlias, Qualifier.replaceMilestoneAliases(models, filterExpr)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 487400: 6.706\n",
            "INFO:absl:Evaluating checkpoint step: 497400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f1201d0ad50>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-497400\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); Animation errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } final String brokerID = brokerConnections.remove(brokerName); if (brokerConnections.isEmpty()) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (latestBranch.getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, Integer>(); this.disks.put(diskJSONArray.length(), clusterMapConfig); populateDigitalCapacityInBytes(diskJSONArray); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } try (InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 497400: 6.706\n",
            "INFO:absl:Evaluating checkpoint step: 500000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 10000, '_save_checkpoints_secs': None, '_session_config': graph_options {\n",
            "  rewrite_options {\n",
            "    disable_meta_optimizer: true\n",
            "  }\n",
            "}\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.73.70.58:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({'worker': ['10.73.70.58:8470']}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.73.70.58:8470', '_evaluation_master': 'grpc://10.73.70.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=100, num_shards=None, num_cores_per_replica=1, per_host_input_for_training=4, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1, experimental_allow_per_host_v2_parallel_get_next=False, experimental_feed_hook=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu.tpu_cluster_resolver.TPUClusterResolver object at 0x7f120257de50>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.73.70.58:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Initializing TPU system (master: grpc://10.73.70.58:8470) to fetch topology for model parallelism. This might take a while.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 2335623954687684864)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, -8837840486756139988)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 1583207433166832106)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, -3043370306099144058)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 7680278410970060099)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4524627161987172487)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, -1083132789948562032)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2015131200462960203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, -8406823457850150035)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, -4957423160843909765)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, -2898529446383314506)\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Padding 'marked_code' with sequence lengths: {'inputs': 513, 'targets': 512}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:num_cores_per_replica: 1\n",
            "INFO:tensorflow:computation_shape: [1, 1, 1, 1]\n",
            "INFO:tensorflow:num_replicas: 8\n",
            "INFO:tensorflow:device_assignment.topology.device_coordinates: [[[0 0 0 0]\n",
            "  [0 0 0 1]\n",
            "  [1 0 0 0]\n",
            "  [1 0 0 1]\n",
            "  [0 1 0 0]\n",
            "  [0 1 0 1]\n",
            "  [1 1 0 0]\n",
            "  [1 1 0 1]]]\n",
            "INFO:tensorflow:device_assignment.core_assignment: [[[0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0]]\n",
            "\n",
            " [[1 0 0 1]]\n",
            "\n",
            " [[0 1 0 0]]\n",
            "\n",
            " [[0 1 0 1]]\n",
            "\n",
            " [[1 1 0 0]]\n",
            "\n",
            " [[1 1 0 1]]]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_shape=[8] physical_shape=[2, 2, 2]\n",
            "INFO:tensorflow:auto_logical_to_physical_tpu logical_to_physical = [(0, 0, 0), (0, 0, 1), (0, 1, 0), (0, 1, 1), (1, 1, 0), (1, 1, 1), (1, 0, 0), (1, 0, 1)]\n",
            "WARNING:tensorflow:SimdMeshImpl ignoring devices ['', '', '', '', '', '', '', '']\n",
            "INFO:tensorflow:SimdMeshImpl init: Shape[batch=8] LayoutRules{('experts', 'batch'), ('batch', 'batch'), ('d_ff', 'model'), ('vocab', 'model'), ('ensemble', 'ensemble'), ('heads', 'model')}\n",
            "INFO:tensorflow:Device Assignment: <tensorflow.python.tpu.device_assignment.DeviceAssignment object at 0x7f120094c890>\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable encoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "WARNING:tensorflow:Using default tf glorot_uniform_initializer for variable decoder/block_000/layer_000/SelfAttention/relative_attention_bias  The initialzer will guess the input and output dimensions  based on dimension order.\n",
            "INFO:tensorflow:Create pnum_tensor\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Casting <dtype: 'int32'> to float32 for allreduce\n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_000/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_001/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_002/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_003/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_004/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/k                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/o                size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/q                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_001/EncDecAttention/v                size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable decoder/block_005/layer_002/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_000/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_001/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_002/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_003/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_004/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/k                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/o                  size 262144       slice_size 262144       Shape[heads=512, d_model=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/q                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_000/SelfAttention/v                  size 262144       slice_size 262144       Shape[d_model=512, heads=512]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wi/kernel         size 1048576      slice_size 1048576      Shape[d_model=512, d_ff=2048]                               \n",
            "INFO:tensorflow:Variable encoder/block_005/layer_001/DenseReluDense/wo/kernel         size 1048576      slice_size 1048576      Shape[d_ff=2048, d_model=512]                               \n",
            "INFO:tensorflow:Variable shared/embedding                                             size 16449536     slice_size 16449536     Shape[vocab=32128, d_model=512]                             \n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/SelfAttention/relative_attention_bias size 512          slice_size 512          Shape[stacked=2, heads=8, buckets=32]                       \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/SelfAttention/relative_attention_bias\n",
            "INFO:tensorflow:Variable stacked/encoder/block_000/layer_000/layer_norm/scale         size 16384        slice_size 16384        Shape[stacked=32, d_model=512]                              \n",
            "INFO:tensorflow:    encoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    encoder/final_layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_000/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_001/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_002/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_003/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_004/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_000/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_001/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/block_005/layer_002/layer_norm/scale\n",
            "INFO:tensorflow:    decoder/final_layer_norm/scale\n",
            "INFO:tensorflow:Trainable Variables            count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:All Variables                  count: 99      Total size: 60506624         Total slice_size: 60506624       \n",
            "INFO:tensorflow:Counters:\n",
            "allconcat: 8.4e+06\n",
            " allconcat/0: 8.4e+06\n",
            "  allconcat/0/reshape_op: 8.4e+06\n",
            "allreduce: 8\n",
            " allreduce/[0]: 8\n",
            "  allreduce/[0]/reduce_op: 8\n",
            "einsum: 5.41e+13\n",
            "einsum_unique: 5.41e+13\n",
            "output: 5.36e+11\n",
            " output/AddOperation: 1.38e+11\n",
            " output/BinaryOpWithBroadcasting: 1.68e+09\n",
            " output/Constant: 3.23e+09\n",
            " output/EinsumOperation: 1.22e+11\n",
            " output/ImportOperation: 8.4e+06\n",
            " output/MinMaxOperation: 3.84e+07\n",
            " output/OneHotOperation: 3.46e+10\n",
            " output/RangeOperation: 8.21e+03\n",
            " output/ReduceOperation: 1.68e+08\n",
            " output/ReshapeOperation: 2.77e+10\n",
            " output/ScalarAddOperation: 6.73e+07\n",
            " output/ScalarMultiplyOperation: 2.01e+09\n",
            " output/ShiftOperation: 5.25e+05\n",
            " output/SlicewiseOperation: 1.64e+11\n",
            " output/StackedVariable: 1.35e+05\n",
            " output/StopGradient: 3.88e+10\n",
            " output/UnstackOperation: 1.35e+05\n",
            " output/Variable: 4.84e+08\n",
            " output/WhileLoopOperation: 3.23e+09\n",
            "output_unique: 5.34e+11\n",
            " output_unique/AddOperation: 1.38e+11\n",
            " output_unique/BinaryOpWithBroadcasting: 1.63e+09\n",
            " output_unique/Constant: 3.23e+09\n",
            " output_unique/EinsumOperation: 1.22e+11\n",
            " output_unique/ImportOperation: 1.05e+06\n",
            " output_unique/MinMaxOperation: 5.26e+06\n",
            " output_unique/OneHotOperation: 3.39e+10\n",
            " output_unique/RangeOperation: 1.03e+03\n",
            " output_unique/ReduceOperation: 1.68e+08\n",
            " output_unique/ReshapeOperation: 2.77e+10\n",
            " output_unique/ScalarAddOperation: 2.31e+07\n",
            " output_unique/ScalarMultiplyOperation: 1.92e+09\n",
            " output_unique/ShiftOperation: 5.25e+05\n",
            " output_unique/SlicewiseOperation: 1.64e+11\n",
            " output_unique/StackedVariable: 1.69e+04\n",
            " output_unique/StopGradient: 3.88e+10\n",
            " output_unique/UnstackOperation: 1.69e+04\n",
            " output_unique/Variable: 6.05e+07\n",
            " output_unique/WhileLoopOperation: 3.23e+09\n",
            "variables: 6.05e+07\n",
            " variables/trainable: 6.05e+07\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from gs://code_review_automation/fine_tuning/HP_tuning/big_model/marked_code/model.ckpt-500000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Before copy master to slices.\n",
            "INFO:tensorflow:Done with copy master to slices.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
            "INFO:tensorflow:decoded 0: markedCode2code: public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); <START> errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); <END> } }); executor.submit(task); }\n",
            "INFO:tensorflow:            -> public void createRecoveryKey() { Task<String> task = new RecoveryKeyCreationTask(); task.setOnScheduled(event -> { LOG.debug(\"Creating recovery key for {}.\", vault.getDisplayablePath()); }); task.setOnSucceeded(event -> { String recoveryKey = task.getValue(); recoveryKeyProperty.set(recoveryKey); window.setScene(successScene.get()); }); task.setOnFailed(event -> { if (task.getException() instanceof InvalidPassphraseException) { Animations.createShakeWindowAnimation(window).play(); } else { LOG.error(\"Creation of recovery key failed.\", task.getException()); errorComponent.cause(task.getException()).window(window).returnToScene(createScene.get()).build().showErrorScene(); } }); executor.submit(task); }\n",
            "INFO:tensorflow:decoded 1: markedCode2code: public int hashCode() { <START> return element.hashCode(); <END> }\n",
            "INFO:tensorflow:            -> public int hashCode() { return element.hashCode(); }\n",
            "INFO:tensorflow:decoded 2: markedCode2code: private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); <START> if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null <END> && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:            -> private void createDynamicMappingControl(Composite parent, TabbedPropertySheetPage tabbedPropertySheetPage, EEFDynamicMappingFor dynamicMappingFor) { String domainClassExpression = dynamicMappingFor.getDomainClassExpression(); EEFDynamicMappingSwitch dynamicMappingSwitch = dynamicMappingFor.getSwitch(); String switchExpression = dynamicMappingSwitch.getSwitchExpression(); if (domainClassExpression != null && domainClassExpression.trim().length() > 0 && switchExpression != null && switchExpression.trim().length() > 0) { IEvaluationResult domainClassExpressionResult = this.interpreter.evaluateExpression(this.variableManager.getVariables(), domainClassExpression); if (domainClassExpressionResult.success()) { for (EObject eObject : domainClassExpressionResult.asEObjects()) { String iterator = dynamicMappingFor.getIterator(); Map<String, Object> switchExpressionVariables = new HashMap<String, Object>(); switchExpressionVariables.put(\"self\", this.variableManager.getVariables().get(\"self\")); switchExpressionVariables.put(iterator, eObject); IEvaluationResult switchExpressionResult = this.interpreter.evaluateExpression(switchExpressionVariables, switchExpression); EEFWidgetDescription eefWidgetDescription = this.getWidgetDescription(switchExpressionResult, dynamicMappingSwitch.getCases()); if (eefWidgetDescription != null) { IVariableManager childVariableManager = this.variableManager.createChild(); childVariableManager.put(iterator, eObject); this.createWidgetControl(parent, tabbedPropertySheetPage, eefWidgetDescription, childVariableManager); } } } } }\n",
            "INFO:tensorflow:decoded 4: markedCode2code: public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } <START> brokerConnections.remove(brokerName); <END> for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:            -> public void removeBrokerConnection(String brokerName) { synchronized (brokerConnections) { MqttBrokerConnection connection = brokerConnections.get(brokerName.toLowerCase()); if (connection == null) { return; } final String brokerID = brokerConnections.remove(brokerName); if (brokerConnections.isEmpty()) { return; } for (MqttBrokersObserver o : brokersObservers) { o.brokerRemoved(connection); } } }\n",
            "INFO:tensorflow:decoded 8: markedCode2code: private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } <START> if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { <END> addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:            -> private void addSiblingNode(int indexOfNode) { synchronized (latestBranch) { final long splitTime = treeEnd; assert (indexOfNode < latestBranch.size()); if (indexOfNode == 0) { addNewRootNode(); return; } if (((CoreNode) latestBranch.get(indexOfNode - 1)).getNbChildren() == config.getMaxChildren()) { addSiblingNode(indexOfNode - 1); return; } for (int i = indexOfNode; i < latestBranch.size(); i++) { latestBranch.get(i).closeThisNode(splitTime); treeIO.writeNode(latestBranch.get(i)); CoreNode prevNode = (CoreNode) latestBranch.get(i - 1); HTNode newNode; switch (latestBranch.get(i).getNodeType()) { case CORE: newNode = initNewCoreNode(prevNode.getSequenceNumber(), splitTime + 1); break; case LEAF: newNode = initNewLeafNode(prevNode.getSequenceNumber(), splitTime + 1); break; default: throw new IllegalStateException(); } prevNode.linkNewChild(newNode); latestBranch.set(i, newNode); } } }\n",
            "INFO:tensorflow:decoded 16: markedCode2code: public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); <START> this.secretPassword = password != null ? Secret.fromString(password) : null; <END> this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:            -> public ProxyConfiguration(String name, int port, String userName, String password, String noProxyHost, String testUrl) { this.name = Util.fixEmptyAndTrim(name); this.port = port; this.userName = Util.fixEmptyAndTrim(userName); this.secretPassword = Secret.fromString(password); this.noProxyHost = Util.fixEmptyAndTrim(noProxyHost); this.testUrl = Util.fixEmptyAndTrim(testUrl); this.authenticator = newAuthenticator(); }\n",
            "INFO:tensorflow:decoded 32: markedCode2code: public void setSlaveConnectTimeout(int slaveConnectTimeout) { if (slaveConnectTimeout < 0) { <START> this.slaveConnectTimeout = 0; <END> } else { this.slaveConnectTimeout = slaveConnectTimeout; } }\n",
            "INFO:tensorflow:            -> public void setSlaveConnectTimeout(int slaveConnectTimeout) { this.slaveConnectTimeout = slaveConnectTimeout; }\n",
            "INFO:tensorflow:decoded 64: markedCode2code: private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); <START> assertNotNull(schemaResource); <END> InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:            -> private void testXSDConfigXML(String xmlFileName) throws Exception { SchemaFactory factory = SchemaFactory.newInstance(XMLConstants.W3C_XML_SCHEMA_NS_URI); URL schemaResource = XMLConfigBuilderTest.class.getClassLoader().getResource(\"hazelcast-config-\" + Versions.CURRENT_CLUSTER_VERSION + \".xsd\"); assertNotNull(schemaResource); InputStream xmlResource = XMLConfigBuilderTest.class.getClassLoader().getResourceAsStream(xmlFileName); Schema schema = factory.newSchema(schemaResource); Source source = new StreamSource(xmlResource); Validator validator = schema.newValidator(); try { validator.validate(source); } catch (SAXException ex) { fail(xmlFileName + \" is not valid because: \" + ex.toString()); } }\n",
            "INFO:tensorflow:decoded 128: markedCode2code: public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); <START> } catch (Exception e) { <END> logger.error(\"Error during start {}\", e); throw new InstantiationError(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); validate(); }\n",
            "INFO:tensorflow:            -> public DataNode(Datacenter datacenter, JSONObject jsonObject, ClusterMapConfig clusterMapConfig) throws JSONException { if (logger.isTraceEnabled()) { logger.trace(\"DataNode \" + jsonObject.toString()); } this.datacenter = datacenter; this.hostname = getFullyQualifiedDomainName(jsonObject.getString(\"hostname\")); this.port = jsonObject.getInt(\"port\"); try { ResourceStatePolicyFactory resourceStatePolicyFactory = Utils .getObj(clusterMapConfig.clusterMapResourceStatePolicyFactory, this, HardwareState.valueOf(jsonObject.getString(\"hardwareState\")), clusterMapConfig); this.dataNodeStatePolicy = resourceStatePolicyFactory.getResourceStatePolicy(); } catch (IllegalArgumentException e) { logger.error(\"Error during start {}\", e); throw new IllegalStateException(\"Error during start \" + e); } JSONArray diskJSONArray = jsonObject.getJSONArray(\"disks\"); this.disks = new ArrayList<Disk>(diskJSONArray.length()); for (int i = 0; i < diskJSONArray.length(); ++i) { this.disks.add(new Disk(this, diskJSONArray.getJSONObject(i), clusterMapConfig)); } this.rawCapacityInBytes = calculateRawCapacityInBytes(); this.disks = new HashMap<Disk, Integer>(); this.disks.put(diskJSONArray.length(), clusterMapConfig); populateDigitalCapacityInBytes(diskJSONArray); validate(); }\n",
            "INFO:tensorflow:decoded 256: markedCode2code: protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; <START> for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { <END> try ( Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:            -> protected void createTable(final DbEntity entity) throws DatabaseEngineException { final String defaultCreateTableStatement = getCreateTableStatement(entity); final String createTableCompressLOBS = getCompressLobsStatements(entity); final String createTableStatement = defaultCreateTableStatement + createTableCompressLOBS; for (final String createTable : ImmutableList.of(createTableStatement, defaultCreateTableStatement)) { try ( final Statement statement = conn.createStatement() ) { statement.executeUpdate(createTable); break; } catch (final SQLException ex) { if (ex.getMessage().startsWith(NAME_ALREADY_EXISTS)) { logger.debug(dev, \"'{}' is already defined\", entity.getName()); handleOperation(new OperationFault(entity.getName(), OperationFault.Type.TABLE_ALREADY_EXISTS), ex); break; } else if (ex.getMessage().startsWith(SECUREFILE_NOT_ASSM)) { logger.warn(\"Secure file LOBS cannot be used in non-ASSM tablespace. Creating table \" + \"without compressed lobs\"); } else { throw new DatabaseEngineException(\"Something went wrong handling statement\", ex); } } } }\n",
            "INFO:tensorflow:decoded 512: markedCode2code: public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); <START> mockCellsWithPadding(0, 0, PADDING, 100d); <END> mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:            -> public void testMinimalWidthOneCellInEachRowWithPadding() throws Exception { gridData.appendColumn(column); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); gridData.appendRow(new DMNGridRow()); mockCellsWithPadding(0, 0, PADDING, 100d); mockCellsWithPadding(1, 0, PADDING, 150); mockCellsWithPadding(2, 0, PADDING, 125); Assertions.assertThat(column.getMinimumWidth()).isEqualTo(170); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 1024: markedCode2code: public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(XBeeAPIType.RX_64); <START> this.sourceAddress = sourceAddress; <END> this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:            -> public RX64Packet(XBee64BitAddress sourceAddress, int rssi, int receiveOptions, byte[] receivedData) { super(APIFrameType.RX_64); if (sourceAddress == null) throw new NullPointerException(\"Source address cannot be null.\"); if (rssi < 0 || rssi > 100) throw new IllegalArgumentException(\"RSSI value must be between 0 and 100.\"); if (receiveOptions < 0 || receiveOptions > 255) throw new IllegalArgumentException(\"Receive options value must be between 0 and 255.\"); this.sourceAddress = sourceAddress; this.rssi = rssi; this.receiveOptions = receiveOptions; this.receivedData = receivedData; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 2048: markedCode2code: public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { <START> return streamToString(getStatsFromWebpack()); <END> } InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:            -> public static String getStatsAssetsByChunkName(VaadinService service) throws IOException { DeploymentConfiguration config = service.getDeploymentConfiguration(); if (!config.isProductionMode() && config.enableDevServer()) { return streamToString(getStatsFromWebpack()); } try (InputStream resourceAsStream; if (config.isStatsExternal()) { resourceAsStream = getStatsFromExternalUrl( config.getExternalStatsUrl(), service.getContext()); } else { resourceAsStream = getStatsFromClassPath(service); } if (resourceAsStream == null) { return null; } try (Scanner scan = new Scanner(resourceAsStream, StandardCharsets.UTF_8.name())) { StringBuilder assets = new StringBuilder(); assets.append(\"{\"); scanToAssetChunkStart(scan, assets); while (scan.hasNextLine()) { String line = scan.nextLine().trim(); if (\"}\".equals(line) || \"},\".equals(line)) { return assets.append(\"}\").toString(); } else if (line.endsWith(\"}\") || line.endsWith(\"},\")) { return assets .append(line.substring(0, line.indexOf('}')).trim()) .append(\"}\").toString(); } else if (line.contains(\"{\")) { break; } assets.append(line); } getLogger() .error(\"Could not parse assetsByChunkName from stats.json\"); } return null; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 4096: markedCode2code: public synchronized BigtableClusterName getClusterName() throws IOException { <START> if (options.getClusterName() == null) { <END> try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:            -> public synchronized BigtableClusterName getClusterName() throws IOException { if (options.getClusterName() == null) { try (BigtableClusterUtilities util = BigtableClusterUtilities.forInstance(options.getProjectId(), options.getInstanceId())) { final ListClustersResponse clusters = util.getClusters(); Preconditions.checkState(clusters.getClustersCount() == 0, \"Project '%s' / Instance '%s' has %d clusters. There must be exactly 1 for this operation to work.\", options.getProjectId(), options.getInstanceId(), clusters.getClustersCount()); String clusterName = util.getSingleCluster().getName(); String clusterId = BigtableClusterName.parse(clusterName).getClusterId(); options = options.toBuilder().setClusterId(clusterId).build(); } catch (GeneralSecurityException e) { throw new IOException(\"Could not get cluster Id.\", e); } } return options.getClusterName(); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 8192: markedCode2code: <START> public void goToweb (View view) { String url = \"<LINK_0>\"; link(url); <END> }\n",
            "INFO:tensorflow:            -> public void goToweb (View view) { link(\"<LINK_0>\"); }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:decoded 16384: markedCode2code: private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { boolean hasUpdatedQualifier = Qualifier.hasUpdatedQualifier(filterExpr); FilterExpression filterExprNoAlias = Qualifier.replaceMilestoneAliases(models, filterExpr); List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) <START> .sorted(determineComparator(filterExprNoAlias, hasUpdatedQualifier)) <END> .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:            -> private Map<FilterExpression, List<TurboIssue>> processFilter(List<FilterExpression> filterExprs) { MultiModel models = logic.getModels(); List<TurboIssue> allModelIssues = models.getIssues(); Map<FilterExpression, List<TurboIssue>> filteredSortedAndCounted = new HashMap<>(); filterExprs.forEach(filterExpr -> { List<TurboIssue> filterAndSortedExpression = filteredSortedAndCounted.get(filterExpr); if (filterAndSortedExpression == null) { List<TurboIssue> filteredSortedAndCountedIssues = allModelIssues.stream() .filter(issue -> Qualifier.process(models, filterExprNoAlias, issue)) .sorted(determineComparator(filterExprNoAlias, Qualifier.hasUpdatedQualifier(filterExpr)) .limit(determineCount(allModelIssues, filterExprNoAlias)) .collect(Collectors.toList()); filteredSortedAndCounted.put(filterExpr, filteredSortedAndCountedIssues); } }); return filteredSortedAndCounted; }\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:eval/marked_code/accuracy at step 500000: 6.861\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTr15bwE6YY-"
      },
      "source": [
        "if ON_CLOUD:\n",
        "  %reload_ext tensorboard\n",
        "  import tensorboard as tb\n",
        "tb.notebook.start(\"--logdir \" + MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}